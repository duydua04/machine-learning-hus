{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "vlH6m6ciAihF",
    "outputId": "a34d0b86-af1a-49f3-bbf7-2698462829a6",
    "ExecuteTime": {
     "end_time": "2025-11-05T03:59:48.785605Z",
     "start_time": "2025-11-05T03:59:48.162848Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"data/heart_disease_health_indicators_BRFSS2015.csv\")\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  \\\n",
       "0                        0.0     1.0       1.0        1.0  40.0     1.0   \n",
       "1                        0.0     0.0       0.0        0.0  25.0     1.0   \n",
       "2                        0.0     1.0       1.0        1.0  28.0     0.0   \n",
       "3                        0.0     1.0       0.0        1.0  27.0     0.0   \n",
       "4                        0.0     1.0       1.0        1.0  24.0     0.0   \n",
       "...                      ...     ...       ...        ...   ...     ...   \n",
       "253675                   0.0     1.0       1.0        1.0  45.0     0.0   \n",
       "253676                   0.0     1.0       1.0        1.0  18.0     0.0   \n",
       "253677                   0.0     0.0       0.0        1.0  28.0     0.0   \n",
       "253678                   0.0     1.0       0.0        1.0  23.0     0.0   \n",
       "253679                   1.0     1.0       1.0        1.0  25.0     0.0   \n",
       "\n",
       "        Stroke  Diabetes  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0          0.0       0.0           0.0     0.0  ...            1.0   \n",
       "1          0.0       0.0           1.0     0.0  ...            0.0   \n",
       "2          0.0       0.0           0.0     1.0  ...            1.0   \n",
       "3          0.0       0.0           1.0     1.0  ...            1.0   \n",
       "4          0.0       0.0           1.0     1.0  ...            1.0   \n",
       "...        ...       ...           ...     ...  ...            ...   \n",
       "253675     0.0       0.0           0.0     1.0  ...            1.0   \n",
       "253676     0.0       2.0           0.0     0.0  ...            1.0   \n",
       "253677     0.0       0.0           1.0     1.0  ...            1.0   \n",
       "253678     0.0       0.0           0.0     1.0  ...            1.0   \n",
       "253679     0.0       2.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "        NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n",
       "0               0.0      5.0      18.0      15.0       1.0  0.0   9.0   \n",
       "1               1.0      3.0       0.0       0.0       0.0  0.0   7.0   \n",
       "2               1.0      5.0      30.0      30.0       1.0  0.0   9.0   \n",
       "3               0.0      2.0       0.0       0.0       0.0  0.0  11.0   \n",
       "4               0.0      2.0       3.0       0.0       0.0  0.0  11.0   \n",
       "...             ...      ...       ...       ...       ...  ...   ...   \n",
       "253675          0.0      3.0       0.0       5.0       0.0  1.0   5.0   \n",
       "253676          0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n",
       "253677          0.0      1.0       0.0       0.0       0.0  0.0   2.0   \n",
       "253678          0.0      3.0       0.0       0.0       0.0  1.0   7.0   \n",
       "253679          0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n",
       "\n",
       "        Education  Income  \n",
       "0             4.0     3.0  \n",
       "1             6.0     1.0  \n",
       "2             4.0     8.0  \n",
       "3             3.0     6.0  \n",
       "4             5.0     4.0  \n",
       "...           ...     ...  \n",
       "253675        6.0     7.0  \n",
       "253676        2.0     4.0  \n",
       "253677        5.0     2.0  \n",
       "253678        5.0     1.0  \n",
       "253679        6.0     2.0  \n",
       "\n",
       "[253680 rows x 22 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253680 rows Ã— 22 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tt1egyf2AihI"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HMuC5diuAihJ",
    "ExecuteTime": {
     "end_time": "2025-11-05T03:59:48.909660Z",
     "start_time": "2025-11-05T03:59:48.890669Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X = df.drop('HeartDiseaseorAttack', axis=1)\n",
    "y = df['HeartDiseaseorAttack'].astype(int)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hb9CYrVvAihK"
   },
   "source": [
    "## Without Demensional Reduction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qG63JHbWAihK",
    "outputId": "49aa7d40-3f43-4f00-c4b8-d7c737a11340",
    "ExecuteTime": {
     "end_time": "2025-11-05T03:59:55.640353Z",
     "start_time": "2025-11-05T03:59:49.068905Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "lrm = LogisticRegression(max_iter=10000, class_weight='balanced', random_state=42)\n",
    "lrm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lrm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.75      0.85     45957\n",
      "           1       0.25      0.80      0.38      4779\n",
      "\n",
      "    accuracy                           0.75     50736\n",
      "   macro avg       0.61      0.77      0.61     50736\n",
      "weighted avg       0.90      0.75      0.80     50736\n",
      "\n",
      "[[34422 11535]\n",
      " [  970  3809]]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zz5Sy6G7AihL",
    "outputId": "9d148486-1290-4a28-bd2b-3855c7c6cb04",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:00:03.455426Z",
     "start_time": "2025-11-05T03:59:56.012093Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "lrm = LogisticRegression(max_iter=10000, class_weight='balanced', random_state=42)\n",
    "lrm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lrm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.75      0.85     68936\n",
      "           1       0.25      0.80      0.38      7168\n",
      "\n",
      "    accuracy                           0.75     76104\n",
      "   macro avg       0.61      0.77      0.61     76104\n",
      "weighted avg       0.90      0.75      0.80     76104\n",
      "\n",
      "[[51511 17425]\n",
      " [ 1463  5705]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oW4gEG5gAihM",
    "outputId": "34ba8576-6cc2-4689-a1a2-0647ada6882f",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:00:09.602397Z",
     "start_time": "2025-11-05T04:00:03.749305Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "lrm = LogisticRegression(max_iter=10000, class_weight='balanced', random_state=42)\n",
    "lrm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lrm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.75      0.84     91915\n",
      "           1       0.25      0.80      0.38      9557\n",
      "\n",
      "    accuracy                           0.75    101472\n",
      "   macro avg       0.61      0.77      0.61    101472\n",
      "weighted avg       0.90      0.75      0.80    101472\n",
      "\n",
      "[[68575 23340]\n",
      " [ 1954  7603]]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i41i91DkAihN"
   },
   "source": [
    "## Dimensional Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tP3QFwmCAihN"
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t56vQl8VAihO",
    "outputId": "e5b69be8-a3ea-4f2b-d0eb-acfdf107ecc5",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:00:10.149699Z",
     "start_time": "2025-11-05T04:00:09.723152Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "std = StandardScaler()\n",
    "X_train_scaled = std.fit_transform(X_train)\n",
    "X_test_scaled = std.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=14)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "lrm = LogisticRegression(max_iter=10000, class_weight='balanced')\n",
    "lrm.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = lrm.predict(X_test_pca)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.75      0.84     45957\n",
      "           1       0.24      0.78      0.37      4779\n",
      "\n",
      "    accuracy                           0.75     50736\n",
      "   macro avg       0.61      0.76      0.61     50736\n",
      "weighted avg       0.90      0.75      0.80     50736\n",
      "\n",
      "[[34358 11599]\n",
      " [ 1049  3730]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlmQC7dMAihO",
    "outputId": "43348cb0-3792-45d5-fd0d-64279c4da13a",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:00:10.659492Z",
     "start_time": "2025-11-05T04:00:10.180458Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "std = StandardScaler()\n",
    "X_train_scaled = std.fit_transform(X_train)\n",
    "X_test_scaled = std.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=14)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "lrm = LogisticRegression(max_iter=10000, class_weight='balanced')\n",
    "lrm.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = lrm.predict(X_test_pca)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.75      0.84     68936\n",
      "           1       0.24      0.78      0.37      7168\n",
      "\n",
      "    accuracy                           0.75     76104\n",
      "   macro avg       0.61      0.76      0.61     76104\n",
      "weighted avg       0.90      0.75      0.80     76104\n",
      "\n",
      "[[51471 17465]\n",
      " [ 1578  5590]]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ggtpRJXAihO",
    "outputId": "4255a3c0-08f9-434f-cb83-8340efbd3482",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:00:11.116590Z",
     "start_time": "2025-11-05T04:00:10.677665Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "std = StandardScaler()\n",
    "X_train_scaled = std.fit_transform(X_train)\n",
    "X_test_scaled = std.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=14)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "\n",
    "lrm = LogisticRegression(max_iter=10000, class_weight='balanced')\n",
    "lrm.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = lrm.predict(X_test_pca)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.75      0.84     91915\n",
      "           1       0.24      0.78      0.37      9557\n",
      "\n",
      "    accuracy                           0.75    101472\n",
      "   macro avg       0.61      0.76      0.61    101472\n",
      "weighted avg       0.90      0.75      0.80    101472\n",
      "\n",
      "[[68478 23437]\n",
      " [ 2075  7482]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TzsC4QwAihP"
   },
   "source": [
    "# Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iU1RBdLnAihP",
    "outputId": "a2005bf8-78d0-46a4-bfcf-bef9126077e2",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:00:15.135624Z",
     "start_time": "2025-11-05T04:00:11.178448Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.ops as ops\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class HeartDiseaseDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "data = pd.read_csv('data/heart_disease_health_indicators_BRFSS2015.csv')\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(data.head())\n",
    "\n",
    "X = data.drop('HeartDiseaseorAttack', axis=1).values\n",
    "y = data['HeartDiseaseorAttack'].values"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading dataset...\n",
      "Dataset shape: (253680, 22)\n",
      "   HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
      "0                   0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
      "1                   0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
      "2                   0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
      "3                   0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
      "4                   0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
      "\n",
      "   Diabetes  PhysActivity  Fruits  ...  AnyHealthcare  NoDocbcCost  GenHlth  \\\n",
      "0       0.0           0.0     0.0  ...            1.0          0.0      5.0   \n",
      "1       0.0           1.0     0.0  ...            0.0          1.0      3.0   \n",
      "2       0.0           0.0     1.0  ...            1.0          1.0      5.0   \n",
      "3       0.0           1.0     1.0  ...            1.0          0.0      2.0   \n",
      "4       0.0           1.0     1.0  ...            1.0          0.0      2.0   \n",
      "\n",
      "   MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \n",
      "0      18.0      15.0       1.0  0.0   9.0        4.0     3.0  \n",
      "1       0.0       0.0       0.0  0.0   7.0        6.0     1.0  \n",
      "2      30.0      30.0       1.0  0.0   9.0        4.0     8.0  \n",
      "3       0.0       0.0       0.0  0.0  11.0        3.0     6.0  \n",
      "4       3.0       0.0       0.0  0.0  11.0        5.0     4.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gg8N53--AihQ",
    "outputId": "c5198e54-3450-4bd6-bc88-8b3cd2e5b098",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:00:15.249216Z",
     "start_time": "2025-11-05T04:00:15.224069Z"
    }
   },
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(\"\\nClass distribution:\")\n",
    "for value, count in zip(unique, counts):\n",
    "    print(f\"Class {value}: {count} samples ({100 * count / len(y):.2f}%)\")\n",
    "\n",
    "total_size = len(X)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "dataset = HeartDiseaseDataset(X, y)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution:\n",
      "Class 0.0: 229787 samples (90.58%)\n",
      "Class 1.0: 23893 samples (9.42%)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tR38P8elAihQ",
    "outputId": "2b017931-27dd-4c9f-c4cb-cfdde064d8e5",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:00:15.291818Z",
     "start_time": "2025-11-05T04:00:15.282487Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class HeartDiseaseMLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes=2, class_frequencies=None):\n",
    "        super(HeartDiseaseMLPClassifier, self).__init__()\n",
    "\n",
    "        self.mlp = ops.MLP(\n",
    "            in_channels=input_size,\n",
    "            hidden_channels=[128, 64, 32],  # 3 hidden layers\n",
    "            norm_layer=nn.BatchNorm1d,      # batch normalization\n",
    "            activation_layer=nn.ReLU,       # ReLU activation\n",
    "            dropout=0.3,                    # 30% dropout for regularization\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "        # Output layer for binary classification\n",
    "        self.classifier = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        if class_frequencies:\n",
    "            self.weights = torch.tensor([1.0 / (freq + 1e-7) for freq in class_frequencies], device=device)\n",
    "        else:\n",
    "            self.weights = torch.ones(num_classes, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        x = self.classifier(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "    def get_weighted_loss(self, outputs, labels):\n",
    "        # Ensure outputs and labels are on the same device\n",
    "        outputs = outputs.to(self.weights.device)\n",
    "        labels = labels.to(self.weights.device)\n",
    "        labels = labels.float()\n",
    "\n",
    "        # For binary classification with sigmoid outputs\n",
    "        criterion = nn.BCELoss(reduction='none')\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Apply class weights for binary classification\n",
    "        weighted_loss = torch.zeros_like(loss)\n",
    "\n",
    "        # Class 1 (positive samples)\n",
    "        positive_mask = (labels == 1)\n",
    "        if positive_mask.any():\n",
    "            weighted_loss[positive_mask] = loss[positive_mask] * self.weights[1]\n",
    "\n",
    "        # Class 0 (negative samples)\n",
    "        negative_mask = (labels == 0)\n",
    "        if negative_mask.any():\n",
    "            weighted_loss[negative_mask] = loss[negative_mask] * self.weights[0]\n",
    "\n",
    "        return weighted_loss.mean()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw3cCfhTAihR"
   },
   "source": [
    "## Without weight-balanced"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjatyvsDAihR",
    "outputId": "29dffbc2-4a40-4b16-fd44-20bd65d652c3",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:00:15.352722Z",
     "start_time": "2025-11-05T04:00:15.346717Z"
    }
   },
   "source": [
    "input_features = X.shape[1]\n",
    "model = HeartDiseaseMLPClassifier(input_features).to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeartDiseaseMLPClassifier(\n",
      "  (mlp): MLP(\n",
      "    (0): Linear(in_features=21, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (9): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvnX9SrLAihR",
    "outputId": "e4dff7db-cb0b-4d46-a822-581a17ded2c3",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:01:51.969050Z",
     "start_time": "2025-11-05T04:00:15.442992Z"
    }
   },
   "source": [
    "num_epochs = 20\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_aucs = []\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        target = target.float()\n",
    "        output = output.float()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "print('Training finished!')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch: 1/20, Batch: 0/1586, Loss: 0.7398\n",
      "Epoch: 1/20, Batch: 50/1586, Loss: 0.1972\n",
      "Epoch: 1/20, Batch: 100/1586, Loss: 0.2594\n",
      "Epoch: 1/20, Batch: 150/1586, Loss: 0.1936\n",
      "Epoch: 1/20, Batch: 200/1586, Loss: 0.2085\n",
      "Epoch: 1/20, Batch: 250/1586, Loss: 0.2534\n",
      "Epoch: 1/20, Batch: 300/1586, Loss: 0.2134\n",
      "Epoch: 1/20, Batch: 350/1586, Loss: 0.3019\n",
      "Epoch: 1/20, Batch: 400/1586, Loss: 0.2302\n",
      "Epoch: 1/20, Batch: 450/1586, Loss: 0.2073\n",
      "Epoch: 1/20, Batch: 500/1586, Loss: 0.3941\n",
      "Epoch: 1/20, Batch: 550/1586, Loss: 0.1913\n",
      "Epoch: 1/20, Batch: 600/1586, Loss: 0.2019\n",
      "Epoch: 1/20, Batch: 650/1586, Loss: 0.2955\n",
      "Epoch: 1/20, Batch: 700/1586, Loss: 0.2756\n",
      "Epoch: 1/20, Batch: 750/1586, Loss: 0.1962\n",
      "Epoch: 1/20, Batch: 800/1586, Loss: 0.2056\n",
      "Epoch: 1/20, Batch: 850/1586, Loss: 0.2832\n",
      "Epoch: 1/20, Batch: 900/1586, Loss: 0.2440\n",
      "Epoch: 1/20, Batch: 950/1586, Loss: 0.2254\n",
      "Epoch: 1/20, Batch: 1000/1586, Loss: 0.4109\n",
      "Epoch: 1/20, Batch: 1050/1586, Loss: 0.2942\n",
      "Epoch: 1/20, Batch: 1100/1586, Loss: 0.2145\n",
      "Epoch: 1/20, Batch: 1150/1586, Loss: 0.2379\n",
      "Epoch: 1/20, Batch: 1200/1586, Loss: 0.2581\n",
      "Epoch: 1/20, Batch: 1250/1586, Loss: 0.2019\n",
      "Epoch: 1/20, Batch: 1300/1586, Loss: 0.2586\n",
      "Epoch: 1/20, Batch: 1350/1586, Loss: 0.2861\n",
      "Epoch: 1/20, Batch: 1400/1586, Loss: 0.2255\n",
      "Epoch: 1/20, Batch: 1450/1586, Loss: 0.2225\n",
      "Epoch: 1/20, Batch: 1500/1586, Loss: 0.2956\n",
      "Epoch: 1/20, Batch: 1550/1586, Loss: 0.2012\n",
      "Epoch: 1, Train Loss: 0.2559\n",
      "Epoch: 2/20, Batch: 0/1586, Loss: 0.2295\n",
      "Epoch: 2/20, Batch: 50/1586, Loss: 0.1528\n",
      "Epoch: 2/20, Batch: 100/1586, Loss: 0.1807\n",
      "Epoch: 2/20, Batch: 150/1586, Loss: 0.2377\n",
      "Epoch: 2/20, Batch: 200/1586, Loss: 0.2780\n",
      "Epoch: 2/20, Batch: 250/1586, Loss: 0.2204\n",
      "Epoch: 2/20, Batch: 300/1586, Loss: 0.2429\n",
      "Epoch: 2/20, Batch: 350/1586, Loss: 0.2447\n",
      "Epoch: 2/20, Batch: 400/1586, Loss: 0.2122\n",
      "Epoch: 2/20, Batch: 450/1586, Loss: 0.1939\n",
      "Epoch: 2/20, Batch: 500/1586, Loss: 0.2520\n",
      "Epoch: 2/20, Batch: 550/1586, Loss: 0.2388\n",
      "Epoch: 2/20, Batch: 600/1586, Loss: 0.3548\n",
      "Epoch: 2/20, Batch: 650/1586, Loss: 0.2310\n",
      "Epoch: 2/20, Batch: 700/1586, Loss: 0.1763\n",
      "Epoch: 2/20, Batch: 750/1586, Loss: 0.2828\n",
      "Epoch: 2/20, Batch: 800/1586, Loss: 0.2711\n",
      "Epoch: 2/20, Batch: 850/1586, Loss: 0.3101\n",
      "Epoch: 2/20, Batch: 900/1586, Loss: 0.2598\n",
      "Epoch: 2/20, Batch: 950/1586, Loss: 0.2492\n",
      "Epoch: 2/20, Batch: 1000/1586, Loss: 0.2993\n",
      "Epoch: 2/20, Batch: 1050/1586, Loss: 0.2815\n",
      "Epoch: 2/20, Batch: 1100/1586, Loss: 0.1620\n",
      "Epoch: 2/20, Batch: 1150/1586, Loss: 0.3312\n",
      "Epoch: 2/20, Batch: 1200/1586, Loss: 0.2620\n",
      "Epoch: 2/20, Batch: 1250/1586, Loss: 0.2671\n",
      "Epoch: 2/20, Batch: 1300/1586, Loss: 0.2659\n",
      "Epoch: 2/20, Batch: 1350/1586, Loss: 0.2563\n",
      "Epoch: 2/20, Batch: 1400/1586, Loss: 0.2812\n",
      "Epoch: 2/20, Batch: 1450/1586, Loss: 0.2049\n",
      "Epoch: 2/20, Batch: 1500/1586, Loss: 0.2510\n",
      "Epoch: 2/20, Batch: 1550/1586, Loss: 0.2137\n",
      "Epoch: 2, Train Loss: 0.2451\n",
      "Epoch: 3/20, Batch: 0/1586, Loss: 0.1884\n",
      "Epoch: 3/20, Batch: 50/1586, Loss: 0.2088\n",
      "Epoch: 3/20, Batch: 100/1586, Loss: 0.2053\n",
      "Epoch: 3/20, Batch: 150/1586, Loss: 0.2371\n",
      "Epoch: 3/20, Batch: 200/1586, Loss: 0.2149\n",
      "Epoch: 3/20, Batch: 250/1586, Loss: 0.1629\n",
      "Epoch: 3/20, Batch: 300/1586, Loss: 0.2047\n",
      "Epoch: 3/20, Batch: 350/1586, Loss: 0.2646\n",
      "Epoch: 3/20, Batch: 400/1586, Loss: 0.1963\n",
      "Epoch: 3/20, Batch: 450/1586, Loss: 0.1978\n",
      "Epoch: 3/20, Batch: 500/1586, Loss: 0.3429\n",
      "Epoch: 3/20, Batch: 550/1586, Loss: 0.1614\n",
      "Epoch: 3/20, Batch: 600/1586, Loss: 0.2506\n",
      "Epoch: 3/20, Batch: 650/1586, Loss: 0.1422\n",
      "Epoch: 3/20, Batch: 700/1586, Loss: 0.2468\n",
      "Epoch: 3/20, Batch: 750/1586, Loss: 0.2032\n",
      "Epoch: 3/20, Batch: 800/1586, Loss: 0.2476\n",
      "Epoch: 3/20, Batch: 850/1586, Loss: 0.1925\n",
      "Epoch: 3/20, Batch: 900/1586, Loss: 0.3754\n",
      "Epoch: 3/20, Batch: 950/1586, Loss: 0.1961\n",
      "Epoch: 3/20, Batch: 1000/1586, Loss: 0.2151\n",
      "Epoch: 3/20, Batch: 1050/1586, Loss: 0.1695\n",
      "Epoch: 3/20, Batch: 1100/1586, Loss: 0.2118\n",
      "Epoch: 3/20, Batch: 1150/1586, Loss: 0.2809\n",
      "Epoch: 3/20, Batch: 1200/1586, Loss: 0.2813\n",
      "Epoch: 3/20, Batch: 1250/1586, Loss: 0.2668\n",
      "Epoch: 3/20, Batch: 1300/1586, Loss: 0.1761\n",
      "Epoch: 3/20, Batch: 1350/1586, Loss: 0.2169\n",
      "Epoch: 3/20, Batch: 1400/1586, Loss: 0.2610\n",
      "Epoch: 3/20, Batch: 1450/1586, Loss: 0.2803\n",
      "Epoch: 3/20, Batch: 1500/1586, Loss: 0.3228\n",
      "Epoch: 3/20, Batch: 1550/1586, Loss: 0.1440\n",
      "Epoch: 3, Train Loss: 0.2435\n",
      "Epoch: 4/20, Batch: 0/1586, Loss: 0.3515\n",
      "Epoch: 4/20, Batch: 50/1586, Loss: 0.1974\n",
      "Epoch: 4/20, Batch: 100/1586, Loss: 0.4481\n",
      "Epoch: 4/20, Batch: 150/1586, Loss: 0.2337\n",
      "Epoch: 4/20, Batch: 200/1586, Loss: 0.2683\n",
      "Epoch: 4/20, Batch: 250/1586, Loss: 0.1819\n",
      "Epoch: 4/20, Batch: 300/1586, Loss: 0.2383\n",
      "Epoch: 4/20, Batch: 350/1586, Loss: 0.3098\n",
      "Epoch: 4/20, Batch: 400/1586, Loss: 0.2673\n",
      "Epoch: 4/20, Batch: 450/1586, Loss: 0.3105\n",
      "Epoch: 4/20, Batch: 500/1586, Loss: 0.2622\n",
      "Epoch: 4/20, Batch: 550/1586, Loss: 0.2808\n",
      "Epoch: 4/20, Batch: 600/1586, Loss: 0.2635\n",
      "Epoch: 4/20, Batch: 650/1586, Loss: 0.2406\n",
      "Epoch: 4/20, Batch: 700/1586, Loss: 0.2448\n",
      "Epoch: 4/20, Batch: 750/1586, Loss: 0.2068\n",
      "Epoch: 4/20, Batch: 800/1586, Loss: 0.2072\n",
      "Epoch: 4/20, Batch: 850/1586, Loss: 0.2296\n",
      "Epoch: 4/20, Batch: 900/1586, Loss: 0.2213\n",
      "Epoch: 4/20, Batch: 950/1586, Loss: 0.2239\n",
      "Epoch: 4/20, Batch: 1000/1586, Loss: 0.2044\n",
      "Epoch: 4/20, Batch: 1050/1586, Loss: 0.1825\n",
      "Epoch: 4/20, Batch: 1100/1586, Loss: 0.2375\n",
      "Epoch: 4/20, Batch: 1150/1586, Loss: 0.2605\n",
      "Epoch: 4/20, Batch: 1200/1586, Loss: 0.2318\n",
      "Epoch: 4/20, Batch: 1250/1586, Loss: 0.2489\n",
      "Epoch: 4/20, Batch: 1300/1586, Loss: 0.2249\n",
      "Epoch: 4/20, Batch: 1350/1586, Loss: 0.3023\n",
      "Epoch: 4/20, Batch: 1400/1586, Loss: 0.2251\n",
      "Epoch: 4/20, Batch: 1450/1586, Loss: 0.1941\n",
      "Epoch: 4/20, Batch: 1500/1586, Loss: 0.1752\n",
      "Epoch: 4/20, Batch: 1550/1586, Loss: 0.2133\n",
      "Epoch: 4, Train Loss: 0.2428\n",
      "Epoch: 5/20, Batch: 0/1586, Loss: 0.2825\n",
      "Epoch: 5/20, Batch: 50/1586, Loss: 0.3694\n",
      "Epoch: 5/20, Batch: 100/1586, Loss: 0.2427\n",
      "Epoch: 5/20, Batch: 150/1586, Loss: 0.3118\n",
      "Epoch: 5/20, Batch: 200/1586, Loss: 0.2583\n",
      "Epoch: 5/20, Batch: 250/1586, Loss: 0.3413\n",
      "Epoch: 5/20, Batch: 300/1586, Loss: 0.2863\n",
      "Epoch: 5/20, Batch: 350/1586, Loss: 0.2503\n",
      "Epoch: 5/20, Batch: 400/1586, Loss: 0.2422\n",
      "Epoch: 5/20, Batch: 450/1586, Loss: 0.2466\n",
      "Epoch: 5/20, Batch: 500/1586, Loss: 0.2229\n",
      "Epoch: 5/20, Batch: 550/1586, Loss: 0.2186\n",
      "Epoch: 5/20, Batch: 600/1586, Loss: 0.2028\n",
      "Epoch: 5/20, Batch: 650/1586, Loss: 0.2099\n",
      "Epoch: 5/20, Batch: 700/1586, Loss: 0.2383\n",
      "Epoch: 5/20, Batch: 750/1586, Loss: 0.2840\n",
      "Epoch: 5/20, Batch: 800/1586, Loss: 0.2909\n",
      "Epoch: 5/20, Batch: 850/1586, Loss: 0.2289\n",
      "Epoch: 5/20, Batch: 900/1586, Loss: 0.2203\n",
      "Epoch: 5/20, Batch: 950/1586, Loss: 0.2440\n",
      "Epoch: 5/20, Batch: 1000/1586, Loss: 0.2411\n",
      "Epoch: 5/20, Batch: 1050/1586, Loss: 0.2584\n",
      "Epoch: 5/20, Batch: 1100/1586, Loss: 0.3347\n",
      "Epoch: 5/20, Batch: 1150/1586, Loss: 0.1986\n",
      "Epoch: 5/20, Batch: 1200/1586, Loss: 0.2083\n",
      "Epoch: 5/20, Batch: 1250/1586, Loss: 0.3264\n",
      "Epoch: 5/20, Batch: 1300/1586, Loss: 0.3203\n",
      "Epoch: 5/20, Batch: 1350/1586, Loss: 0.2318\n",
      "Epoch: 5/20, Batch: 1400/1586, Loss: 0.1710\n",
      "Epoch: 5/20, Batch: 1450/1586, Loss: 0.1960\n",
      "Epoch: 5/20, Batch: 1500/1586, Loss: 0.2512\n",
      "Epoch: 5/20, Batch: 1550/1586, Loss: 0.2383\n",
      "Epoch: 5, Train Loss: 0.2424\n",
      "Epoch: 6/20, Batch: 0/1586, Loss: 0.1851\n",
      "Epoch: 6/20, Batch: 50/1586, Loss: 0.2205\n",
      "Epoch: 6/20, Batch: 100/1586, Loss: 0.3575\n",
      "Epoch: 6/20, Batch: 150/1586, Loss: 0.1896\n",
      "Epoch: 6/20, Batch: 200/1586, Loss: 0.2248\n",
      "Epoch: 6/20, Batch: 250/1586, Loss: 0.2542\n",
      "Epoch: 6/20, Batch: 300/1586, Loss: 0.1467\n",
      "Epoch: 6/20, Batch: 350/1586, Loss: 0.1881\n",
      "Epoch: 6/20, Batch: 400/1586, Loss: 0.1777\n",
      "Epoch: 6/20, Batch: 450/1586, Loss: 0.3742\n",
      "Epoch: 6/20, Batch: 500/1586, Loss: 0.2808\n",
      "Epoch: 6/20, Batch: 550/1586, Loss: 0.2424\n",
      "Epoch: 6/20, Batch: 600/1586, Loss: 0.2362\n",
      "Epoch: 6/20, Batch: 650/1586, Loss: 0.3032\n",
      "Epoch: 6/20, Batch: 700/1586, Loss: 0.2704\n",
      "Epoch: 6/20, Batch: 750/1586, Loss: 0.2110\n",
      "Epoch: 6/20, Batch: 800/1586, Loss: 0.1593\n",
      "Epoch: 6/20, Batch: 850/1586, Loss: 0.2398\n",
      "Epoch: 6/20, Batch: 900/1586, Loss: 0.1868\n",
      "Epoch: 6/20, Batch: 950/1586, Loss: 0.2776\n",
      "Epoch: 6/20, Batch: 1000/1586, Loss: 0.1808\n",
      "Epoch: 6/20, Batch: 1050/1586, Loss: 0.2127\n",
      "Epoch: 6/20, Batch: 1100/1586, Loss: 0.2998\n",
      "Epoch: 6/20, Batch: 1150/1586, Loss: 0.2748\n",
      "Epoch: 6/20, Batch: 1200/1586, Loss: 0.2155\n",
      "Epoch: 6/20, Batch: 1250/1586, Loss: 0.1903\n",
      "Epoch: 6/20, Batch: 1300/1586, Loss: 0.2128\n",
      "Epoch: 6/20, Batch: 1350/1586, Loss: 0.1425\n",
      "Epoch: 6/20, Batch: 1400/1586, Loss: 0.2705\n",
      "Epoch: 6/20, Batch: 1450/1586, Loss: 0.2412\n",
      "Epoch: 6/20, Batch: 1500/1586, Loss: 0.2504\n",
      "Epoch: 6/20, Batch: 1550/1586, Loss: 0.3202\n",
      "Epoch: 6, Train Loss: 0.2414\n",
      "Epoch: 7/20, Batch: 0/1586, Loss: 0.2793\n",
      "Epoch: 7/20, Batch: 50/1586, Loss: 0.1717\n",
      "Epoch: 7/20, Batch: 100/1586, Loss: 0.2088\n",
      "Epoch: 7/20, Batch: 150/1586, Loss: 0.1864\n",
      "Epoch: 7/20, Batch: 200/1586, Loss: 0.4034\n",
      "Epoch: 7/20, Batch: 250/1586, Loss: 0.2390\n",
      "Epoch: 7/20, Batch: 300/1586, Loss: 0.1866\n",
      "Epoch: 7/20, Batch: 350/1586, Loss: 0.2145\n",
      "Epoch: 7/20, Batch: 400/1586, Loss: 0.2371\n",
      "Epoch: 7/20, Batch: 450/1586, Loss: 0.3040\n",
      "Epoch: 7/20, Batch: 500/1586, Loss: 0.2590\n",
      "Epoch: 7/20, Batch: 550/1586, Loss: 0.2367\n",
      "Epoch: 7/20, Batch: 600/1586, Loss: 0.1564\n",
      "Epoch: 7/20, Batch: 650/1586, Loss: 0.2179\n",
      "Epoch: 7/20, Batch: 700/1586, Loss: 0.2188\n",
      "Epoch: 7/20, Batch: 750/1586, Loss: 0.1841\n",
      "Epoch: 7/20, Batch: 800/1586, Loss: 0.2442\n",
      "Epoch: 7/20, Batch: 850/1586, Loss: 0.3201\n",
      "Epoch: 7/20, Batch: 900/1586, Loss: 0.2596\n",
      "Epoch: 7/20, Batch: 950/1586, Loss: 0.2614\n",
      "Epoch: 7/20, Batch: 1000/1586, Loss: 0.2468\n",
      "Epoch: 7/20, Batch: 1050/1586, Loss: 0.1715\n",
      "Epoch: 7/20, Batch: 1100/1586, Loss: 0.2371\n",
      "Epoch: 7/20, Batch: 1150/1586, Loss: 0.2398\n",
      "Epoch: 7/20, Batch: 1200/1586, Loss: 0.1720\n",
      "Epoch: 7/20, Batch: 1250/1586, Loss: 0.2391\n",
      "Epoch: 7/20, Batch: 1300/1586, Loss: 0.2071\n",
      "Epoch: 7/20, Batch: 1350/1586, Loss: 0.2547\n",
      "Epoch: 7/20, Batch: 1400/1586, Loss: 0.1923\n",
      "Epoch: 7/20, Batch: 1450/1586, Loss: 0.4247\n",
      "Epoch: 7/20, Batch: 1500/1586, Loss: 0.2253\n",
      "Epoch: 7/20, Batch: 1550/1586, Loss: 0.2245\n",
      "Epoch: 7, Train Loss: 0.2416\n",
      "Epoch: 8/20, Batch: 0/1586, Loss: 0.3525\n",
      "Epoch: 8/20, Batch: 50/1586, Loss: 0.2764\n",
      "Epoch: 8/20, Batch: 100/1586, Loss: 0.1982\n",
      "Epoch: 8/20, Batch: 150/1586, Loss: 0.2453\n",
      "Epoch: 8/20, Batch: 200/1586, Loss: 0.3336\n",
      "Epoch: 8/20, Batch: 250/1586, Loss: 0.2555\n",
      "Epoch: 8/20, Batch: 300/1586, Loss: 0.1914\n",
      "Epoch: 8/20, Batch: 350/1586, Loss: 0.2711\n",
      "Epoch: 8/20, Batch: 400/1586, Loss: 0.2424\n",
      "Epoch: 8/20, Batch: 450/1586, Loss: 0.2571\n",
      "Epoch: 8/20, Batch: 500/1586, Loss: 0.2354\n",
      "Epoch: 8/20, Batch: 550/1586, Loss: 0.1837\n",
      "Epoch: 8/20, Batch: 600/1586, Loss: 0.2257\n",
      "Epoch: 8/20, Batch: 650/1586, Loss: 0.2340\n",
      "Epoch: 8/20, Batch: 700/1586, Loss: 0.2946\n",
      "Epoch: 8/20, Batch: 750/1586, Loss: 0.3147\n",
      "Epoch: 8/20, Batch: 800/1586, Loss: 0.2122\n",
      "Epoch: 8/20, Batch: 850/1586, Loss: 0.1802\n",
      "Epoch: 8/20, Batch: 900/1586, Loss: 0.2049\n",
      "Epoch: 8/20, Batch: 950/1586, Loss: 0.1908\n",
      "Epoch: 8/20, Batch: 1000/1586, Loss: 0.3200\n",
      "Epoch: 8/20, Batch: 1050/1586, Loss: 0.2154\n",
      "Epoch: 8/20, Batch: 1100/1586, Loss: 0.2136\n",
      "Epoch: 8/20, Batch: 1150/1586, Loss: 0.2332\n",
      "Epoch: 8/20, Batch: 1200/1586, Loss: 0.1952\n",
      "Epoch: 8/20, Batch: 1250/1586, Loss: 0.2128\n",
      "Epoch: 8/20, Batch: 1300/1586, Loss: 0.2293\n",
      "Epoch: 8/20, Batch: 1350/1586, Loss: 0.1963\n",
      "Epoch: 8/20, Batch: 1400/1586, Loss: 0.1999\n",
      "Epoch: 8/20, Batch: 1450/1586, Loss: 0.2917\n",
      "Epoch: 8/20, Batch: 1500/1586, Loss: 0.2056\n",
      "Epoch: 8/20, Batch: 1550/1586, Loss: 0.2863\n",
      "Epoch: 8, Train Loss: 0.2413\n",
      "Epoch: 9/20, Batch: 0/1586, Loss: 0.2234\n",
      "Epoch: 9/20, Batch: 50/1586, Loss: 0.2179\n",
      "Epoch: 9/20, Batch: 100/1586, Loss: 0.1907\n",
      "Epoch: 9/20, Batch: 150/1586, Loss: 0.2298\n",
      "Epoch: 9/20, Batch: 200/1586, Loss: 0.2402\n",
      "Epoch: 9/20, Batch: 250/1586, Loss: 0.2299\n",
      "Epoch: 9/20, Batch: 300/1586, Loss: 0.2784\n",
      "Epoch: 9/20, Batch: 350/1586, Loss: 0.1999\n",
      "Epoch: 9/20, Batch: 400/1586, Loss: 0.2080\n",
      "Epoch: 9/20, Batch: 450/1586, Loss: 0.2860\n",
      "Epoch: 9/20, Batch: 500/1586, Loss: 0.2679\n",
      "Epoch: 9/20, Batch: 550/1586, Loss: 0.2644\n",
      "Epoch: 9/20, Batch: 600/1586, Loss: 0.2299\n",
      "Epoch: 9/20, Batch: 650/1586, Loss: 0.2573\n",
      "Epoch: 9/20, Batch: 700/1586, Loss: 0.2638\n",
      "Epoch: 9/20, Batch: 750/1586, Loss: 0.2640\n",
      "Epoch: 9/20, Batch: 800/1586, Loss: 0.2198\n",
      "Epoch: 9/20, Batch: 850/1586, Loss: 0.2599\n",
      "Epoch: 9/20, Batch: 900/1586, Loss: 0.3184\n",
      "Epoch: 9/20, Batch: 950/1586, Loss: 0.1213\n",
      "Epoch: 9/20, Batch: 1000/1586, Loss: 0.2737\n",
      "Epoch: 9/20, Batch: 1050/1586, Loss: 0.1977\n",
      "Epoch: 9/20, Batch: 1100/1586, Loss: 0.2590\n",
      "Epoch: 9/20, Batch: 1150/1586, Loss: 0.2610\n",
      "Epoch: 9/20, Batch: 1200/1586, Loss: 0.3189\n",
      "Epoch: 9/20, Batch: 1250/1586, Loss: 0.2813\n",
      "Epoch: 9/20, Batch: 1300/1586, Loss: 0.1993\n",
      "Epoch: 9/20, Batch: 1350/1586, Loss: 0.3418\n",
      "Epoch: 9/20, Batch: 1400/1586, Loss: 0.2407\n",
      "Epoch: 9/20, Batch: 1450/1586, Loss: 0.3123\n",
      "Epoch: 9/20, Batch: 1500/1586, Loss: 0.2534\n",
      "Epoch: 9/20, Batch: 1550/1586, Loss: 0.1997\n",
      "Epoch: 9, Train Loss: 0.2413\n",
      "Epoch: 10/20, Batch: 0/1586, Loss: 0.1603\n",
      "Epoch: 10/20, Batch: 50/1586, Loss: 0.2495\n",
      "Epoch: 10/20, Batch: 100/1586, Loss: 0.2233\n",
      "Epoch: 10/20, Batch: 150/1586, Loss: 0.1817\n",
      "Epoch: 10/20, Batch: 200/1586, Loss: 0.2011\n",
      "Epoch: 10/20, Batch: 250/1586, Loss: 0.1754\n",
      "Epoch: 10/20, Batch: 300/1586, Loss: 0.2027\n",
      "Epoch: 10/20, Batch: 350/1586, Loss: 0.1934\n",
      "Epoch: 10/20, Batch: 400/1586, Loss: 0.3105\n",
      "Epoch: 10/20, Batch: 450/1586, Loss: 0.3460\n",
      "Epoch: 10/20, Batch: 500/1586, Loss: 0.3599\n",
      "Epoch: 10/20, Batch: 550/1586, Loss: 0.3016\n",
      "Epoch: 10/20, Batch: 600/1586, Loss: 0.3494\n",
      "Epoch: 10/20, Batch: 650/1586, Loss: 0.3304\n",
      "Epoch: 10/20, Batch: 700/1586, Loss: 0.1911\n",
      "Epoch: 10/20, Batch: 750/1586, Loss: 0.1945\n",
      "Epoch: 10/20, Batch: 800/1586, Loss: 0.2766\n",
      "Epoch: 10/20, Batch: 850/1586, Loss: 0.1999\n",
      "Epoch: 10/20, Batch: 900/1586, Loss: 0.2271\n",
      "Epoch: 10/20, Batch: 950/1586, Loss: 0.2081\n",
      "Epoch: 10/20, Batch: 1000/1586, Loss: 0.2399\n",
      "Epoch: 10/20, Batch: 1050/1586, Loss: 0.2070\n",
      "Epoch: 10/20, Batch: 1100/1586, Loss: 0.2227\n",
      "Epoch: 10/20, Batch: 1150/1586, Loss: 0.2533\n",
      "Epoch: 10/20, Batch: 1200/1586, Loss: 0.2969\n",
      "Epoch: 10/20, Batch: 1250/1586, Loss: 0.1839\n",
      "Epoch: 10/20, Batch: 1300/1586, Loss: 0.1667\n",
      "Epoch: 10/20, Batch: 1350/1586, Loss: 0.2991\n",
      "Epoch: 10/20, Batch: 1400/1586, Loss: 0.1457\n",
      "Epoch: 10/20, Batch: 1450/1586, Loss: 0.2803\n",
      "Epoch: 10/20, Batch: 1500/1586, Loss: 0.1707\n",
      "Epoch: 10/20, Batch: 1550/1586, Loss: 0.3210\n",
      "Epoch: 10, Train Loss: 0.2408\n",
      "Epoch: 11/20, Batch: 0/1586, Loss: 0.2546\n",
      "Epoch: 11/20, Batch: 50/1586, Loss: 0.2150\n",
      "Epoch: 11/20, Batch: 100/1586, Loss: 0.2123\n",
      "Epoch: 11/20, Batch: 150/1586, Loss: 0.2466\n",
      "Epoch: 11/20, Batch: 200/1586, Loss: 0.2561\n",
      "Epoch: 11/20, Batch: 250/1586, Loss: 0.2529\n",
      "Epoch: 11/20, Batch: 300/1586, Loss: 0.2384\n",
      "Epoch: 11/20, Batch: 350/1586, Loss: 0.2420\n",
      "Epoch: 11/20, Batch: 400/1586, Loss: 0.2389\n",
      "Epoch: 11/20, Batch: 450/1586, Loss: 0.2582\n",
      "Epoch: 11/20, Batch: 500/1586, Loss: 0.2010\n",
      "Epoch: 11/20, Batch: 550/1586, Loss: 0.2530\n",
      "Epoch: 11/20, Batch: 600/1586, Loss: 0.2482\n",
      "Epoch: 11/20, Batch: 650/1586, Loss: 0.3034\n",
      "Epoch: 11/20, Batch: 700/1586, Loss: 0.2441\n",
      "Epoch: 11/20, Batch: 750/1586, Loss: 0.2433\n",
      "Epoch: 11/20, Batch: 800/1586, Loss: 0.1633\n",
      "Epoch: 11/20, Batch: 850/1586, Loss: 0.1623\n",
      "Epoch: 11/20, Batch: 900/1586, Loss: 0.2236\n",
      "Epoch: 11/20, Batch: 950/1586, Loss: 0.2337\n",
      "Epoch: 11/20, Batch: 1000/1586, Loss: 0.2014\n",
      "Epoch: 11/20, Batch: 1050/1586, Loss: 0.2720\n",
      "Epoch: 11/20, Batch: 1100/1586, Loss: 0.1889\n",
      "Epoch: 11/20, Batch: 1150/1586, Loss: 0.1871\n",
      "Epoch: 11/20, Batch: 1200/1586, Loss: 0.1997\n",
      "Epoch: 11/20, Batch: 1250/1586, Loss: 0.2960\n",
      "Epoch: 11/20, Batch: 1300/1586, Loss: 0.1995\n",
      "Epoch: 11/20, Batch: 1350/1586, Loss: 0.1640\n",
      "Epoch: 11/20, Batch: 1400/1586, Loss: 0.2213\n",
      "Epoch: 11/20, Batch: 1450/1586, Loss: 0.2139\n",
      "Epoch: 11/20, Batch: 1500/1586, Loss: 0.2869\n",
      "Epoch: 11/20, Batch: 1550/1586, Loss: 0.1962\n",
      "Epoch: 11, Train Loss: 0.2408\n",
      "Epoch: 12/20, Batch: 0/1586, Loss: 0.2244\n",
      "Epoch: 12/20, Batch: 50/1586, Loss: 0.2177\n",
      "Epoch: 12/20, Batch: 100/1586, Loss: 0.2495\n",
      "Epoch: 12/20, Batch: 150/1586, Loss: 0.2717\n",
      "Epoch: 12/20, Batch: 200/1586, Loss: 0.3203\n",
      "Epoch: 12/20, Batch: 250/1586, Loss: 0.2962\n",
      "Epoch: 12/20, Batch: 300/1586, Loss: 0.2897\n",
      "Epoch: 12/20, Batch: 350/1586, Loss: 0.1792\n",
      "Epoch: 12/20, Batch: 400/1586, Loss: 0.2365\n",
      "Epoch: 12/20, Batch: 450/1586, Loss: 0.1734\n",
      "Epoch: 12/20, Batch: 500/1586, Loss: 0.1764\n",
      "Epoch: 12/20, Batch: 550/1586, Loss: 0.2442\n",
      "Epoch: 12/20, Batch: 600/1586, Loss: 0.1693\n",
      "Epoch: 12/20, Batch: 650/1586, Loss: 0.1609\n",
      "Epoch: 12/20, Batch: 700/1586, Loss: 0.3057\n",
      "Epoch: 12/20, Batch: 750/1586, Loss: 0.2075\n",
      "Epoch: 12/20, Batch: 800/1586, Loss: 0.2571\n",
      "Epoch: 12/20, Batch: 850/1586, Loss: 0.1948\n",
      "Epoch: 12/20, Batch: 900/1586, Loss: 0.2709\n",
      "Epoch: 12/20, Batch: 950/1586, Loss: 0.1384\n",
      "Epoch: 12/20, Batch: 1000/1586, Loss: 0.2405\n",
      "Epoch: 12/20, Batch: 1050/1586, Loss: 0.1947\n",
      "Epoch: 12/20, Batch: 1100/1586, Loss: 0.2611\n",
      "Epoch: 12/20, Batch: 1150/1586, Loss: 0.2544\n",
      "Epoch: 12/20, Batch: 1200/1586, Loss: 0.2357\n",
      "Epoch: 12/20, Batch: 1250/1586, Loss: 0.2550\n",
      "Epoch: 12/20, Batch: 1300/1586, Loss: 0.2542\n",
      "Epoch: 12/20, Batch: 1350/1586, Loss: 0.2861\n",
      "Epoch: 12/20, Batch: 1400/1586, Loss: 0.3785\n",
      "Epoch: 12/20, Batch: 1450/1586, Loss: 0.2428\n",
      "Epoch: 12/20, Batch: 1500/1586, Loss: 0.2347\n",
      "Epoch: 12/20, Batch: 1550/1586, Loss: 0.2208\n",
      "Epoch: 12, Train Loss: 0.2406\n",
      "Epoch: 13/20, Batch: 0/1586, Loss: 0.2374\n",
      "Epoch: 13/20, Batch: 50/1586, Loss: 0.1689\n",
      "Epoch: 13/20, Batch: 100/1586, Loss: 0.2912\n",
      "Epoch: 13/20, Batch: 150/1586, Loss: 0.2208\n",
      "Epoch: 13/20, Batch: 200/1586, Loss: 0.3238\n",
      "Epoch: 13/20, Batch: 250/1586, Loss: 0.1860\n",
      "Epoch: 13/20, Batch: 300/1586, Loss: 0.1947\n",
      "Epoch: 13/20, Batch: 350/1586, Loss: 0.2223\n",
      "Epoch: 13/20, Batch: 400/1586, Loss: 0.2377\n",
      "Epoch: 13/20, Batch: 450/1586, Loss: 0.3066\n",
      "Epoch: 13/20, Batch: 500/1586, Loss: 0.2075\n",
      "Epoch: 13/20, Batch: 550/1586, Loss: 0.2034\n",
      "Epoch: 13/20, Batch: 600/1586, Loss: 0.1825\n",
      "Epoch: 13/20, Batch: 650/1586, Loss: 0.1871\n",
      "Epoch: 13/20, Batch: 700/1586, Loss: 0.1890\n",
      "Epoch: 13/20, Batch: 750/1586, Loss: 0.3413\n",
      "Epoch: 13/20, Batch: 800/1586, Loss: 0.2887\n",
      "Epoch: 13/20, Batch: 850/1586, Loss: 0.2205\n",
      "Epoch: 13/20, Batch: 900/1586, Loss: 0.2857\n",
      "Epoch: 13/20, Batch: 950/1586, Loss: 0.1867\n",
      "Epoch: 13/20, Batch: 1000/1586, Loss: 0.1577\n",
      "Epoch: 13/20, Batch: 1050/1586, Loss: 0.2259\n",
      "Epoch: 13/20, Batch: 1100/1586, Loss: 0.3152\n",
      "Epoch: 13/20, Batch: 1150/1586, Loss: 0.2465\n",
      "Epoch: 13/20, Batch: 1200/1586, Loss: 0.2294\n",
      "Epoch: 13/20, Batch: 1250/1586, Loss: 0.2814\n",
      "Epoch: 13/20, Batch: 1300/1586, Loss: 0.2309\n",
      "Epoch: 13/20, Batch: 1350/1586, Loss: 0.2201\n",
      "Epoch: 13/20, Batch: 1400/1586, Loss: 0.1947\n",
      "Epoch: 13/20, Batch: 1450/1586, Loss: 0.2049\n",
      "Epoch: 13/20, Batch: 1500/1586, Loss: 0.2376\n",
      "Epoch: 13/20, Batch: 1550/1586, Loss: 0.2382\n",
      "Epoch: 13, Train Loss: 0.2403\n",
      "Epoch: 14/20, Batch: 0/1586, Loss: 0.2198\n",
      "Epoch: 14/20, Batch: 50/1586, Loss: 0.2534\n",
      "Epoch: 14/20, Batch: 100/1586, Loss: 0.2058\n",
      "Epoch: 14/20, Batch: 150/1586, Loss: 0.2164\n",
      "Epoch: 14/20, Batch: 200/1586, Loss: 0.2174\n",
      "Epoch: 14/20, Batch: 250/1586, Loss: 0.2476\n",
      "Epoch: 14/20, Batch: 300/1586, Loss: 0.2272\n",
      "Epoch: 14/20, Batch: 350/1586, Loss: 0.3929\n",
      "Epoch: 14/20, Batch: 400/1586, Loss: 0.2514\n",
      "Epoch: 14/20, Batch: 450/1586, Loss: 0.2482\n",
      "Epoch: 14/20, Batch: 500/1586, Loss: 0.2315\n",
      "Epoch: 14/20, Batch: 550/1586, Loss: 0.2323\n",
      "Epoch: 14/20, Batch: 600/1586, Loss: 0.2522\n",
      "Epoch: 14/20, Batch: 650/1586, Loss: 0.2653\n",
      "Epoch: 14/20, Batch: 700/1586, Loss: 0.3181\n",
      "Epoch: 14/20, Batch: 750/1586, Loss: 0.2618\n",
      "Epoch: 14/20, Batch: 800/1586, Loss: 0.1592\n",
      "Epoch: 14/20, Batch: 850/1586, Loss: 0.2239\n",
      "Epoch: 14/20, Batch: 900/1586, Loss: 0.2932\n",
      "Epoch: 14/20, Batch: 950/1586, Loss: 0.3057\n",
      "Epoch: 14/20, Batch: 1000/1586, Loss: 0.2194\n",
      "Epoch: 14/20, Batch: 1050/1586, Loss: 0.2087\n",
      "Epoch: 14/20, Batch: 1100/1586, Loss: 0.3349\n",
      "Epoch: 14/20, Batch: 1150/1586, Loss: 0.2696\n",
      "Epoch: 14/20, Batch: 1200/1586, Loss: 0.1758\n",
      "Epoch: 14/20, Batch: 1250/1586, Loss: 0.2067\n",
      "Epoch: 14/20, Batch: 1300/1586, Loss: 0.2166\n",
      "Epoch: 14/20, Batch: 1350/1586, Loss: 0.2119\n",
      "Epoch: 14/20, Batch: 1400/1586, Loss: 0.3084\n",
      "Epoch: 14/20, Batch: 1450/1586, Loss: 0.2523\n",
      "Epoch: 14/20, Batch: 1500/1586, Loss: 0.2291\n",
      "Epoch: 14/20, Batch: 1550/1586, Loss: 0.2175\n",
      "Epoch: 14, Train Loss: 0.2402\n",
      "Epoch: 15/20, Batch: 0/1586, Loss: 0.3066\n",
      "Epoch: 15/20, Batch: 50/1586, Loss: 0.2738\n",
      "Epoch: 15/20, Batch: 100/1586, Loss: 0.2080\n",
      "Epoch: 15/20, Batch: 150/1586, Loss: 0.2319\n",
      "Epoch: 15/20, Batch: 200/1586, Loss: 0.1919\n",
      "Epoch: 15/20, Batch: 250/1586, Loss: 0.3237\n",
      "Epoch: 15/20, Batch: 300/1586, Loss: 0.2149\n",
      "Epoch: 15/20, Batch: 350/1586, Loss: 0.2211\n",
      "Epoch: 15/20, Batch: 400/1586, Loss: 0.3195\n",
      "Epoch: 15/20, Batch: 450/1586, Loss: 0.2442\n",
      "Epoch: 15/20, Batch: 500/1586, Loss: 0.3172\n",
      "Epoch: 15/20, Batch: 550/1586, Loss: 0.2104\n",
      "Epoch: 15/20, Batch: 600/1586, Loss: 0.1884\n",
      "Epoch: 15/20, Batch: 650/1586, Loss: 0.2932\n",
      "Epoch: 15/20, Batch: 700/1586, Loss: 0.3360\n",
      "Epoch: 15/20, Batch: 750/1586, Loss: 0.2677\n",
      "Epoch: 15/20, Batch: 800/1586, Loss: 0.2238\n",
      "Epoch: 15/20, Batch: 850/1586, Loss: 0.1822\n",
      "Epoch: 15/20, Batch: 900/1586, Loss: 0.2863\n",
      "Epoch: 15/20, Batch: 950/1586, Loss: 0.2251\n",
      "Epoch: 15/20, Batch: 1000/1586, Loss: 0.2010\n",
      "Epoch: 15/20, Batch: 1050/1586, Loss: 0.2229\n",
      "Epoch: 15/20, Batch: 1100/1586, Loss: 0.2535\n",
      "Epoch: 15/20, Batch: 1150/1586, Loss: 0.2895\n",
      "Epoch: 15/20, Batch: 1200/1586, Loss: 0.2229\n",
      "Epoch: 15/20, Batch: 1250/1586, Loss: 0.2905\n",
      "Epoch: 15/20, Batch: 1300/1586, Loss: 0.2343\n",
      "Epoch: 15/20, Batch: 1350/1586, Loss: 0.1865\n",
      "Epoch: 15/20, Batch: 1400/1586, Loss: 0.2462\n",
      "Epoch: 15/20, Batch: 1450/1586, Loss: 0.2231\n",
      "Epoch: 15/20, Batch: 1500/1586, Loss: 0.2992\n",
      "Epoch: 15/20, Batch: 1550/1586, Loss: 0.2155\n",
      "Epoch: 15, Train Loss: 0.2403\n",
      "Epoch: 16/20, Batch: 0/1586, Loss: 0.2536\n",
      "Epoch: 16/20, Batch: 50/1586, Loss: 0.2472\n",
      "Epoch: 16/20, Batch: 100/1586, Loss: 0.3095\n",
      "Epoch: 16/20, Batch: 150/1586, Loss: 0.3598\n",
      "Epoch: 16/20, Batch: 200/1586, Loss: 0.2351\n",
      "Epoch: 16/20, Batch: 250/1586, Loss: 0.2391\n",
      "Epoch: 16/20, Batch: 300/1586, Loss: 0.1969\n",
      "Epoch: 16/20, Batch: 350/1586, Loss: 0.2141\n",
      "Epoch: 16/20, Batch: 400/1586, Loss: 0.2095\n",
      "Epoch: 16/20, Batch: 450/1586, Loss: 0.2253\n",
      "Epoch: 16/20, Batch: 500/1586, Loss: 0.2420\n",
      "Epoch: 16/20, Batch: 550/1586, Loss: 0.2422\n",
      "Epoch: 16/20, Batch: 600/1586, Loss: 0.2749\n",
      "Epoch: 16/20, Batch: 650/1586, Loss: 0.2068\n",
      "Epoch: 16/20, Batch: 700/1586, Loss: 0.2397\n",
      "Epoch: 16/20, Batch: 750/1586, Loss: 0.3584\n",
      "Epoch: 16/20, Batch: 800/1586, Loss: 0.2431\n",
      "Epoch: 16/20, Batch: 850/1586, Loss: 0.2100\n",
      "Epoch: 16/20, Batch: 900/1586, Loss: 0.2715\n",
      "Epoch: 16/20, Batch: 950/1586, Loss: 0.2123\n",
      "Epoch: 16/20, Batch: 1000/1586, Loss: 0.3303\n",
      "Epoch: 16/20, Batch: 1050/1586, Loss: 0.2493\n",
      "Epoch: 16/20, Batch: 1100/1586, Loss: 0.3120\n",
      "Epoch: 16/20, Batch: 1150/1586, Loss: 0.2366\n",
      "Epoch: 16/20, Batch: 1200/1586, Loss: 0.1906\n",
      "Epoch: 16/20, Batch: 1250/1586, Loss: 0.2197\n",
      "Epoch: 16/20, Batch: 1300/1586, Loss: 0.2123\n",
      "Epoch: 16/20, Batch: 1350/1586, Loss: 0.3177\n",
      "Epoch: 16/20, Batch: 1400/1586, Loss: 0.1745\n",
      "Epoch: 16/20, Batch: 1450/1586, Loss: 0.1904\n",
      "Epoch: 16/20, Batch: 1500/1586, Loss: 0.1562\n",
      "Epoch: 16/20, Batch: 1550/1586, Loss: 0.2197\n",
      "Epoch: 16, Train Loss: 0.2400\n",
      "Epoch: 17/20, Batch: 0/1586, Loss: 0.2331\n",
      "Epoch: 17/20, Batch: 50/1586, Loss: 0.2403\n",
      "Epoch: 17/20, Batch: 100/1586, Loss: 0.2062\n",
      "Epoch: 17/20, Batch: 150/1586, Loss: 0.2382\n",
      "Epoch: 17/20, Batch: 200/1586, Loss: 0.2101\n",
      "Epoch: 17/20, Batch: 250/1586, Loss: 0.2148\n",
      "Epoch: 17/20, Batch: 300/1586, Loss: 0.1858\n",
      "Epoch: 17/20, Batch: 350/1586, Loss: 0.2881\n",
      "Epoch: 17/20, Batch: 400/1586, Loss: 0.2099\n",
      "Epoch: 17/20, Batch: 450/1586, Loss: 0.1564\n",
      "Epoch: 17/20, Batch: 500/1586, Loss: 0.2651\n",
      "Epoch: 17/20, Batch: 550/1586, Loss: 0.2364\n",
      "Epoch: 17/20, Batch: 600/1586, Loss: 0.2448\n",
      "Epoch: 17/20, Batch: 650/1586, Loss: 0.2096\n",
      "Epoch: 17/20, Batch: 700/1586, Loss: 0.2331\n",
      "Epoch: 17/20, Batch: 750/1586, Loss: 0.2076\n",
      "Epoch: 17/20, Batch: 800/1586, Loss: 0.1948\n",
      "Epoch: 17/20, Batch: 850/1586, Loss: 0.2748\n",
      "Epoch: 17/20, Batch: 900/1586, Loss: 0.2064\n",
      "Epoch: 17/20, Batch: 950/1586, Loss: 0.3019\n",
      "Epoch: 17/20, Batch: 1000/1586, Loss: 0.2399\n",
      "Epoch: 17/20, Batch: 1050/1586, Loss: 0.2279\n",
      "Epoch: 17/20, Batch: 1100/1586, Loss: 0.1576\n",
      "Epoch: 17/20, Batch: 1150/1586, Loss: 0.1378\n",
      "Epoch: 17/20, Batch: 1200/1586, Loss: 0.1857\n",
      "Epoch: 17/20, Batch: 1250/1586, Loss: 0.1930\n",
      "Epoch: 17/20, Batch: 1300/1586, Loss: 0.2383\n",
      "Epoch: 17/20, Batch: 1350/1586, Loss: 0.3182\n",
      "Epoch: 17/20, Batch: 1400/1586, Loss: 0.2700\n",
      "Epoch: 17/20, Batch: 1450/1586, Loss: 0.2314\n",
      "Epoch: 17/20, Batch: 1500/1586, Loss: 0.2562\n",
      "Epoch: 17/20, Batch: 1550/1586, Loss: 0.3693\n",
      "Epoch: 17, Train Loss: 0.2400\n",
      "Epoch: 18/20, Batch: 0/1586, Loss: 0.2726\n",
      "Epoch: 18/20, Batch: 50/1586, Loss: 0.2144\n",
      "Epoch: 18/20, Batch: 100/1586, Loss: 0.2511\n",
      "Epoch: 18/20, Batch: 150/1586, Loss: 0.2395\n",
      "Epoch: 18/20, Batch: 200/1586, Loss: 0.1628\n",
      "Epoch: 18/20, Batch: 250/1586, Loss: 0.3169\n",
      "Epoch: 18/20, Batch: 300/1586, Loss: 0.2052\n",
      "Epoch: 18/20, Batch: 350/1586, Loss: 0.1839\n",
      "Epoch: 18/20, Batch: 400/1586, Loss: 0.2390\n",
      "Epoch: 18/20, Batch: 450/1586, Loss: 0.2344\n",
      "Epoch: 18/20, Batch: 500/1586, Loss: 0.3486\n",
      "Epoch: 18/20, Batch: 550/1586, Loss: 0.2335\n",
      "Epoch: 18/20, Batch: 600/1586, Loss: 0.1900\n",
      "Epoch: 18/20, Batch: 650/1586, Loss: 0.1917\n",
      "Epoch: 18/20, Batch: 700/1586, Loss: 0.2358\n",
      "Epoch: 18/20, Batch: 750/1586, Loss: 0.2026\n",
      "Epoch: 18/20, Batch: 800/1586, Loss: 0.2172\n",
      "Epoch: 18/20, Batch: 850/1586, Loss: 0.2423\n",
      "Epoch: 18/20, Batch: 900/1586, Loss: 0.2390\n",
      "Epoch: 18/20, Batch: 950/1586, Loss: 0.2097\n",
      "Epoch: 18/20, Batch: 1000/1586, Loss: 0.3561\n",
      "Epoch: 18/20, Batch: 1050/1586, Loss: 0.2236\n",
      "Epoch: 18/20, Batch: 1100/1586, Loss: 0.1855\n",
      "Epoch: 18/20, Batch: 1150/1586, Loss: 0.3167\n",
      "Epoch: 18/20, Batch: 1200/1586, Loss: 0.2553\n",
      "Epoch: 18/20, Batch: 1250/1586, Loss: 0.1825\n",
      "Epoch: 18/20, Batch: 1300/1586, Loss: 0.2794\n",
      "Epoch: 18/20, Batch: 1350/1586, Loss: 0.2138\n",
      "Epoch: 18/20, Batch: 1400/1586, Loss: 0.2212\n",
      "Epoch: 18/20, Batch: 1450/1586, Loss: 0.3046\n",
      "Epoch: 18/20, Batch: 1500/1586, Loss: 0.2465\n",
      "Epoch: 18/20, Batch: 1550/1586, Loss: 0.2891\n",
      "Epoch: 18, Train Loss: 0.2398\n",
      "Epoch: 19/20, Batch: 0/1586, Loss: 0.1728\n",
      "Epoch: 19/20, Batch: 50/1586, Loss: 0.2828\n",
      "Epoch: 19/20, Batch: 100/1586, Loss: 0.2518\n",
      "Epoch: 19/20, Batch: 150/1586, Loss: 0.2601\n",
      "Epoch: 19/20, Batch: 200/1586, Loss: 0.2039\n",
      "Epoch: 19/20, Batch: 250/1586, Loss: 0.2672\n",
      "Epoch: 19/20, Batch: 300/1586, Loss: 0.1946\n",
      "Epoch: 19/20, Batch: 350/1586, Loss: 0.2700\n",
      "Epoch: 19/20, Batch: 400/1586, Loss: 0.1804\n",
      "Epoch: 19/20, Batch: 450/1586, Loss: 0.3344\n",
      "Epoch: 19/20, Batch: 500/1586, Loss: 0.2195\n",
      "Epoch: 19/20, Batch: 550/1586, Loss: 0.2572\n",
      "Epoch: 19/20, Batch: 600/1586, Loss: 0.1674\n",
      "Epoch: 19/20, Batch: 650/1586, Loss: 0.1709\n",
      "Epoch: 19/20, Batch: 700/1586, Loss: 0.2319\n",
      "Epoch: 19/20, Batch: 750/1586, Loss: 0.2622\n",
      "Epoch: 19/20, Batch: 800/1586, Loss: 0.2125\n",
      "Epoch: 19/20, Batch: 850/1586, Loss: 0.1694\n",
      "Epoch: 19/20, Batch: 900/1586, Loss: 0.2318\n",
      "Epoch: 19/20, Batch: 950/1586, Loss: 0.2308\n",
      "Epoch: 19/20, Batch: 1000/1586, Loss: 0.1654\n",
      "Epoch: 19/20, Batch: 1050/1586, Loss: 0.2638\n",
      "Epoch: 19/20, Batch: 1100/1586, Loss: 0.1298\n",
      "Epoch: 19/20, Batch: 1150/1586, Loss: 0.2388\n",
      "Epoch: 19/20, Batch: 1200/1586, Loss: 0.2697\n",
      "Epoch: 19/20, Batch: 1250/1586, Loss: 0.2546\n",
      "Epoch: 19/20, Batch: 1300/1586, Loss: 0.3265\n",
      "Epoch: 19/20, Batch: 1350/1586, Loss: 0.2898\n",
      "Epoch: 19/20, Batch: 1400/1586, Loss: 0.2336\n",
      "Epoch: 19/20, Batch: 1450/1586, Loss: 0.2236\n",
      "Epoch: 19/20, Batch: 1500/1586, Loss: 0.2011\n",
      "Epoch: 19/20, Batch: 1550/1586, Loss: 0.1996\n",
      "Epoch: 19, Train Loss: 0.2399\n",
      "Epoch: 20/20, Batch: 0/1586, Loss: 0.1673\n",
      "Epoch: 20/20, Batch: 50/1586, Loss: 0.2487\n",
      "Epoch: 20/20, Batch: 100/1586, Loss: 0.2952\n",
      "Epoch: 20/20, Batch: 150/1586, Loss: 0.2587\n",
      "Epoch: 20/20, Batch: 200/1586, Loss: 0.2117\n",
      "Epoch: 20/20, Batch: 250/1586, Loss: 0.2421\n",
      "Epoch: 20/20, Batch: 300/1586, Loss: 0.2315\n",
      "Epoch: 20/20, Batch: 350/1586, Loss: 0.3077\n",
      "Epoch: 20/20, Batch: 400/1586, Loss: 0.2138\n",
      "Epoch: 20/20, Batch: 450/1586, Loss: 0.2859\n",
      "Epoch: 20/20, Batch: 500/1586, Loss: 0.4110\n",
      "Epoch: 20/20, Batch: 550/1586, Loss: 0.3187\n",
      "Epoch: 20/20, Batch: 600/1586, Loss: 0.2269\n",
      "Epoch: 20/20, Batch: 650/1586, Loss: 0.1774\n",
      "Epoch: 20/20, Batch: 700/1586, Loss: 0.3302\n",
      "Epoch: 20/20, Batch: 750/1586, Loss: 0.3692\n",
      "Epoch: 20/20, Batch: 800/1586, Loss: 0.2909\n",
      "Epoch: 20/20, Batch: 850/1586, Loss: 0.1320\n",
      "Epoch: 20/20, Batch: 900/1586, Loss: 0.2821\n",
      "Epoch: 20/20, Batch: 950/1586, Loss: 0.2292\n",
      "Epoch: 20/20, Batch: 1000/1586, Loss: 0.1667\n",
      "Epoch: 20/20, Batch: 1050/1586, Loss: 0.2543\n",
      "Epoch: 20/20, Batch: 1100/1586, Loss: 0.2913\n",
      "Epoch: 20/20, Batch: 1150/1586, Loss: 0.2152\n",
      "Epoch: 20/20, Batch: 1200/1586, Loss: 0.2551\n",
      "Epoch: 20/20, Batch: 1250/1586, Loss: 0.2224\n",
      "Epoch: 20/20, Batch: 1300/1586, Loss: 0.2800\n",
      "Epoch: 20/20, Batch: 1350/1586, Loss: 0.2007\n",
      "Epoch: 20/20, Batch: 1400/1586, Loss: 0.1891\n",
      "Epoch: 20/20, Batch: 1450/1586, Loss: 0.1934\n",
      "Epoch: 20/20, Batch: 1500/1586, Loss: 0.1539\n",
      "Epoch: 20/20, Batch: 1550/1586, Loss: 0.2899\n",
      "Epoch: 20, Train Loss: 0.2400\n",
      "Training finished!\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "umea1o7CAihR",
    "outputId": "8e7a56ea-d52a-410e-fc07-dd772d20aa37",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:01:52.632243Z",
     "start_time": "2025-11-05T04:01:52.061362Z"
    }
   },
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        y_true.extend(target.cpu().numpy())\n",
    "        y_pred.extend((output > 0.5).cpu().numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95     45997\n",
      "         1.0       0.62      0.09      0.15      4739\n",
      "\n",
      "    accuracy                           0.91     50736\n",
      "   macro avg       0.77      0.54      0.55     50736\n",
      "weighted avg       0.89      0.91      0.88     50736\n",
      "\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBAOAJawAihS"
   },
   "source": [
    "## Class Weight-Balanced"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nIUWYmc_AihS",
    "outputId": "16be9e04-0b3b-415c-d071-28fd74aa46c9",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:01:52.680520Z",
     "start_time": "2025-11-05T04:01:52.673505Z"
    }
   },
   "source": [
    "class_0_frequency = np.sum(y_train == 0) / len(y_train)\n",
    "class_1_frequency = np.sum(y_train == 1) / len(y_train)\n",
    "class_frequencies = [class_0_frequency, class_1_frequency]\n",
    "print(f\"Class frequencies: {class_frequencies}\")\n",
    "\n",
    "input_features = X.shape[1]\n",
    "\n",
    "weighted_model = HeartDiseaseMLPClassifier(input_size=input_features, class_frequencies=class_frequencies).to(device)\n",
    "print(weighted_model)\n",
    "\n",
    "optimizer = optim.Adam(weighted_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class frequencies: [np.float64(0.905813097866078), np.float64(0.094186902133922)]\n",
      "HeartDiseaseMLPClassifier(\n",
      "  (mlp): MLP(\n",
      "    (0): Linear(in_features=21, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (9): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uP_fMJe7AihS",
    "outputId": "db575c69-16d6-4d40-d917-d7ff3217145c",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:03:43.798267Z",
     "start_time": "2025-11-05T04:01:52.731823Z"
    }
   },
   "source": [
    "num_epochs = 20\n",
    "weighted_train_losses = []\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    weighted_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = weighted_model(data)\n",
    "\n",
    "        target = target.float()\n",
    "        output = output.float()\n",
    "        loss = weighted_model.get_weighted_loss(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    weighted_train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "print('Training finished!')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch: 1/20, Batch: 0/1586, Loss: 0.9985\n",
      "Epoch: 1/20, Batch: 50/1586, Loss: 1.1132\n",
      "Epoch: 1/20, Batch: 100/1586, Loss: 1.1398\n",
      "Epoch: 1/20, Batch: 150/1586, Loss: 1.0684\n",
      "Epoch: 1/20, Batch: 200/1586, Loss: 1.0175\n",
      "Epoch: 1/20, Batch: 250/1586, Loss: 1.2051\n",
      "Epoch: 1/20, Batch: 300/1586, Loss: 1.1930\n",
      "Epoch: 1/20, Batch: 350/1586, Loss: 1.0446\n",
      "Epoch: 1/20, Batch: 400/1586, Loss: 0.8261\n",
      "Epoch: 1/20, Batch: 450/1586, Loss: 0.8800\n",
      "Epoch: 1/20, Batch: 500/1586, Loss: 0.9781\n",
      "Epoch: 1/20, Batch: 550/1586, Loss: 1.1804\n",
      "Epoch: 1/20, Batch: 600/1586, Loss: 0.9379\n",
      "Epoch: 1/20, Batch: 650/1586, Loss: 1.2167\n",
      "Epoch: 1/20, Batch: 700/1586, Loss: 0.8419\n",
      "Epoch: 1/20, Batch: 750/1586, Loss: 1.4502\n",
      "Epoch: 1/20, Batch: 800/1586, Loss: 0.8714\n",
      "Epoch: 1/20, Batch: 850/1586, Loss: 0.7845\n",
      "Epoch: 1/20, Batch: 900/1586, Loss: 0.9252\n",
      "Epoch: 1/20, Batch: 950/1586, Loss: 0.7600\n",
      "Epoch: 1/20, Batch: 1000/1586, Loss: 0.6948\n",
      "Epoch: 1/20, Batch: 1050/1586, Loss: 0.8773\n",
      "Epoch: 1/20, Batch: 1100/1586, Loss: 0.7999\n",
      "Epoch: 1/20, Batch: 1150/1586, Loss: 0.8415\n",
      "Epoch: 1/20, Batch: 1200/1586, Loss: 1.0791\n",
      "Epoch: 1/20, Batch: 1250/1586, Loss: 1.0814\n",
      "Epoch: 1/20, Batch: 1300/1586, Loss: 1.1097\n",
      "Epoch: 1/20, Batch: 1350/1586, Loss: 0.7935\n",
      "Epoch: 1/20, Batch: 1400/1586, Loss: 0.7829\n",
      "Epoch: 1/20, Batch: 1450/1586, Loss: 1.0385\n",
      "Epoch: 1/20, Batch: 1500/1586, Loss: 0.9346\n",
      "Epoch: 1/20, Batch: 1550/1586, Loss: 0.8106\n",
      "Epoch: 1, Train Loss: 1.0167\n",
      "Epoch: 2/20, Batch: 0/1586, Loss: 1.1161\n",
      "Epoch: 2/20, Batch: 50/1586, Loss: 0.9988\n",
      "Epoch: 2/20, Batch: 100/1586, Loss: 1.3976\n",
      "Epoch: 2/20, Batch: 150/1586, Loss: 1.1259\n",
      "Epoch: 2/20, Batch: 200/1586, Loss: 0.9473\n",
      "Epoch: 2/20, Batch: 250/1586, Loss: 1.0934\n",
      "Epoch: 2/20, Batch: 300/1586, Loss: 0.8744\n",
      "Epoch: 2/20, Batch: 350/1586, Loss: 0.9859\n",
      "Epoch: 2/20, Batch: 400/1586, Loss: 0.7678\n",
      "Epoch: 2/20, Batch: 450/1586, Loss: 0.8819\n",
      "Epoch: 2/20, Batch: 500/1586, Loss: 0.7145\n",
      "Epoch: 2/20, Batch: 550/1586, Loss: 0.8496\n",
      "Epoch: 2/20, Batch: 600/1586, Loss: 1.0309\n",
      "Epoch: 2/20, Batch: 650/1586, Loss: 1.1237\n",
      "Epoch: 2/20, Batch: 700/1586, Loss: 1.2602\n",
      "Epoch: 2/20, Batch: 750/1586, Loss: 0.7524\n",
      "Epoch: 2/20, Batch: 800/1586, Loss: 0.8108\n",
      "Epoch: 2/20, Batch: 850/1586, Loss: 0.7535\n",
      "Epoch: 2/20, Batch: 900/1586, Loss: 1.0193\n",
      "Epoch: 2/20, Batch: 950/1586, Loss: 1.2214\n",
      "Epoch: 2/20, Batch: 1000/1586, Loss: 0.6951\n",
      "Epoch: 2/20, Batch: 1050/1586, Loss: 1.0432\n",
      "Epoch: 2/20, Batch: 1100/1586, Loss: 1.0998\n",
      "Epoch: 2/20, Batch: 1150/1586, Loss: 1.0050\n",
      "Epoch: 2/20, Batch: 1200/1586, Loss: 1.1258\n",
      "Epoch: 2/20, Batch: 1250/1586, Loss: 0.8702\n",
      "Epoch: 2/20, Batch: 1300/1586, Loss: 0.8738\n",
      "Epoch: 2/20, Batch: 1350/1586, Loss: 1.0569\n",
      "Epoch: 2/20, Batch: 1400/1586, Loss: 1.0186\n",
      "Epoch: 2/20, Batch: 1450/1586, Loss: 0.8654\n",
      "Epoch: 2/20, Batch: 1500/1586, Loss: 1.4071\n",
      "Epoch: 2/20, Batch: 1550/1586, Loss: 1.0421\n",
      "Epoch: 2, Train Loss: 0.9847\n",
      "Epoch: 3/20, Batch: 0/1586, Loss: 1.1175\n",
      "Epoch: 3/20, Batch: 50/1586, Loss: 0.9410\n",
      "Epoch: 3/20, Batch: 100/1586, Loss: 1.0895\n",
      "Epoch: 3/20, Batch: 150/1586, Loss: 1.1106\n",
      "Epoch: 3/20, Batch: 200/1586, Loss: 1.1715\n",
      "Epoch: 3/20, Batch: 250/1586, Loss: 0.8217\n",
      "Epoch: 3/20, Batch: 300/1586, Loss: 0.6731\n",
      "Epoch: 3/20, Batch: 350/1586, Loss: 0.7902\n",
      "Epoch: 3/20, Batch: 400/1586, Loss: 0.7952\n",
      "Epoch: 3/20, Batch: 450/1586, Loss: 1.1869\n",
      "Epoch: 3/20, Batch: 500/1586, Loss: 1.1348\n",
      "Epoch: 3/20, Batch: 550/1586, Loss: 0.9273\n",
      "Epoch: 3/20, Batch: 600/1586, Loss: 0.8659\n",
      "Epoch: 3/20, Batch: 650/1586, Loss: 0.8734\n",
      "Epoch: 3/20, Batch: 700/1586, Loss: 0.7809\n",
      "Epoch: 3/20, Batch: 750/1586, Loss: 0.7901\n",
      "Epoch: 3/20, Batch: 800/1586, Loss: 0.9621\n",
      "Epoch: 3/20, Batch: 850/1586, Loss: 1.3331\n",
      "Epoch: 3/20, Batch: 900/1586, Loss: 0.9927\n",
      "Epoch: 3/20, Batch: 950/1586, Loss: 0.8095\n",
      "Epoch: 3/20, Batch: 1000/1586, Loss: 1.1381\n",
      "Epoch: 3/20, Batch: 1050/1586, Loss: 0.7670\n",
      "Epoch: 3/20, Batch: 1100/1586, Loss: 1.4914\n",
      "Epoch: 3/20, Batch: 1150/1586, Loss: 0.8678\n",
      "Epoch: 3/20, Batch: 1200/1586, Loss: 0.8049\n",
      "Epoch: 3/20, Batch: 1250/1586, Loss: 1.1295\n",
      "Epoch: 3/20, Batch: 1300/1586, Loss: 0.9581\n",
      "Epoch: 3/20, Batch: 1350/1586, Loss: 0.8528\n",
      "Epoch: 3/20, Batch: 1400/1586, Loss: 1.1172\n",
      "Epoch: 3/20, Batch: 1450/1586, Loss: 1.2052\n",
      "Epoch: 3/20, Batch: 1500/1586, Loss: 1.1908\n",
      "Epoch: 3/20, Batch: 1550/1586, Loss: 0.9998\n",
      "Epoch: 3, Train Loss: 0.9806\n",
      "Epoch: 4/20, Batch: 0/1586, Loss: 1.2529\n",
      "Epoch: 4/20, Batch: 50/1586, Loss: 0.8135\n",
      "Epoch: 4/20, Batch: 100/1586, Loss: 1.1405\n",
      "Epoch: 4/20, Batch: 150/1586, Loss: 0.8696\n",
      "Epoch: 4/20, Batch: 200/1586, Loss: 1.1929\n",
      "Epoch: 4/20, Batch: 250/1586, Loss: 0.9993\n",
      "Epoch: 4/20, Batch: 300/1586, Loss: 0.6410\n",
      "Epoch: 4/20, Batch: 350/1586, Loss: 1.0988\n",
      "Epoch: 4/20, Batch: 400/1586, Loss: 1.0890\n",
      "Epoch: 4/20, Batch: 450/1586, Loss: 1.1425\n",
      "Epoch: 4/20, Batch: 500/1586, Loss: 0.8043\n",
      "Epoch: 4/20, Batch: 550/1586, Loss: 0.9275\n",
      "Epoch: 4/20, Batch: 600/1586, Loss: 1.4217\n",
      "Epoch: 4/20, Batch: 650/1586, Loss: 0.8338\n",
      "Epoch: 4/20, Batch: 700/1586, Loss: 0.8144\n",
      "Epoch: 4/20, Batch: 750/1586, Loss: 1.0428\n",
      "Epoch: 4/20, Batch: 800/1586, Loss: 0.7935\n",
      "Epoch: 4/20, Batch: 850/1586, Loss: 0.9237\n",
      "Epoch: 4/20, Batch: 900/1586, Loss: 0.9535\n",
      "Epoch: 4/20, Batch: 950/1586, Loss: 0.7261\n",
      "Epoch: 4/20, Batch: 1000/1586, Loss: 0.9281\n",
      "Epoch: 4/20, Batch: 1050/1586, Loss: 0.8179\n",
      "Epoch: 4/20, Batch: 1100/1586, Loss: 0.9923\n",
      "Epoch: 4/20, Batch: 1150/1586, Loss: 0.9101\n",
      "Epoch: 4/20, Batch: 1200/1586, Loss: 1.4183\n",
      "Epoch: 4/20, Batch: 1250/1586, Loss: 0.8477\n",
      "Epoch: 4/20, Batch: 1300/1586, Loss: 0.9797\n",
      "Epoch: 4/20, Batch: 1350/1586, Loss: 0.9332\n",
      "Epoch: 4/20, Batch: 1400/1586, Loss: 0.8988\n",
      "Epoch: 4/20, Batch: 1450/1586, Loss: 1.0375\n",
      "Epoch: 4/20, Batch: 1500/1586, Loss: 1.0073\n",
      "Epoch: 4/20, Batch: 1550/1586, Loss: 1.0409\n",
      "Epoch: 4, Train Loss: 0.9762\n",
      "Epoch: 5/20, Batch: 0/1586, Loss: 0.9420\n",
      "Epoch: 5/20, Batch: 50/1586, Loss: 1.2686\n",
      "Epoch: 5/20, Batch: 100/1586, Loss: 1.0962\n",
      "Epoch: 5/20, Batch: 150/1586, Loss: 0.8646\n",
      "Epoch: 5/20, Batch: 200/1586, Loss: 1.2498\n",
      "Epoch: 5/20, Batch: 250/1586, Loss: 0.8494\n",
      "Epoch: 5/20, Batch: 300/1586, Loss: 0.7124\n",
      "Epoch: 5/20, Batch: 350/1586, Loss: 0.7487\n",
      "Epoch: 5/20, Batch: 400/1586, Loss: 1.0133\n",
      "Epoch: 5/20, Batch: 450/1586, Loss: 1.0870\n",
      "Epoch: 5/20, Batch: 500/1586, Loss: 0.8569\n",
      "Epoch: 5/20, Batch: 550/1586, Loss: 1.3199\n",
      "Epoch: 5/20, Batch: 600/1586, Loss: 0.8899\n",
      "Epoch: 5/20, Batch: 650/1586, Loss: 0.8533\n",
      "Epoch: 5/20, Batch: 700/1586, Loss: 0.9344\n",
      "Epoch: 5/20, Batch: 750/1586, Loss: 0.6996\n",
      "Epoch: 5/20, Batch: 800/1586, Loss: 1.0433\n",
      "Epoch: 5/20, Batch: 850/1586, Loss: 0.7227\n",
      "Epoch: 5/20, Batch: 900/1586, Loss: 0.9797\n",
      "Epoch: 5/20, Batch: 950/1586, Loss: 0.8152\n",
      "Epoch: 5/20, Batch: 1000/1586, Loss: 0.9348\n",
      "Epoch: 5/20, Batch: 1050/1586, Loss: 1.0974\n",
      "Epoch: 5/20, Batch: 1100/1586, Loss: 0.8410\n",
      "Epoch: 5/20, Batch: 1150/1586, Loss: 1.5303\n",
      "Epoch: 5/20, Batch: 1200/1586, Loss: 0.7993\n",
      "Epoch: 5/20, Batch: 1250/1586, Loss: 0.8464\n",
      "Epoch: 5/20, Batch: 1300/1586, Loss: 1.1463\n",
      "Epoch: 5/20, Batch: 1350/1586, Loss: 0.8310\n",
      "Epoch: 5/20, Batch: 1400/1586, Loss: 0.9173\n",
      "Epoch: 5/20, Batch: 1450/1586, Loss: 0.7430\n",
      "Epoch: 5/20, Batch: 1500/1586, Loss: 1.1963\n",
      "Epoch: 5/20, Batch: 1550/1586, Loss: 0.8423\n",
      "Epoch: 5, Train Loss: 0.9747\n",
      "Epoch: 6/20, Batch: 0/1586, Loss: 0.7414\n",
      "Epoch: 6/20, Batch: 50/1586, Loss: 1.2026\n",
      "Epoch: 6/20, Batch: 100/1586, Loss: 0.9567\n",
      "Epoch: 6/20, Batch: 150/1586, Loss: 0.9701\n",
      "Epoch: 6/20, Batch: 200/1586, Loss: 1.0139\n",
      "Epoch: 6/20, Batch: 250/1586, Loss: 0.9953\n",
      "Epoch: 6/20, Batch: 300/1586, Loss: 1.0517\n",
      "Epoch: 6/20, Batch: 350/1586, Loss: 1.3878\n",
      "Epoch: 6/20, Batch: 400/1586, Loss: 1.1887\n",
      "Epoch: 6/20, Batch: 450/1586, Loss: 1.1492\n",
      "Epoch: 6/20, Batch: 500/1586, Loss: 0.9952\n",
      "Epoch: 6/20, Batch: 550/1586, Loss: 0.8154\n",
      "Epoch: 6/20, Batch: 600/1586, Loss: 0.8994\n",
      "Epoch: 6/20, Batch: 650/1586, Loss: 0.7877\n",
      "Epoch: 6/20, Batch: 700/1586, Loss: 1.2246\n",
      "Epoch: 6/20, Batch: 750/1586, Loss: 0.9931\n",
      "Epoch: 6/20, Batch: 800/1586, Loss: 0.9478\n",
      "Epoch: 6/20, Batch: 850/1586, Loss: 1.2387\n",
      "Epoch: 6/20, Batch: 900/1586, Loss: 0.7448\n",
      "Epoch: 6/20, Batch: 950/1586, Loss: 0.7514\n",
      "Epoch: 6/20, Batch: 1000/1586, Loss: 0.9448\n",
      "Epoch: 6/20, Batch: 1050/1586, Loss: 1.3986\n",
      "Epoch: 6/20, Batch: 1100/1586, Loss: 0.6720\n",
      "Epoch: 6/20, Batch: 1150/1586, Loss: 0.9094\n",
      "Epoch: 6/20, Batch: 1200/1586, Loss: 1.3869\n",
      "Epoch: 6/20, Batch: 1250/1586, Loss: 0.8117\n",
      "Epoch: 6/20, Batch: 1300/1586, Loss: 1.2151\n",
      "Epoch: 6/20, Batch: 1350/1586, Loss: 0.9112\n",
      "Epoch: 6/20, Batch: 1400/1586, Loss: 0.6620\n",
      "Epoch: 6/20, Batch: 1450/1586, Loss: 0.9756\n",
      "Epoch: 6/20, Batch: 1500/1586, Loss: 0.9606\n",
      "Epoch: 6/20, Batch: 1550/1586, Loss: 1.0108\n",
      "Epoch: 6, Train Loss: 0.9741\n",
      "Epoch: 7/20, Batch: 0/1586, Loss: 0.9231\n",
      "Epoch: 7/20, Batch: 50/1586, Loss: 0.9042\n",
      "Epoch: 7/20, Batch: 100/1586, Loss: 0.9157\n",
      "Epoch: 7/20, Batch: 150/1586, Loss: 1.2767\n",
      "Epoch: 7/20, Batch: 200/1586, Loss: 0.8330\n",
      "Epoch: 7/20, Batch: 250/1586, Loss: 1.1241\n",
      "Epoch: 7/20, Batch: 300/1586, Loss: 1.1092\n",
      "Epoch: 7/20, Batch: 350/1586, Loss: 1.2405\n",
      "Epoch: 7/20, Batch: 400/1586, Loss: 1.0119\n",
      "Epoch: 7/20, Batch: 450/1586, Loss: 0.7931\n",
      "Epoch: 7/20, Batch: 500/1586, Loss: 1.1090\n",
      "Epoch: 7/20, Batch: 550/1586, Loss: 0.9562\n",
      "Epoch: 7/20, Batch: 600/1586, Loss: 1.1455\n",
      "Epoch: 7/20, Batch: 650/1586, Loss: 0.8715\n",
      "Epoch: 7/20, Batch: 700/1586, Loss: 0.9067\n",
      "Epoch: 7/20, Batch: 750/1586, Loss: 1.0569\n",
      "Epoch: 7/20, Batch: 800/1586, Loss: 1.1636\n",
      "Epoch: 7/20, Batch: 850/1586, Loss: 0.9412\n",
      "Epoch: 7/20, Batch: 900/1586, Loss: 1.3392\n",
      "Epoch: 7/20, Batch: 950/1586, Loss: 0.8375\n",
      "Epoch: 7/20, Batch: 1000/1586, Loss: 0.7749\n",
      "Epoch: 7/20, Batch: 1050/1586, Loss: 1.1958\n",
      "Epoch: 7/20, Batch: 1100/1586, Loss: 0.7912\n",
      "Epoch: 7/20, Batch: 1150/1586, Loss: 0.9381\n",
      "Epoch: 7/20, Batch: 1200/1586, Loss: 0.7587\n",
      "Epoch: 7/20, Batch: 1250/1586, Loss: 0.9816\n",
      "Epoch: 7/20, Batch: 1300/1586, Loss: 1.2256\n",
      "Epoch: 7/20, Batch: 1350/1586, Loss: 1.3092\n",
      "Epoch: 7/20, Batch: 1400/1586, Loss: 0.7901\n",
      "Epoch: 7/20, Batch: 1450/1586, Loss: 0.7566\n",
      "Epoch: 7/20, Batch: 1500/1586, Loss: 0.9149\n",
      "Epoch: 7/20, Batch: 1550/1586, Loss: 0.7658\n",
      "Epoch: 7, Train Loss: 0.9726\n",
      "Epoch: 8/20, Batch: 0/1586, Loss: 0.8268\n",
      "Epoch: 8/20, Batch: 50/1586, Loss: 1.0594\n",
      "Epoch: 8/20, Batch: 100/1586, Loss: 0.7018\n",
      "Epoch: 8/20, Batch: 150/1586, Loss: 0.8757\n",
      "Epoch: 8/20, Batch: 200/1586, Loss: 0.8693\n",
      "Epoch: 8/20, Batch: 250/1586, Loss: 0.8512\n",
      "Epoch: 8/20, Batch: 300/1586, Loss: 0.9380\n",
      "Epoch: 8/20, Batch: 350/1586, Loss: 1.1994\n",
      "Epoch: 8/20, Batch: 400/1586, Loss: 1.0604\n",
      "Epoch: 8/20, Batch: 450/1586, Loss: 1.0389\n",
      "Epoch: 8/20, Batch: 500/1586, Loss: 0.7867\n",
      "Epoch: 8/20, Batch: 550/1586, Loss: 0.8416\n",
      "Epoch: 8/20, Batch: 600/1586, Loss: 0.7530\n",
      "Epoch: 8/20, Batch: 650/1586, Loss: 0.8267\n",
      "Epoch: 8/20, Batch: 700/1586, Loss: 0.9493\n",
      "Epoch: 8/20, Batch: 750/1586, Loss: 0.6766\n",
      "Epoch: 8/20, Batch: 800/1586, Loss: 0.9460\n",
      "Epoch: 8/20, Batch: 850/1586, Loss: 0.8569\n",
      "Epoch: 8/20, Batch: 900/1586, Loss: 0.8498\n",
      "Epoch: 8/20, Batch: 950/1586, Loss: 0.7375\n",
      "Epoch: 8/20, Batch: 1000/1586, Loss: 0.8827\n",
      "Epoch: 8/20, Batch: 1050/1586, Loss: 0.9481\n",
      "Epoch: 8/20, Batch: 1100/1586, Loss: 0.9198\n",
      "Epoch: 8/20, Batch: 1150/1586, Loss: 0.7833\n",
      "Epoch: 8/20, Batch: 1200/1586, Loss: 1.2702\n",
      "Epoch: 8/20, Batch: 1250/1586, Loss: 1.3705\n",
      "Epoch: 8/20, Batch: 1300/1586, Loss: 0.9328\n",
      "Epoch: 8/20, Batch: 1350/1586, Loss: 0.8268\n",
      "Epoch: 8/20, Batch: 1400/1586, Loss: 1.2058\n",
      "Epoch: 8/20, Batch: 1450/1586, Loss: 0.9352\n",
      "Epoch: 8/20, Batch: 1500/1586, Loss: 0.9859\n",
      "Epoch: 8/20, Batch: 1550/1586, Loss: 1.0335\n",
      "Epoch: 8, Train Loss: 0.9703\n",
      "Epoch: 9/20, Batch: 0/1586, Loss: 1.0248\n",
      "Epoch: 9/20, Batch: 50/1586, Loss: 0.9954\n",
      "Epoch: 9/20, Batch: 100/1586, Loss: 0.8244\n",
      "Epoch: 9/20, Batch: 150/1586, Loss: 0.9050\n",
      "Epoch: 9/20, Batch: 200/1586, Loss: 1.0262\n",
      "Epoch: 9/20, Batch: 250/1586, Loss: 0.7988\n",
      "Epoch: 9/20, Batch: 300/1586, Loss: 0.6823\n",
      "Epoch: 9/20, Batch: 350/1586, Loss: 0.8220\n",
      "Epoch: 9/20, Batch: 400/1586, Loss: 1.0156\n",
      "Epoch: 9/20, Batch: 450/1586, Loss: 1.1805\n",
      "Epoch: 9/20, Batch: 500/1586, Loss: 1.2016\n",
      "Epoch: 9/20, Batch: 550/1586, Loss: 0.9933\n",
      "Epoch: 9/20, Batch: 600/1586, Loss: 1.1200\n",
      "Epoch: 9/20, Batch: 650/1586, Loss: 0.7541\n",
      "Epoch: 9/20, Batch: 700/1586, Loss: 0.7453\n",
      "Epoch: 9/20, Batch: 750/1586, Loss: 0.7517\n",
      "Epoch: 9/20, Batch: 800/1586, Loss: 0.9173\n",
      "Epoch: 9/20, Batch: 850/1586, Loss: 0.9644\n",
      "Epoch: 9/20, Batch: 900/1586, Loss: 0.7696\n",
      "Epoch: 9/20, Batch: 950/1586, Loss: 0.7911\n",
      "Epoch: 9/20, Batch: 1000/1586, Loss: 0.9823\n",
      "Epoch: 9/20, Batch: 1050/1586, Loss: 1.1766\n",
      "Epoch: 9/20, Batch: 1100/1586, Loss: 0.8885\n",
      "Epoch: 9/20, Batch: 1150/1586, Loss: 0.8304\n",
      "Epoch: 9/20, Batch: 1200/1586, Loss: 1.2945\n",
      "Epoch: 9/20, Batch: 1250/1586, Loss: 0.8791\n",
      "Epoch: 9/20, Batch: 1300/1586, Loss: 1.3724\n",
      "Epoch: 9/20, Batch: 1350/1586, Loss: 1.1328\n",
      "Epoch: 9/20, Batch: 1400/1586, Loss: 0.8742\n",
      "Epoch: 9/20, Batch: 1450/1586, Loss: 1.0263\n",
      "Epoch: 9/20, Batch: 1500/1586, Loss: 1.1847\n",
      "Epoch: 9/20, Batch: 1550/1586, Loss: 0.9145\n",
      "Epoch: 9, Train Loss: 0.9702\n",
      "Epoch: 10/20, Batch: 0/1586, Loss: 0.7429\n",
      "Epoch: 10/20, Batch: 50/1586, Loss: 0.8023\n",
      "Epoch: 10/20, Batch: 100/1586, Loss: 0.8915\n",
      "Epoch: 10/20, Batch: 150/1586, Loss: 1.2605\n",
      "Epoch: 10/20, Batch: 200/1586, Loss: 0.8784\n",
      "Epoch: 10/20, Batch: 250/1586, Loss: 0.7756\n",
      "Epoch: 10/20, Batch: 300/1586, Loss: 0.8006\n",
      "Epoch: 10/20, Batch: 350/1586, Loss: 1.0830\n",
      "Epoch: 10/20, Batch: 400/1586, Loss: 0.8688\n",
      "Epoch: 10/20, Batch: 450/1586, Loss: 1.0814\n",
      "Epoch: 10/20, Batch: 500/1586, Loss: 0.8735\n",
      "Epoch: 10/20, Batch: 550/1586, Loss: 1.0738\n",
      "Epoch: 10/20, Batch: 600/1586, Loss: 1.0276\n",
      "Epoch: 10/20, Batch: 650/1586, Loss: 1.1648\n",
      "Epoch: 10/20, Batch: 700/1586, Loss: 0.6621\n",
      "Epoch: 10/20, Batch: 750/1586, Loss: 0.8162\n",
      "Epoch: 10/20, Batch: 800/1586, Loss: 0.8538\n",
      "Epoch: 10/20, Batch: 850/1586, Loss: 1.0197\n",
      "Epoch: 10/20, Batch: 900/1586, Loss: 1.1116\n",
      "Epoch: 10/20, Batch: 950/1586, Loss: 1.0662\n",
      "Epoch: 10/20, Batch: 1000/1586, Loss: 1.1571\n",
      "Epoch: 10/20, Batch: 1050/1586, Loss: 0.7483\n",
      "Epoch: 10/20, Batch: 1100/1586, Loss: 0.8964\n",
      "Epoch: 10/20, Batch: 1150/1586, Loss: 0.9504\n",
      "Epoch: 10/20, Batch: 1200/1586, Loss: 1.0059\n",
      "Epoch: 10/20, Batch: 1250/1586, Loss: 1.1238\n",
      "Epoch: 10/20, Batch: 1300/1586, Loss: 1.1353\n",
      "Epoch: 10/20, Batch: 1350/1586, Loss: 1.0118\n",
      "Epoch: 10/20, Batch: 1400/1586, Loss: 1.1425\n",
      "Epoch: 10/20, Batch: 1450/1586, Loss: 0.9359\n",
      "Epoch: 10/20, Batch: 1500/1586, Loss: 0.7420\n",
      "Epoch: 10/20, Batch: 1550/1586, Loss: 1.0286\n",
      "Epoch: 10, Train Loss: 0.9694\n",
      "Epoch: 11/20, Batch: 0/1586, Loss: 0.7747\n",
      "Epoch: 11/20, Batch: 50/1586, Loss: 0.7346\n",
      "Epoch: 11/20, Batch: 100/1586, Loss: 1.0753\n",
      "Epoch: 11/20, Batch: 150/1586, Loss: 1.1262\n",
      "Epoch: 11/20, Batch: 200/1586, Loss: 1.0328\n",
      "Epoch: 11/20, Batch: 250/1586, Loss: 1.0009\n",
      "Epoch: 11/20, Batch: 300/1586, Loss: 0.7492\n",
      "Epoch: 11/20, Batch: 350/1586, Loss: 0.9997\n",
      "Epoch: 11/20, Batch: 400/1586, Loss: 0.8733\n",
      "Epoch: 11/20, Batch: 450/1586, Loss: 1.2263\n",
      "Epoch: 11/20, Batch: 500/1586, Loss: 0.9329\n",
      "Epoch: 11/20, Batch: 550/1586, Loss: 1.0834\n",
      "Epoch: 11/20, Batch: 600/1586, Loss: 0.8025\n",
      "Epoch: 11/20, Batch: 650/1586, Loss: 0.7825\n",
      "Epoch: 11/20, Batch: 700/1586, Loss: 1.1517\n",
      "Epoch: 11/20, Batch: 750/1586, Loss: 0.7404\n",
      "Epoch: 11/20, Batch: 800/1586, Loss: 1.2746\n",
      "Epoch: 11/20, Batch: 850/1586, Loss: 0.8144\n",
      "Epoch: 11/20, Batch: 900/1586, Loss: 0.9639\n",
      "Epoch: 11/20, Batch: 950/1586, Loss: 1.0384\n",
      "Epoch: 11/20, Batch: 1000/1586, Loss: 0.8034\n",
      "Epoch: 11/20, Batch: 1050/1586, Loss: 0.8872\n",
      "Epoch: 11/20, Batch: 1100/1586, Loss: 0.7494\n",
      "Epoch: 11/20, Batch: 1150/1586, Loss: 0.8575\n",
      "Epoch: 11/20, Batch: 1200/1586, Loss: 0.9343\n",
      "Epoch: 11/20, Batch: 1250/1586, Loss: 0.9407\n",
      "Epoch: 11/20, Batch: 1300/1586, Loss: 0.9487\n",
      "Epoch: 11/20, Batch: 1350/1586, Loss: 0.8942\n",
      "Epoch: 11/20, Batch: 1400/1586, Loss: 0.9643\n",
      "Epoch: 11/20, Batch: 1450/1586, Loss: 1.0147\n",
      "Epoch: 11/20, Batch: 1500/1586, Loss: 1.1233\n",
      "Epoch: 11/20, Batch: 1550/1586, Loss: 1.1857\n",
      "Epoch: 11, Train Loss: 0.9682\n",
      "Epoch: 12/20, Batch: 0/1586, Loss: 0.8390\n",
      "Epoch: 12/20, Batch: 50/1586, Loss: 0.7148\n",
      "Epoch: 12/20, Batch: 100/1586, Loss: 1.2801\n",
      "Epoch: 12/20, Batch: 150/1586, Loss: 0.9304\n",
      "Epoch: 12/20, Batch: 200/1586, Loss: 0.7667\n",
      "Epoch: 12/20, Batch: 250/1586, Loss: 0.9145\n",
      "Epoch: 12/20, Batch: 300/1586, Loss: 1.2035\n",
      "Epoch: 12/20, Batch: 350/1586, Loss: 1.2901\n",
      "Epoch: 12/20, Batch: 400/1586, Loss: 0.6368\n",
      "Epoch: 12/20, Batch: 450/1586, Loss: 0.9263\n",
      "Epoch: 12/20, Batch: 500/1586, Loss: 1.0431\n",
      "Epoch: 12/20, Batch: 550/1586, Loss: 0.8554\n",
      "Epoch: 12/20, Batch: 600/1586, Loss: 0.8538\n",
      "Epoch: 12/20, Batch: 650/1586, Loss: 0.6934\n",
      "Epoch: 12/20, Batch: 700/1586, Loss: 0.9474\n",
      "Epoch: 12/20, Batch: 750/1586, Loss: 0.7816\n",
      "Epoch: 12/20, Batch: 800/1586, Loss: 0.8656\n",
      "Epoch: 12/20, Batch: 850/1586, Loss: 0.9965\n",
      "Epoch: 12/20, Batch: 900/1586, Loss: 1.2670\n",
      "Epoch: 12/20, Batch: 950/1586, Loss: 1.2234\n",
      "Epoch: 12/20, Batch: 1000/1586, Loss: 0.7156\n",
      "Epoch: 12/20, Batch: 1050/1586, Loss: 0.7634\n",
      "Epoch: 12/20, Batch: 1100/1586, Loss: 1.0401\n",
      "Epoch: 12/20, Batch: 1150/1586, Loss: 1.1858\n",
      "Epoch: 12/20, Batch: 1200/1586, Loss: 1.0351\n",
      "Epoch: 12/20, Batch: 1250/1586, Loss: 0.9047\n",
      "Epoch: 12/20, Batch: 1300/1586, Loss: 1.2293\n",
      "Epoch: 12/20, Batch: 1350/1586, Loss: 1.3492\n",
      "Epoch: 12/20, Batch: 1400/1586, Loss: 0.8505\n",
      "Epoch: 12/20, Batch: 1450/1586, Loss: 0.9951\n",
      "Epoch: 12/20, Batch: 1500/1586, Loss: 0.8910\n",
      "Epoch: 12/20, Batch: 1550/1586, Loss: 1.3917\n",
      "Epoch: 12, Train Loss: 0.9676\n",
      "Epoch: 13/20, Batch: 0/1586, Loss: 1.0011\n",
      "Epoch: 13/20, Batch: 50/1586, Loss: 1.1234\n",
      "Epoch: 13/20, Batch: 100/1586, Loss: 0.7626\n",
      "Epoch: 13/20, Batch: 150/1586, Loss: 0.7434\n",
      "Epoch: 13/20, Batch: 200/1586, Loss: 1.3723\n",
      "Epoch: 13/20, Batch: 250/1586, Loss: 0.8510\n",
      "Epoch: 13/20, Batch: 300/1586, Loss: 0.9399\n",
      "Epoch: 13/20, Batch: 350/1586, Loss: 1.1911\n",
      "Epoch: 13/20, Batch: 400/1586, Loss: 0.6531\n",
      "Epoch: 13/20, Batch: 450/1586, Loss: 0.8549\n",
      "Epoch: 13/20, Batch: 500/1586, Loss: 1.0312\n",
      "Epoch: 13/20, Batch: 550/1586, Loss: 1.0145\n",
      "Epoch: 13/20, Batch: 600/1586, Loss: 0.9700\n",
      "Epoch: 13/20, Batch: 650/1586, Loss: 0.8008\n",
      "Epoch: 13/20, Batch: 700/1586, Loss: 0.9486\n",
      "Epoch: 13/20, Batch: 750/1586, Loss: 0.9111\n",
      "Epoch: 13/20, Batch: 800/1586, Loss: 0.8095\n",
      "Epoch: 13/20, Batch: 850/1586, Loss: 0.9965\n",
      "Epoch: 13/20, Batch: 900/1586, Loss: 0.7624\n",
      "Epoch: 13/20, Batch: 950/1586, Loss: 0.8054\n",
      "Epoch: 13/20, Batch: 1000/1586, Loss: 0.9662\n",
      "Epoch: 13/20, Batch: 1050/1586, Loss: 0.7183\n",
      "Epoch: 13/20, Batch: 1100/1586, Loss: 0.7739\n",
      "Epoch: 13/20, Batch: 1150/1586, Loss: 1.0000\n",
      "Epoch: 13/20, Batch: 1200/1586, Loss: 1.1417\n",
      "Epoch: 13/20, Batch: 1250/1586, Loss: 0.8976\n",
      "Epoch: 13/20, Batch: 1300/1586, Loss: 0.9713\n",
      "Epoch: 13/20, Batch: 1350/1586, Loss: 1.0682\n",
      "Epoch: 13/20, Batch: 1400/1586, Loss: 0.6149\n",
      "Epoch: 13/20, Batch: 1450/1586, Loss: 0.7184\n",
      "Epoch: 13/20, Batch: 1500/1586, Loss: 0.9856\n",
      "Epoch: 13/20, Batch: 1550/1586, Loss: 0.8673\n",
      "Epoch: 13, Train Loss: 0.9671\n",
      "Epoch: 14/20, Batch: 0/1586, Loss: 0.6187\n",
      "Epoch: 14/20, Batch: 50/1586, Loss: 1.1685\n",
      "Epoch: 14/20, Batch: 100/1586, Loss: 1.0190\n",
      "Epoch: 14/20, Batch: 150/1586, Loss: 1.0119\n",
      "Epoch: 14/20, Batch: 200/1586, Loss: 1.1242\n",
      "Epoch: 14/20, Batch: 250/1586, Loss: 1.0386\n",
      "Epoch: 14/20, Batch: 300/1586, Loss: 0.8174\n",
      "Epoch: 14/20, Batch: 350/1586, Loss: 1.6715\n",
      "Epoch: 14/20, Batch: 400/1586, Loss: 0.6910\n",
      "Epoch: 14/20, Batch: 450/1586, Loss: 0.9498\n",
      "Epoch: 14/20, Batch: 500/1586, Loss: 0.6595\n",
      "Epoch: 14/20, Batch: 550/1586, Loss: 1.1912\n",
      "Epoch: 14/20, Batch: 600/1586, Loss: 0.9296\n",
      "Epoch: 14/20, Batch: 650/1586, Loss: 0.9553\n",
      "Epoch: 14/20, Batch: 700/1586, Loss: 1.0732\n",
      "Epoch: 14/20, Batch: 750/1586, Loss: 0.7022\n",
      "Epoch: 14/20, Batch: 800/1586, Loss: 0.8856\n",
      "Epoch: 14/20, Batch: 850/1586, Loss: 1.3170\n",
      "Epoch: 14/20, Batch: 900/1586, Loss: 0.9160\n",
      "Epoch: 14/20, Batch: 950/1586, Loss: 0.7329\n",
      "Epoch: 14/20, Batch: 1000/1586, Loss: 1.2096\n",
      "Epoch: 14/20, Batch: 1050/1586, Loss: 1.4982\n",
      "Epoch: 14/20, Batch: 1100/1586, Loss: 0.8885\n",
      "Epoch: 14/20, Batch: 1150/1586, Loss: 0.9050\n",
      "Epoch: 14/20, Batch: 1200/1586, Loss: 1.0526\n",
      "Epoch: 14/20, Batch: 1250/1586, Loss: 0.9476\n",
      "Epoch: 14/20, Batch: 1300/1586, Loss: 1.3037\n",
      "Epoch: 14/20, Batch: 1350/1586, Loss: 0.8452\n",
      "Epoch: 14/20, Batch: 1400/1586, Loss: 0.7978\n",
      "Epoch: 14/20, Batch: 1450/1586, Loss: 1.1109\n",
      "Epoch: 14/20, Batch: 1500/1586, Loss: 1.0071\n",
      "Epoch: 14/20, Batch: 1550/1586, Loss: 0.9040\n",
      "Epoch: 14, Train Loss: 0.9670\n",
      "Epoch: 15/20, Batch: 0/1586, Loss: 0.7859\n",
      "Epoch: 15/20, Batch: 50/1586, Loss: 0.8853\n",
      "Epoch: 15/20, Batch: 100/1586, Loss: 1.0595\n",
      "Epoch: 15/20, Batch: 150/1586, Loss: 0.9183\n",
      "Epoch: 15/20, Batch: 200/1586, Loss: 0.8822\n",
      "Epoch: 15/20, Batch: 250/1586, Loss: 1.1447\n",
      "Epoch: 15/20, Batch: 300/1586, Loss: 0.9925\n",
      "Epoch: 15/20, Batch: 350/1586, Loss: 1.1119\n",
      "Epoch: 15/20, Batch: 400/1586, Loss: 0.8123\n",
      "Epoch: 15/20, Batch: 450/1586, Loss: 1.2926\n",
      "Epoch: 15/20, Batch: 500/1586, Loss: 0.7876\n",
      "Epoch: 15/20, Batch: 550/1586, Loss: 0.8577\n",
      "Epoch: 15/20, Batch: 600/1586, Loss: 1.5579\n",
      "Epoch: 15/20, Batch: 650/1586, Loss: 1.1496\n",
      "Epoch: 15/20, Batch: 700/1586, Loss: 1.0538\n",
      "Epoch: 15/20, Batch: 750/1586, Loss: 0.7263\n",
      "Epoch: 15/20, Batch: 800/1586, Loss: 0.6718\n",
      "Epoch: 15/20, Batch: 850/1586, Loss: 1.3508\n",
      "Epoch: 15/20, Batch: 900/1586, Loss: 0.8993\n",
      "Epoch: 15/20, Batch: 950/1586, Loss: 1.3031\n",
      "Epoch: 15/20, Batch: 1000/1586, Loss: 1.3287\n",
      "Epoch: 15/20, Batch: 1050/1586, Loss: 0.7951\n",
      "Epoch: 15/20, Batch: 1100/1586, Loss: 0.9700\n",
      "Epoch: 15/20, Batch: 1150/1586, Loss: 0.9448\n",
      "Epoch: 15/20, Batch: 1200/1586, Loss: 1.0991\n",
      "Epoch: 15/20, Batch: 1250/1586, Loss: 0.7292\n",
      "Epoch: 15/20, Batch: 1300/1586, Loss: 1.0183\n",
      "Epoch: 15/20, Batch: 1350/1586, Loss: 1.1699\n",
      "Epoch: 15/20, Batch: 1400/1586, Loss: 1.0243\n",
      "Epoch: 15/20, Batch: 1450/1586, Loss: 1.2472\n",
      "Epoch: 15/20, Batch: 1500/1586, Loss: 0.7687\n",
      "Epoch: 15/20, Batch: 1550/1586, Loss: 0.8824\n",
      "Epoch: 15, Train Loss: 0.9642\n",
      "Epoch: 16/20, Batch: 0/1586, Loss: 1.2246\n",
      "Epoch: 16/20, Batch: 50/1586, Loss: 0.7891\n",
      "Epoch: 16/20, Batch: 100/1586, Loss: 0.6765\n",
      "Epoch: 16/20, Batch: 150/1586, Loss: 0.9066\n",
      "Epoch: 16/20, Batch: 200/1586, Loss: 0.6534\n",
      "Epoch: 16/20, Batch: 250/1586, Loss: 0.8224\n",
      "Epoch: 16/20, Batch: 300/1586, Loss: 1.1812\n",
      "Epoch: 16/20, Batch: 350/1586, Loss: 1.1031\n",
      "Epoch: 16/20, Batch: 400/1586, Loss: 1.0492\n",
      "Epoch: 16/20, Batch: 450/1586, Loss: 1.0874\n",
      "Epoch: 16/20, Batch: 500/1586, Loss: 1.4925\n",
      "Epoch: 16/20, Batch: 550/1586, Loss: 1.1899\n",
      "Epoch: 16/20, Batch: 600/1586, Loss: 1.0793\n",
      "Epoch: 16/20, Batch: 650/1586, Loss: 0.7406\n",
      "Epoch: 16/20, Batch: 700/1586, Loss: 1.0791\n",
      "Epoch: 16/20, Batch: 750/1586, Loss: 1.2919\n",
      "Epoch: 16/20, Batch: 800/1586, Loss: 1.0479\n",
      "Epoch: 16/20, Batch: 850/1586, Loss: 0.7772\n",
      "Epoch: 16/20, Batch: 900/1586, Loss: 0.8288\n",
      "Epoch: 16/20, Batch: 950/1586, Loss: 1.0720\n",
      "Epoch: 16/20, Batch: 1000/1586, Loss: 0.8119\n",
      "Epoch: 16/20, Batch: 1050/1586, Loss: 1.2597\n",
      "Epoch: 16/20, Batch: 1100/1586, Loss: 0.8929\n",
      "Epoch: 16/20, Batch: 1150/1586, Loss: 1.1467\n",
      "Epoch: 16/20, Batch: 1200/1586, Loss: 0.9980\n",
      "Epoch: 16/20, Batch: 1250/1586, Loss: 1.2026\n",
      "Epoch: 16/20, Batch: 1300/1586, Loss: 1.4005\n",
      "Epoch: 16/20, Batch: 1350/1586, Loss: 0.9989\n",
      "Epoch: 16/20, Batch: 1400/1586, Loss: 0.9858\n",
      "Epoch: 16/20, Batch: 1450/1586, Loss: 1.0960\n",
      "Epoch: 16/20, Batch: 1500/1586, Loss: 0.8777\n",
      "Epoch: 16/20, Batch: 1550/1586, Loss: 0.9008\n",
      "Epoch: 16, Train Loss: 0.9666\n",
      "Epoch: 17/20, Batch: 0/1586, Loss: 0.9192\n",
      "Epoch: 17/20, Batch: 50/1586, Loss: 0.6617\n",
      "Epoch: 17/20, Batch: 100/1586, Loss: 1.1604\n",
      "Epoch: 17/20, Batch: 150/1586, Loss: 0.9267\n",
      "Epoch: 17/20, Batch: 200/1586, Loss: 0.7519\n",
      "Epoch: 17/20, Batch: 250/1586, Loss: 0.7627\n",
      "Epoch: 17/20, Batch: 300/1586, Loss: 0.8967\n",
      "Epoch: 17/20, Batch: 350/1586, Loss: 0.9685\n",
      "Epoch: 17/20, Batch: 400/1586, Loss: 1.2420\n",
      "Epoch: 17/20, Batch: 450/1586, Loss: 0.8334\n",
      "Epoch: 17/20, Batch: 500/1586, Loss: 1.2795\n",
      "Epoch: 17/20, Batch: 550/1586, Loss: 1.1833\n",
      "Epoch: 17/20, Batch: 600/1586, Loss: 0.8174\n",
      "Epoch: 17/20, Batch: 650/1586, Loss: 1.5470\n",
      "Epoch: 17/20, Batch: 700/1586, Loss: 0.8226\n",
      "Epoch: 17/20, Batch: 750/1586, Loss: 0.9390\n",
      "Epoch: 17/20, Batch: 800/1586, Loss: 1.1415\n",
      "Epoch: 17/20, Batch: 850/1586, Loss: 1.0131\n",
      "Epoch: 17/20, Batch: 900/1586, Loss: 0.8626\n",
      "Epoch: 17/20, Batch: 950/1586, Loss: 1.1488\n",
      "Epoch: 17/20, Batch: 1000/1586, Loss: 0.9701\n",
      "Epoch: 17/20, Batch: 1050/1586, Loss: 0.7636\n",
      "Epoch: 17/20, Batch: 1100/1586, Loss: 0.8693\n",
      "Epoch: 17/20, Batch: 1150/1586, Loss: 0.8191\n",
      "Epoch: 17/20, Batch: 1200/1586, Loss: 1.4566\n",
      "Epoch: 17/20, Batch: 1250/1586, Loss: 0.8309\n",
      "Epoch: 17/20, Batch: 1300/1586, Loss: 0.9253\n",
      "Epoch: 17/20, Batch: 1350/1586, Loss: 0.7897\n",
      "Epoch: 17/20, Batch: 1400/1586, Loss: 1.1952\n",
      "Epoch: 17/20, Batch: 1450/1586, Loss: 0.8882\n",
      "Epoch: 17/20, Batch: 1500/1586, Loss: 1.1489\n",
      "Epoch: 17/20, Batch: 1550/1586, Loss: 0.8263\n",
      "Epoch: 17, Train Loss: 0.9657\n",
      "Epoch: 18/20, Batch: 0/1586, Loss: 0.7740\n",
      "Epoch: 18/20, Batch: 50/1586, Loss: 0.9287\n",
      "Epoch: 18/20, Batch: 100/1586, Loss: 0.7074\n",
      "Epoch: 18/20, Batch: 150/1586, Loss: 1.1967\n",
      "Epoch: 18/20, Batch: 200/1586, Loss: 1.0015\n",
      "Epoch: 18/20, Batch: 250/1586, Loss: 0.8473\n",
      "Epoch: 18/20, Batch: 300/1586, Loss: 0.8921\n",
      "Epoch: 18/20, Batch: 350/1586, Loss: 1.1519\n",
      "Epoch: 18/20, Batch: 400/1586, Loss: 0.9896\n",
      "Epoch: 18/20, Batch: 450/1586, Loss: 0.7912\n",
      "Epoch: 18/20, Batch: 500/1586, Loss: 0.9661\n",
      "Epoch: 18/20, Batch: 550/1586, Loss: 0.7097\n",
      "Epoch: 18/20, Batch: 600/1586, Loss: 0.9042\n",
      "Epoch: 18/20, Batch: 650/1586, Loss: 1.0680\n",
      "Epoch: 18/20, Batch: 700/1586, Loss: 1.3902\n",
      "Epoch: 18/20, Batch: 750/1586, Loss: 0.9004\n",
      "Epoch: 18/20, Batch: 800/1586, Loss: 1.0815\n",
      "Epoch: 18/20, Batch: 850/1586, Loss: 0.8609\n",
      "Epoch: 18/20, Batch: 900/1586, Loss: 0.6378\n",
      "Epoch: 18/20, Batch: 950/1586, Loss: 0.7583\n",
      "Epoch: 18/20, Batch: 1000/1586, Loss: 0.7733\n",
      "Epoch: 18/20, Batch: 1050/1586, Loss: 0.9307\n",
      "Epoch: 18/20, Batch: 1100/1586, Loss: 0.7686\n",
      "Epoch: 18/20, Batch: 1150/1586, Loss: 0.7946\n",
      "Epoch: 18/20, Batch: 1200/1586, Loss: 0.7989\n",
      "Epoch: 18/20, Batch: 1250/1586, Loss: 1.0469\n",
      "Epoch: 18/20, Batch: 1300/1586, Loss: 0.7568\n",
      "Epoch: 18/20, Batch: 1350/1586, Loss: 1.2375\n",
      "Epoch: 18/20, Batch: 1400/1586, Loss: 1.0770\n",
      "Epoch: 18/20, Batch: 1450/1586, Loss: 0.9205\n",
      "Epoch: 18/20, Batch: 1500/1586, Loss: 1.3087\n",
      "Epoch: 18/20, Batch: 1550/1586, Loss: 0.8066\n",
      "Epoch: 18, Train Loss: 0.9652\n",
      "Epoch: 19/20, Batch: 0/1586, Loss: 0.7863\n",
      "Epoch: 19/20, Batch: 50/1586, Loss: 0.7732\n",
      "Epoch: 19/20, Batch: 100/1586, Loss: 1.1878\n",
      "Epoch: 19/20, Batch: 150/1586, Loss: 0.9550\n",
      "Epoch: 19/20, Batch: 200/1586, Loss: 0.8056\n",
      "Epoch: 19/20, Batch: 250/1586, Loss: 0.8925\n",
      "Epoch: 19/20, Batch: 300/1586, Loss: 1.0994\n",
      "Epoch: 19/20, Batch: 350/1586, Loss: 0.8999\n",
      "Epoch: 19/20, Batch: 400/1586, Loss: 0.8721\n",
      "Epoch: 19/20, Batch: 450/1586, Loss: 0.7598\n",
      "Epoch: 19/20, Batch: 500/1586, Loss: 0.8120\n",
      "Epoch: 19/20, Batch: 550/1586, Loss: 0.8636\n",
      "Epoch: 19/20, Batch: 600/1586, Loss: 1.3661\n",
      "Epoch: 19/20, Batch: 650/1586, Loss: 0.7945\n",
      "Epoch: 19/20, Batch: 700/1586, Loss: 0.9920\n",
      "Epoch: 19/20, Batch: 750/1586, Loss: 1.1302\n",
      "Epoch: 19/20, Batch: 800/1586, Loss: 0.9507\n",
      "Epoch: 19/20, Batch: 850/1586, Loss: 0.8733\n",
      "Epoch: 19/20, Batch: 900/1586, Loss: 0.9429\n",
      "Epoch: 19/20, Batch: 950/1586, Loss: 0.8495\n",
      "Epoch: 19/20, Batch: 1000/1586, Loss: 0.8376\n",
      "Epoch: 19/20, Batch: 1050/1586, Loss: 0.8010\n",
      "Epoch: 19/20, Batch: 1100/1586, Loss: 0.8806\n",
      "Epoch: 19/20, Batch: 1150/1586, Loss: 0.9177\n",
      "Epoch: 19/20, Batch: 1200/1586, Loss: 0.8849\n",
      "Epoch: 19/20, Batch: 1250/1586, Loss: 1.2300\n",
      "Epoch: 19/20, Batch: 1300/1586, Loss: 0.8362\n",
      "Epoch: 19/20, Batch: 1350/1586, Loss: 1.1811\n",
      "Epoch: 19/20, Batch: 1400/1586, Loss: 0.7923\n",
      "Epoch: 19/20, Batch: 1450/1586, Loss: 0.8464\n",
      "Epoch: 19/20, Batch: 1500/1586, Loss: 1.0176\n",
      "Epoch: 19/20, Batch: 1550/1586, Loss: 0.8201\n",
      "Epoch: 19, Train Loss: 0.9649\n",
      "Epoch: 20/20, Batch: 0/1586, Loss: 1.0659\n",
      "Epoch: 20/20, Batch: 50/1586, Loss: 0.8530\n",
      "Epoch: 20/20, Batch: 100/1586, Loss: 0.9023\n",
      "Epoch: 20/20, Batch: 150/1586, Loss: 1.4316\n",
      "Epoch: 20/20, Batch: 200/1586, Loss: 0.8454\n",
      "Epoch: 20/20, Batch: 250/1586, Loss: 1.1309\n",
      "Epoch: 20/20, Batch: 300/1586, Loss: 0.9781\n",
      "Epoch: 20/20, Batch: 350/1586, Loss: 1.1883\n",
      "Epoch: 20/20, Batch: 400/1586, Loss: 1.1478\n",
      "Epoch: 20/20, Batch: 450/1586, Loss: 1.1147\n",
      "Epoch: 20/20, Batch: 500/1586, Loss: 1.0908\n",
      "Epoch: 20/20, Batch: 550/1586, Loss: 0.6758\n",
      "Epoch: 20/20, Batch: 600/1586, Loss: 1.3896\n",
      "Epoch: 20/20, Batch: 650/1586, Loss: 1.0685\n",
      "Epoch: 20/20, Batch: 700/1586, Loss: 0.7721\n",
      "Epoch: 20/20, Batch: 750/1586, Loss: 0.9633\n",
      "Epoch: 20/20, Batch: 800/1586, Loss: 0.7359\n",
      "Epoch: 20/20, Batch: 850/1586, Loss: 1.1201\n",
      "Epoch: 20/20, Batch: 900/1586, Loss: 1.0990\n",
      "Epoch: 20/20, Batch: 950/1586, Loss: 1.1336\n",
      "Epoch: 20/20, Batch: 1000/1586, Loss: 0.8894\n",
      "Epoch: 20/20, Batch: 1050/1586, Loss: 0.8953\n",
      "Epoch: 20/20, Batch: 1100/1586, Loss: 1.2007\n",
      "Epoch: 20/20, Batch: 1150/1586, Loss: 0.8392\n",
      "Epoch: 20/20, Batch: 1200/1586, Loss: 1.0992\n",
      "Epoch: 20/20, Batch: 1250/1586, Loss: 0.9690\n",
      "Epoch: 20/20, Batch: 1300/1586, Loss: 1.2214\n",
      "Epoch: 20/20, Batch: 1350/1586, Loss: 1.2568\n",
      "Epoch: 20/20, Batch: 1400/1586, Loss: 0.9359\n",
      "Epoch: 20/20, Batch: 1450/1586, Loss: 0.9040\n",
      "Epoch: 20/20, Batch: 1500/1586, Loss: 0.7884\n",
      "Epoch: 20/20, Batch: 1550/1586, Loss: 0.8462\n",
      "Epoch: 20, Train Loss: 0.9661\n",
      "Training finished!\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "ZG2C5O7VAihT",
    "outputId": "9ebbb79b-a0cc-48c1-8ee1-e99f83117e36",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:03:44.531913Z",
     "start_time": "2025-11-05T04:03:43.897153Z"
    }
   },
   "source": [
    "weighted_model.eval()\n",
    "y_true_weighted = []\n",
    "y_pred_weighted = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = weighted_model(data)\n",
    "\n",
    "        y_true_weighted.extend(target.cpu().numpy())\n",
    "        y_pred_weighted.extend((output > 0.5).cpu().numpy())\n",
    "\n",
    "y_true_weighted = np.array(y_true_weighted)\n",
    "y_pred_weighted = np.array(y_pred_weighted)\n",
    "\n",
    "print(\"\\nClassification Report (Weighted):\")\n",
    "print(classification_report(y_true_weighted, y_pred_weighted))\n",
    "print(\"\\nConfusion Matrix (Weighted):\")\n",
    "cm_weighted = confusion_matrix(y_true_weighted, y_pred_weighted)\n",
    "sns.heatmap(cm_weighted, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Weighted)')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Weighted):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.72      0.83     45997\n",
      "         1.0       0.23      0.83      0.36      4739\n",
      "\n",
      "    accuracy                           0.73     50736\n",
      "   macro avg       0.60      0.77      0.60     50736\n",
      "weighted avg       0.91      0.73      0.79     50736\n",
      "\n",
      "\n",
      "Confusion Matrix (Weighted):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rLbRAotAihT"
   },
   "source": [
    "#### train:test = 7:3"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J9WsLryyAihT",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:03:44.584591Z",
     "start_time": "2025-11-05T04:03:44.559307Z"
    }
   },
   "source": [
    "total_size = len(X)\n",
    "train_size = int(0.7 * total_size)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "dataset = HeartDiseaseDataset(X, y)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "input_features = X.shape[1]\n",
    "\n",
    "weighted_model_2 = HeartDiseaseMLPClassifier(input_size=input_features, class_frequencies=class_frequencies).to(device)\n",
    "\n",
    "optimizer = optim.Adam(weighted_model_2.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdvbefFQAihT",
    "outputId": "9b1d574e-a8d4-4cb0-b952-514b272a8712",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:05:19.621986Z",
     "start_time": "2025-11-05T04:03:44.616397Z"
    }
   },
   "source": [
    "num_epochs = 20\n",
    "weighted_train_losses = []\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    weighted_model_2.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = weighted_model_2(data)\n",
    "\n",
    "        target = target.float()\n",
    "        output = output.float()\n",
    "        loss = weighted_model_2.get_weighted_loss(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    weighted_train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "print('Training finished!')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch: 1/20, Batch: 0/1388, Loss: 1.3350\n",
      "Epoch: 1/20, Batch: 50/1388, Loss: 0.8269\n",
      "Epoch: 1/20, Batch: 100/1388, Loss: 0.8208\n",
      "Epoch: 1/20, Batch: 150/1388, Loss: 0.9970\n",
      "Epoch: 1/20, Batch: 200/1388, Loss: 0.8255\n",
      "Epoch: 1/20, Batch: 250/1388, Loss: 1.2970\n",
      "Epoch: 1/20, Batch: 300/1388, Loss: 1.0641\n",
      "Epoch: 1/20, Batch: 350/1388, Loss: 0.8040\n",
      "Epoch: 1/20, Batch: 400/1388, Loss: 0.8146\n",
      "Epoch: 1/20, Batch: 450/1388, Loss: 1.0739\n",
      "Epoch: 1/20, Batch: 500/1388, Loss: 1.0982\n",
      "Epoch: 1/20, Batch: 550/1388, Loss: 1.0235\n",
      "Epoch: 1/20, Batch: 600/1388, Loss: 0.7672\n",
      "Epoch: 1/20, Batch: 650/1388, Loss: 1.1217\n",
      "Epoch: 1/20, Batch: 700/1388, Loss: 1.0488\n",
      "Epoch: 1/20, Batch: 750/1388, Loss: 0.7614\n",
      "Epoch: 1/20, Batch: 800/1388, Loss: 0.7488\n",
      "Epoch: 1/20, Batch: 850/1388, Loss: 0.8464\n",
      "Epoch: 1/20, Batch: 900/1388, Loss: 1.4232\n",
      "Epoch: 1/20, Batch: 950/1388, Loss: 1.1517\n",
      "Epoch: 1/20, Batch: 1000/1388, Loss: 0.7070\n",
      "Epoch: 1/20, Batch: 1050/1388, Loss: 0.7789\n",
      "Epoch: 1/20, Batch: 1100/1388, Loss: 1.0392\n",
      "Epoch: 1/20, Batch: 1150/1388, Loss: 1.6246\n",
      "Epoch: 1/20, Batch: 1200/1388, Loss: 1.0493\n",
      "Epoch: 1/20, Batch: 1250/1388, Loss: 0.8606\n",
      "Epoch: 1/20, Batch: 1300/1388, Loss: 0.9434\n",
      "Epoch: 1/20, Batch: 1350/1388, Loss: 1.2357\n",
      "Epoch: 1, Train Loss: 1.0168\n",
      "Epoch: 2/20, Batch: 0/1388, Loss: 1.0587\n",
      "Epoch: 2/20, Batch: 50/1388, Loss: 0.8959\n",
      "Epoch: 2/20, Batch: 100/1388, Loss: 0.8559\n",
      "Epoch: 2/20, Batch: 150/1388, Loss: 1.0903\n",
      "Epoch: 2/20, Batch: 200/1388, Loss: 1.2499\n",
      "Epoch: 2/20, Batch: 250/1388, Loss: 1.0456\n",
      "Epoch: 2/20, Batch: 300/1388, Loss: 1.0825\n",
      "Epoch: 2/20, Batch: 350/1388, Loss: 1.1118\n",
      "Epoch: 2/20, Batch: 400/1388, Loss: 0.8722\n",
      "Epoch: 2/20, Batch: 450/1388, Loss: 0.7784\n",
      "Epoch: 2/20, Batch: 500/1388, Loss: 1.0510\n",
      "Epoch: 2/20, Batch: 550/1388, Loss: 0.7674\n",
      "Epoch: 2/20, Batch: 600/1388, Loss: 0.8219\n",
      "Epoch: 2/20, Batch: 650/1388, Loss: 0.9987\n",
      "Epoch: 2/20, Batch: 700/1388, Loss: 0.8342\n",
      "Epoch: 2/20, Batch: 750/1388, Loss: 0.8875\n",
      "Epoch: 2/20, Batch: 800/1388, Loss: 0.8597\n",
      "Epoch: 2/20, Batch: 850/1388, Loss: 0.7714\n",
      "Epoch: 2/20, Batch: 900/1388, Loss: 1.3242\n",
      "Epoch: 2/20, Batch: 950/1388, Loss: 0.8547\n",
      "Epoch: 2/20, Batch: 1000/1388, Loss: 0.6627\n",
      "Epoch: 2/20, Batch: 1050/1388, Loss: 0.8557\n",
      "Epoch: 2/20, Batch: 1100/1388, Loss: 0.8797\n",
      "Epoch: 2/20, Batch: 1150/1388, Loss: 0.7698\n",
      "Epoch: 2/20, Batch: 1200/1388, Loss: 0.9031\n",
      "Epoch: 2/20, Batch: 1250/1388, Loss: 0.7951\n",
      "Epoch: 2/20, Batch: 1300/1388, Loss: 0.8727\n",
      "Epoch: 2/20, Batch: 1350/1388, Loss: 1.0348\n",
      "Epoch: 2, Train Loss: 0.9843\n",
      "Epoch: 3/20, Batch: 0/1388, Loss: 0.8979\n",
      "Epoch: 3/20, Batch: 50/1388, Loss: 0.8894\n",
      "Epoch: 3/20, Batch: 100/1388, Loss: 1.0637\n",
      "Epoch: 3/20, Batch: 150/1388, Loss: 0.7542\n",
      "Epoch: 3/20, Batch: 200/1388, Loss: 1.0486\n",
      "Epoch: 3/20, Batch: 250/1388, Loss: 0.7800\n",
      "Epoch: 3/20, Batch: 300/1388, Loss: 0.8557\n",
      "Epoch: 3/20, Batch: 350/1388, Loss: 1.0502\n",
      "Epoch: 3/20, Batch: 400/1388, Loss: 0.9714\n",
      "Epoch: 3/20, Batch: 450/1388, Loss: 0.9179\n",
      "Epoch: 3/20, Batch: 500/1388, Loss: 0.9890\n",
      "Epoch: 3/20, Batch: 550/1388, Loss: 0.8989\n",
      "Epoch: 3/20, Batch: 600/1388, Loss: 0.7842\n",
      "Epoch: 3/20, Batch: 650/1388, Loss: 1.2294\n",
      "Epoch: 3/20, Batch: 700/1388, Loss: 0.9350\n",
      "Epoch: 3/20, Batch: 750/1388, Loss: 1.2709\n",
      "Epoch: 3/20, Batch: 800/1388, Loss: 0.8894\n",
      "Epoch: 3/20, Batch: 850/1388, Loss: 1.1345\n",
      "Epoch: 3/20, Batch: 900/1388, Loss: 0.6861\n",
      "Epoch: 3/20, Batch: 950/1388, Loss: 0.8888\n",
      "Epoch: 3/20, Batch: 1000/1388, Loss: 0.9779\n",
      "Epoch: 3/20, Batch: 1050/1388, Loss: 0.8579\n",
      "Epoch: 3/20, Batch: 1100/1388, Loss: 0.7678\n",
      "Epoch: 3/20, Batch: 1150/1388, Loss: 1.0271\n",
      "Epoch: 3/20, Batch: 1200/1388, Loss: 1.0233\n",
      "Epoch: 3/20, Batch: 1250/1388, Loss: 1.2963\n",
      "Epoch: 3/20, Batch: 1300/1388, Loss: 0.8275\n",
      "Epoch: 3/20, Batch: 1350/1388, Loss: 0.9149\n",
      "Epoch: 3, Train Loss: 0.9771\n",
      "Epoch: 4/20, Batch: 0/1388, Loss: 0.7619\n",
      "Epoch: 4/20, Batch: 50/1388, Loss: 0.7804\n",
      "Epoch: 4/20, Batch: 100/1388, Loss: 1.0560\n",
      "Epoch: 4/20, Batch: 150/1388, Loss: 1.1316\n",
      "Epoch: 4/20, Batch: 200/1388, Loss: 1.2270\n",
      "Epoch: 4/20, Batch: 250/1388, Loss: 1.0378\n",
      "Epoch: 4/20, Batch: 300/1388, Loss: 0.8580\n",
      "Epoch: 4/20, Batch: 350/1388, Loss: 0.8658\n",
      "Epoch: 4/20, Batch: 400/1388, Loss: 0.9575\n",
      "Epoch: 4/20, Batch: 450/1388, Loss: 1.4687\n",
      "Epoch: 4/20, Batch: 500/1388, Loss: 1.6543\n",
      "Epoch: 4/20, Batch: 550/1388, Loss: 0.7531\n",
      "Epoch: 4/20, Batch: 600/1388, Loss: 1.0924\n",
      "Epoch: 4/20, Batch: 650/1388, Loss: 0.8391\n",
      "Epoch: 4/20, Batch: 700/1388, Loss: 0.8854\n",
      "Epoch: 4/20, Batch: 750/1388, Loss: 1.1830\n",
      "Epoch: 4/20, Batch: 800/1388, Loss: 0.8759\n",
      "Epoch: 4/20, Batch: 850/1388, Loss: 0.9445\n",
      "Epoch: 4/20, Batch: 900/1388, Loss: 0.7815\n",
      "Epoch: 4/20, Batch: 950/1388, Loss: 0.8286\n",
      "Epoch: 4/20, Batch: 1000/1388, Loss: 0.8643\n",
      "Epoch: 4/20, Batch: 1050/1388, Loss: 1.0877\n",
      "Epoch: 4/20, Batch: 1100/1388, Loss: 0.8394\n",
      "Epoch: 4/20, Batch: 1150/1388, Loss: 0.9118\n",
      "Epoch: 4/20, Batch: 1200/1388, Loss: 0.8022\n",
      "Epoch: 4/20, Batch: 1250/1388, Loss: 0.8968\n",
      "Epoch: 4/20, Batch: 1300/1388, Loss: 0.9048\n",
      "Epoch: 4/20, Batch: 1350/1388, Loss: 1.0581\n",
      "Epoch: 4, Train Loss: 0.9742\n",
      "Epoch: 5/20, Batch: 0/1388, Loss: 1.1537\n",
      "Epoch: 5/20, Batch: 50/1388, Loss: 0.7787\n",
      "Epoch: 5/20, Batch: 100/1388, Loss: 0.8741\n",
      "Epoch: 5/20, Batch: 150/1388, Loss: 1.0234\n",
      "Epoch: 5/20, Batch: 200/1388, Loss: 1.3742\n",
      "Epoch: 5/20, Batch: 250/1388, Loss: 1.0343\n",
      "Epoch: 5/20, Batch: 300/1388, Loss: 1.4972\n",
      "Epoch: 5/20, Batch: 350/1388, Loss: 0.9733\n",
      "Epoch: 5/20, Batch: 400/1388, Loss: 0.9709\n",
      "Epoch: 5/20, Batch: 450/1388, Loss: 0.7892\n",
      "Epoch: 5/20, Batch: 500/1388, Loss: 1.1783\n",
      "Epoch: 5/20, Batch: 550/1388, Loss: 0.8187\n",
      "Epoch: 5/20, Batch: 600/1388, Loss: 0.8279\n",
      "Epoch: 5/20, Batch: 650/1388, Loss: 1.1996\n",
      "Epoch: 5/20, Batch: 700/1388, Loss: 1.3596\n",
      "Epoch: 5/20, Batch: 750/1388, Loss: 1.1213\n",
      "Epoch: 5/20, Batch: 800/1388, Loss: 0.8746\n",
      "Epoch: 5/20, Batch: 850/1388, Loss: 0.8886\n",
      "Epoch: 5/20, Batch: 900/1388, Loss: 0.8972\n",
      "Epoch: 5/20, Batch: 950/1388, Loss: 0.6994\n",
      "Epoch: 5/20, Batch: 1000/1388, Loss: 1.2698\n",
      "Epoch: 5/20, Batch: 1050/1388, Loss: 1.3545\n",
      "Epoch: 5/20, Batch: 1100/1388, Loss: 1.2692\n",
      "Epoch: 5/20, Batch: 1150/1388, Loss: 0.9091\n",
      "Epoch: 5/20, Batch: 1200/1388, Loss: 0.9393\n",
      "Epoch: 5/20, Batch: 1250/1388, Loss: 0.6254\n",
      "Epoch: 5/20, Batch: 1300/1388, Loss: 0.9669\n",
      "Epoch: 5/20, Batch: 1350/1388, Loss: 0.9237\n",
      "Epoch: 5, Train Loss: 0.9730\n",
      "Epoch: 6/20, Batch: 0/1388, Loss: 1.1074\n",
      "Epoch: 6/20, Batch: 50/1388, Loss: 0.9699\n",
      "Epoch: 6/20, Batch: 100/1388, Loss: 1.0430\n",
      "Epoch: 6/20, Batch: 150/1388, Loss: 0.9419\n",
      "Epoch: 6/20, Batch: 200/1388, Loss: 0.9146\n",
      "Epoch: 6/20, Batch: 250/1388, Loss: 1.2860\n",
      "Epoch: 6/20, Batch: 300/1388, Loss: 0.8872\n",
      "Epoch: 6/20, Batch: 350/1388, Loss: 1.5972\n",
      "Epoch: 6/20, Batch: 400/1388, Loss: 0.9034\n",
      "Epoch: 6/20, Batch: 450/1388, Loss: 0.8863\n",
      "Epoch: 6/20, Batch: 500/1388, Loss: 1.0264\n",
      "Epoch: 6/20, Batch: 550/1388, Loss: 0.7382\n",
      "Epoch: 6/20, Batch: 600/1388, Loss: 1.1743\n",
      "Epoch: 6/20, Batch: 650/1388, Loss: 1.1280\n",
      "Epoch: 6/20, Batch: 700/1388, Loss: 1.2248\n",
      "Epoch: 6/20, Batch: 750/1388, Loss: 0.8939\n",
      "Epoch: 6/20, Batch: 800/1388, Loss: 0.7334\n",
      "Epoch: 6/20, Batch: 850/1388, Loss: 0.6838\n",
      "Epoch: 6/20, Batch: 900/1388, Loss: 0.8811\n",
      "Epoch: 6/20, Batch: 950/1388, Loss: 1.6527\n",
      "Epoch: 6/20, Batch: 1000/1388, Loss: 1.1157\n",
      "Epoch: 6/20, Batch: 1050/1388, Loss: 1.1295\n",
      "Epoch: 6/20, Batch: 1100/1388, Loss: 0.8746\n",
      "Epoch: 6/20, Batch: 1150/1388, Loss: 1.4712\n",
      "Epoch: 6/20, Batch: 1200/1388, Loss: 1.0951\n",
      "Epoch: 6/20, Batch: 1250/1388, Loss: 0.9161\n",
      "Epoch: 6/20, Batch: 1300/1388, Loss: 0.8347\n",
      "Epoch: 6/20, Batch: 1350/1388, Loss: 0.9165\n",
      "Epoch: 6, Train Loss: 0.9706\n",
      "Epoch: 7/20, Batch: 0/1388, Loss: 0.9145\n",
      "Epoch: 7/20, Batch: 50/1388, Loss: 0.7983\n",
      "Epoch: 7/20, Batch: 100/1388, Loss: 1.5445\n",
      "Epoch: 7/20, Batch: 150/1388, Loss: 0.7773\n",
      "Epoch: 7/20, Batch: 200/1388, Loss: 1.0105\n",
      "Epoch: 7/20, Batch: 250/1388, Loss: 1.4951\n",
      "Epoch: 7/20, Batch: 300/1388, Loss: 0.9857\n",
      "Epoch: 7/20, Batch: 350/1388, Loss: 1.2105\n",
      "Epoch: 7/20, Batch: 400/1388, Loss: 1.0537\n",
      "Epoch: 7/20, Batch: 450/1388, Loss: 0.8776\n",
      "Epoch: 7/20, Batch: 500/1388, Loss: 0.7493\n",
      "Epoch: 7/20, Batch: 550/1388, Loss: 0.7270\n",
      "Epoch: 7/20, Batch: 600/1388, Loss: 1.1872\n",
      "Epoch: 7/20, Batch: 650/1388, Loss: 0.9319\n",
      "Epoch: 7/20, Batch: 700/1388, Loss: 0.7961\n",
      "Epoch: 7/20, Batch: 750/1388, Loss: 1.0968\n",
      "Epoch: 7/20, Batch: 800/1388, Loss: 0.9629\n",
      "Epoch: 7/20, Batch: 850/1388, Loss: 1.0584\n",
      "Epoch: 7/20, Batch: 900/1388, Loss: 0.7774\n",
      "Epoch: 7/20, Batch: 950/1388, Loss: 0.8783\n",
      "Epoch: 7/20, Batch: 1000/1388, Loss: 1.1053\n",
      "Epoch: 7/20, Batch: 1050/1388, Loss: 0.8940\n",
      "Epoch: 7/20, Batch: 1100/1388, Loss: 0.9740\n",
      "Epoch: 7/20, Batch: 1150/1388, Loss: 1.1300\n",
      "Epoch: 7/20, Batch: 1200/1388, Loss: 0.8805\n",
      "Epoch: 7/20, Batch: 1250/1388, Loss: 1.2896\n",
      "Epoch: 7/20, Batch: 1300/1388, Loss: 1.0746\n",
      "Epoch: 7/20, Batch: 1350/1388, Loss: 1.0023\n",
      "Epoch: 7, Train Loss: 0.9695\n",
      "Epoch: 8/20, Batch: 0/1388, Loss: 0.9714\n",
      "Epoch: 8/20, Batch: 50/1388, Loss: 0.7854\n",
      "Epoch: 8/20, Batch: 100/1388, Loss: 0.7452\n",
      "Epoch: 8/20, Batch: 150/1388, Loss: 1.0477\n",
      "Epoch: 8/20, Batch: 200/1388, Loss: 0.8018\n",
      "Epoch: 8/20, Batch: 250/1388, Loss: 0.8674\n",
      "Epoch: 8/20, Batch: 300/1388, Loss: 0.9266\n",
      "Epoch: 8/20, Batch: 350/1388, Loss: 0.8999\n",
      "Epoch: 8/20, Batch: 400/1388, Loss: 0.7900\n",
      "Epoch: 8/20, Batch: 450/1388, Loss: 0.7945\n",
      "Epoch: 8/20, Batch: 500/1388, Loss: 0.8921\n",
      "Epoch: 8/20, Batch: 550/1388, Loss: 0.6848\n",
      "Epoch: 8/20, Batch: 600/1388, Loss: 0.7852\n",
      "Epoch: 8/20, Batch: 650/1388, Loss: 1.2226\n",
      "Epoch: 8/20, Batch: 700/1388, Loss: 0.6947\n",
      "Epoch: 8/20, Batch: 750/1388, Loss: 1.0418\n",
      "Epoch: 8/20, Batch: 800/1388, Loss: 1.0282\n",
      "Epoch: 8/20, Batch: 850/1388, Loss: 1.3007\n",
      "Epoch: 8/20, Batch: 900/1388, Loss: 0.8648\n",
      "Epoch: 8/20, Batch: 950/1388, Loss: 1.0298\n",
      "Epoch: 8/20, Batch: 1000/1388, Loss: 0.9033\n",
      "Epoch: 8/20, Batch: 1050/1388, Loss: 0.9257\n",
      "Epoch: 8/20, Batch: 1100/1388, Loss: 1.1602\n",
      "Epoch: 8/20, Batch: 1150/1388, Loss: 0.7900\n",
      "Epoch: 8/20, Batch: 1200/1388, Loss: 0.8715\n",
      "Epoch: 8/20, Batch: 1250/1388, Loss: 1.1030\n",
      "Epoch: 8/20, Batch: 1300/1388, Loss: 0.8212\n",
      "Epoch: 8/20, Batch: 1350/1388, Loss: 0.8161\n",
      "Epoch: 8, Train Loss: 0.9700\n",
      "Epoch: 9/20, Batch: 0/1388, Loss: 1.1963\n",
      "Epoch: 9/20, Batch: 50/1388, Loss: 1.0119\n",
      "Epoch: 9/20, Batch: 100/1388, Loss: 0.7848\n",
      "Epoch: 9/20, Batch: 150/1388, Loss: 0.8637\n",
      "Epoch: 9/20, Batch: 200/1388, Loss: 1.0100\n",
      "Epoch: 9/20, Batch: 250/1388, Loss: 0.6567\n",
      "Epoch: 9/20, Batch: 300/1388, Loss: 1.0987\n",
      "Epoch: 9/20, Batch: 350/1388, Loss: 1.0197\n",
      "Epoch: 9/20, Batch: 400/1388, Loss: 1.0924\n",
      "Epoch: 9/20, Batch: 450/1388, Loss: 0.8219\n",
      "Epoch: 9/20, Batch: 500/1388, Loss: 0.8688\n",
      "Epoch: 9/20, Batch: 550/1388, Loss: 1.0209\n",
      "Epoch: 9/20, Batch: 600/1388, Loss: 0.7976\n",
      "Epoch: 9/20, Batch: 650/1388, Loss: 0.7862\n",
      "Epoch: 9/20, Batch: 700/1388, Loss: 0.7372\n",
      "Epoch: 9/20, Batch: 750/1388, Loss: 1.0265\n",
      "Epoch: 9/20, Batch: 800/1388, Loss: 0.8062\n",
      "Epoch: 9/20, Batch: 850/1388, Loss: 1.6147\n",
      "Epoch: 9/20, Batch: 900/1388, Loss: 0.7568\n",
      "Epoch: 9/20, Batch: 950/1388, Loss: 0.7957\n",
      "Epoch: 9/20, Batch: 1000/1388, Loss: 0.7590\n",
      "Epoch: 9/20, Batch: 1050/1388, Loss: 0.8255\n",
      "Epoch: 9/20, Batch: 1100/1388, Loss: 1.2433\n",
      "Epoch: 9/20, Batch: 1150/1388, Loss: 0.8572\n",
      "Epoch: 9/20, Batch: 1200/1388, Loss: 0.8734\n",
      "Epoch: 9/20, Batch: 1250/1388, Loss: 1.1367\n",
      "Epoch: 9/20, Batch: 1300/1388, Loss: 0.9317\n",
      "Epoch: 9/20, Batch: 1350/1388, Loss: 0.9833\n",
      "Epoch: 9, Train Loss: 0.9677\n",
      "Epoch: 10/20, Batch: 0/1388, Loss: 0.9169\n",
      "Epoch: 10/20, Batch: 50/1388, Loss: 1.6294\n",
      "Epoch: 10/20, Batch: 100/1388, Loss: 0.7603\n",
      "Epoch: 10/20, Batch: 150/1388, Loss: 0.8887\n",
      "Epoch: 10/20, Batch: 200/1388, Loss: 0.9208\n",
      "Epoch: 10/20, Batch: 250/1388, Loss: 0.9882\n",
      "Epoch: 10/20, Batch: 300/1388, Loss: 1.0742\n",
      "Epoch: 10/20, Batch: 350/1388, Loss: 1.5774\n",
      "Epoch: 10/20, Batch: 400/1388, Loss: 0.8420\n",
      "Epoch: 10/20, Batch: 450/1388, Loss: 0.8084\n",
      "Epoch: 10/20, Batch: 500/1388, Loss: 0.9888\n",
      "Epoch: 10/20, Batch: 550/1388, Loss: 1.1388\n",
      "Epoch: 10/20, Batch: 600/1388, Loss: 0.7493\n",
      "Epoch: 10/20, Batch: 650/1388, Loss: 0.7226\n",
      "Epoch: 10/20, Batch: 700/1388, Loss: 0.8475\n",
      "Epoch: 10/20, Batch: 750/1388, Loss: 0.9312\n",
      "Epoch: 10/20, Batch: 800/1388, Loss: 1.0885\n",
      "Epoch: 10/20, Batch: 850/1388, Loss: 1.1513\n",
      "Epoch: 10/20, Batch: 900/1388, Loss: 0.9409\n",
      "Epoch: 10/20, Batch: 950/1388, Loss: 0.9296\n",
      "Epoch: 10/20, Batch: 1000/1388, Loss: 0.7448\n",
      "Epoch: 10/20, Batch: 1050/1388, Loss: 1.2151\n",
      "Epoch: 10/20, Batch: 1100/1388, Loss: 1.3293\n",
      "Epoch: 10/20, Batch: 1150/1388, Loss: 1.2482\n",
      "Epoch: 10/20, Batch: 1200/1388, Loss: 0.9552\n",
      "Epoch: 10/20, Batch: 1250/1388, Loss: 0.8083\n",
      "Epoch: 10/20, Batch: 1300/1388, Loss: 1.4617\n",
      "Epoch: 10/20, Batch: 1350/1388, Loss: 1.1164\n",
      "Epoch: 10, Train Loss: 0.9682\n",
      "Epoch: 11/20, Batch: 0/1388, Loss: 1.3132\n",
      "Epoch: 11/20, Batch: 50/1388, Loss: 0.7716\n",
      "Epoch: 11/20, Batch: 100/1388, Loss: 0.9899\n",
      "Epoch: 11/20, Batch: 150/1388, Loss: 1.2755\n",
      "Epoch: 11/20, Batch: 200/1388, Loss: 0.9622\n",
      "Epoch: 11/20, Batch: 250/1388, Loss: 1.0301\n",
      "Epoch: 11/20, Batch: 300/1388, Loss: 0.9852\n",
      "Epoch: 11/20, Batch: 350/1388, Loss: 0.9276\n",
      "Epoch: 11/20, Batch: 400/1388, Loss: 0.9172\n",
      "Epoch: 11/20, Batch: 450/1388, Loss: 1.1178\n",
      "Epoch: 11/20, Batch: 500/1388, Loss: 1.2512\n",
      "Epoch: 11/20, Batch: 550/1388, Loss: 0.8154\n",
      "Epoch: 11/20, Batch: 600/1388, Loss: 0.9327\n",
      "Epoch: 11/20, Batch: 650/1388, Loss: 1.0234\n",
      "Epoch: 11/20, Batch: 700/1388, Loss: 0.8128\n",
      "Epoch: 11/20, Batch: 750/1388, Loss: 0.6641\n",
      "Epoch: 11/20, Batch: 800/1388, Loss: 1.2981\n",
      "Epoch: 11/20, Batch: 850/1388, Loss: 0.9061\n",
      "Epoch: 11/20, Batch: 900/1388, Loss: 0.9869\n",
      "Epoch: 11/20, Batch: 950/1388, Loss: 1.0133\n",
      "Epoch: 11/20, Batch: 1000/1388, Loss: 0.8792\n",
      "Epoch: 11/20, Batch: 1050/1388, Loss: 0.7922\n",
      "Epoch: 11/20, Batch: 1100/1388, Loss: 1.4680\n",
      "Epoch: 11/20, Batch: 1150/1388, Loss: 0.7022\n",
      "Epoch: 11/20, Batch: 1200/1388, Loss: 0.8643\n",
      "Epoch: 11/20, Batch: 1250/1388, Loss: 0.7095\n",
      "Epoch: 11/20, Batch: 1300/1388, Loss: 0.7407\n",
      "Epoch: 11/20, Batch: 1350/1388, Loss: 0.8193\n",
      "Epoch: 11, Train Loss: 0.9691\n",
      "Epoch: 12/20, Batch: 0/1388, Loss: 0.8848\n",
      "Epoch: 12/20, Batch: 50/1388, Loss: 0.7687\n",
      "Epoch: 12/20, Batch: 100/1388, Loss: 0.8109\n",
      "Epoch: 12/20, Batch: 150/1388, Loss: 1.2277\n",
      "Epoch: 12/20, Batch: 200/1388, Loss: 0.8775\n",
      "Epoch: 12/20, Batch: 250/1388, Loss: 1.0617\n",
      "Epoch: 12/20, Batch: 300/1388, Loss: 0.9606\n",
      "Epoch: 12/20, Batch: 350/1388, Loss: 1.1098\n",
      "Epoch: 12/20, Batch: 400/1388, Loss: 0.9104\n",
      "Epoch: 12/20, Batch: 450/1388, Loss: 0.7122\n",
      "Epoch: 12/20, Batch: 500/1388, Loss: 0.7690\n",
      "Epoch: 12/20, Batch: 550/1388, Loss: 0.8850\n",
      "Epoch: 12/20, Batch: 600/1388, Loss: 0.9851\n",
      "Epoch: 12/20, Batch: 650/1388, Loss: 1.0857\n",
      "Epoch: 12/20, Batch: 700/1388, Loss: 1.0103\n",
      "Epoch: 12/20, Batch: 750/1388, Loss: 1.0061\n",
      "Epoch: 12/20, Batch: 800/1388, Loss: 1.0854\n",
      "Epoch: 12/20, Batch: 850/1388, Loss: 1.0603\n",
      "Epoch: 12/20, Batch: 900/1388, Loss: 1.0424\n",
      "Epoch: 12/20, Batch: 950/1388, Loss: 1.1294\n",
      "Epoch: 12/20, Batch: 1000/1388, Loss: 0.7831\n",
      "Epoch: 12/20, Batch: 1050/1388, Loss: 1.1983\n",
      "Epoch: 12/20, Batch: 1100/1388, Loss: 1.1426\n",
      "Epoch: 12/20, Batch: 1150/1388, Loss: 0.9762\n",
      "Epoch: 12/20, Batch: 1200/1388, Loss: 0.6994\n",
      "Epoch: 12/20, Batch: 1250/1388, Loss: 0.8231\n",
      "Epoch: 12/20, Batch: 1300/1388, Loss: 0.9032\n",
      "Epoch: 12/20, Batch: 1350/1388, Loss: 0.7999\n",
      "Epoch: 12, Train Loss: 0.9664\n",
      "Epoch: 13/20, Batch: 0/1388, Loss: 1.1346\n",
      "Epoch: 13/20, Batch: 50/1388, Loss: 0.9797\n",
      "Epoch: 13/20, Batch: 100/1388, Loss: 0.8913\n",
      "Epoch: 13/20, Batch: 150/1388, Loss: 0.9425\n",
      "Epoch: 13/20, Batch: 200/1388, Loss: 0.7724\n",
      "Epoch: 13/20, Batch: 250/1388, Loss: 1.6344\n",
      "Epoch: 13/20, Batch: 300/1388, Loss: 0.7276\n",
      "Epoch: 13/20, Batch: 350/1388, Loss: 0.7257\n",
      "Epoch: 13/20, Batch: 400/1388, Loss: 1.1861\n",
      "Epoch: 13/20, Batch: 450/1388, Loss: 0.8563\n",
      "Epoch: 13/20, Batch: 500/1388, Loss: 0.8626\n",
      "Epoch: 13/20, Batch: 550/1388, Loss: 1.3113\n",
      "Epoch: 13/20, Batch: 600/1388, Loss: 0.9288\n",
      "Epoch: 13/20, Batch: 650/1388, Loss: 0.7789\n",
      "Epoch: 13/20, Batch: 700/1388, Loss: 0.7918\n",
      "Epoch: 13/20, Batch: 750/1388, Loss: 1.0615\n",
      "Epoch: 13/20, Batch: 800/1388, Loss: 0.8471\n",
      "Epoch: 13/20, Batch: 850/1388, Loss: 0.7437\n",
      "Epoch: 13/20, Batch: 900/1388, Loss: 0.9328\n",
      "Epoch: 13/20, Batch: 950/1388, Loss: 0.8365\n",
      "Epoch: 13/20, Batch: 1000/1388, Loss: 1.0399\n",
      "Epoch: 13/20, Batch: 1050/1388, Loss: 1.1127\n",
      "Epoch: 13/20, Batch: 1100/1388, Loss: 0.9261\n",
      "Epoch: 13/20, Batch: 1150/1388, Loss: 0.8386\n",
      "Epoch: 13/20, Batch: 1200/1388, Loss: 0.9493\n",
      "Epoch: 13/20, Batch: 1250/1388, Loss: 0.8640\n",
      "Epoch: 13/20, Batch: 1300/1388, Loss: 0.9779\n",
      "Epoch: 13/20, Batch: 1350/1388, Loss: 0.7983\n",
      "Epoch: 13, Train Loss: 0.9677\n",
      "Epoch: 14/20, Batch: 0/1388, Loss: 1.0636\n",
      "Epoch: 14/20, Batch: 50/1388, Loss: 0.8115\n",
      "Epoch: 14/20, Batch: 100/1388, Loss: 1.0933\n",
      "Epoch: 14/20, Batch: 150/1388, Loss: 1.0855\n",
      "Epoch: 14/20, Batch: 200/1388, Loss: 1.0784\n",
      "Epoch: 14/20, Batch: 250/1388, Loss: 0.7589\n",
      "Epoch: 14/20, Batch: 300/1388, Loss: 0.9817\n",
      "Epoch: 14/20, Batch: 350/1388, Loss: 0.8138\n",
      "Epoch: 14/20, Batch: 400/1388, Loss: 1.0901\n",
      "Epoch: 14/20, Batch: 450/1388, Loss: 0.8558\n",
      "Epoch: 14/20, Batch: 500/1388, Loss: 0.8097\n",
      "Epoch: 14/20, Batch: 550/1388, Loss: 0.8752\n",
      "Epoch: 14/20, Batch: 600/1388, Loss: 0.7808\n",
      "Epoch: 14/20, Batch: 650/1388, Loss: 0.7958\n",
      "Epoch: 14/20, Batch: 700/1388, Loss: 0.9471\n",
      "Epoch: 14/20, Batch: 750/1388, Loss: 1.5490\n",
      "Epoch: 14/20, Batch: 800/1388, Loss: 0.8129\n",
      "Epoch: 14/20, Batch: 850/1388, Loss: 0.8662\n",
      "Epoch: 14/20, Batch: 900/1388, Loss: 0.8416\n",
      "Epoch: 14/20, Batch: 950/1388, Loss: 1.0536\n",
      "Epoch: 14/20, Batch: 1000/1388, Loss: 1.1659\n",
      "Epoch: 14/20, Batch: 1050/1388, Loss: 0.7542\n",
      "Epoch: 14/20, Batch: 1100/1388, Loss: 0.8984\n",
      "Epoch: 14/20, Batch: 1150/1388, Loss: 1.1085\n",
      "Epoch: 14/20, Batch: 1200/1388, Loss: 0.8518\n",
      "Epoch: 14/20, Batch: 1250/1388, Loss: 1.1089\n",
      "Epoch: 14/20, Batch: 1300/1388, Loss: 1.0263\n",
      "Epoch: 14/20, Batch: 1350/1388, Loss: 1.0953\n",
      "Epoch: 14, Train Loss: 0.9666\n",
      "Epoch: 15/20, Batch: 0/1388, Loss: 0.8402\n",
      "Epoch: 15/20, Batch: 50/1388, Loss: 0.8301\n",
      "Epoch: 15/20, Batch: 100/1388, Loss: 1.3336\n",
      "Epoch: 15/20, Batch: 150/1388, Loss: 0.8141\n",
      "Epoch: 15/20, Batch: 200/1388, Loss: 0.9885\n",
      "Epoch: 15/20, Batch: 250/1388, Loss: 0.7903\n",
      "Epoch: 15/20, Batch: 300/1388, Loss: 0.7260\n",
      "Epoch: 15/20, Batch: 350/1388, Loss: 1.0759\n",
      "Epoch: 15/20, Batch: 400/1388, Loss: 1.1180\n",
      "Epoch: 15/20, Batch: 450/1388, Loss: 0.9969\n",
      "Epoch: 15/20, Batch: 500/1388, Loss: 0.8252\n",
      "Epoch: 15/20, Batch: 550/1388, Loss: 0.8719\n",
      "Epoch: 15/20, Batch: 600/1388, Loss: 0.9700\n",
      "Epoch: 15/20, Batch: 650/1388, Loss: 1.5151\n",
      "Epoch: 15/20, Batch: 700/1388, Loss: 1.4572\n",
      "Epoch: 15/20, Batch: 750/1388, Loss: 0.8477\n",
      "Epoch: 15/20, Batch: 800/1388, Loss: 0.8532\n",
      "Epoch: 15/20, Batch: 850/1388, Loss: 1.0001\n",
      "Epoch: 15/20, Batch: 900/1388, Loss: 1.1141\n",
      "Epoch: 15/20, Batch: 950/1388, Loss: 0.9248\n",
      "Epoch: 15/20, Batch: 1000/1388, Loss: 0.8289\n",
      "Epoch: 15/20, Batch: 1050/1388, Loss: 0.9522\n",
      "Epoch: 15/20, Batch: 1100/1388, Loss: 0.6701\n",
      "Epoch: 15/20, Batch: 1150/1388, Loss: 1.1194\n",
      "Epoch: 15/20, Batch: 1200/1388, Loss: 0.9260\n",
      "Epoch: 15/20, Batch: 1250/1388, Loss: 1.1533\n",
      "Epoch: 15/20, Batch: 1300/1388, Loss: 0.9746\n",
      "Epoch: 15/20, Batch: 1350/1388, Loss: 1.1425\n",
      "Epoch: 15, Train Loss: 0.9647\n",
      "Epoch: 16/20, Batch: 0/1388, Loss: 1.2272\n",
      "Epoch: 16/20, Batch: 50/1388, Loss: 0.9278\n",
      "Epoch: 16/20, Batch: 100/1388, Loss: 0.7932\n",
      "Epoch: 16/20, Batch: 150/1388, Loss: 0.7640\n",
      "Epoch: 16/20, Batch: 200/1388, Loss: 0.7906\n",
      "Epoch: 16/20, Batch: 250/1388, Loss: 0.8544\n",
      "Epoch: 16/20, Batch: 300/1388, Loss: 0.9134\n",
      "Epoch: 16/20, Batch: 350/1388, Loss: 1.4005\n",
      "Epoch: 16/20, Batch: 400/1388, Loss: 0.9276\n",
      "Epoch: 16/20, Batch: 450/1388, Loss: 1.2375\n",
      "Epoch: 16/20, Batch: 500/1388, Loss: 0.8552\n",
      "Epoch: 16/20, Batch: 550/1388, Loss: 1.3606\n",
      "Epoch: 16/20, Batch: 600/1388, Loss: 1.0341\n",
      "Epoch: 16/20, Batch: 650/1388, Loss: 0.7475\n",
      "Epoch: 16/20, Batch: 700/1388, Loss: 1.3025\n",
      "Epoch: 16/20, Batch: 750/1388, Loss: 0.7812\n",
      "Epoch: 16/20, Batch: 800/1388, Loss: 1.0810\n",
      "Epoch: 16/20, Batch: 850/1388, Loss: 0.8574\n",
      "Epoch: 16/20, Batch: 900/1388, Loss: 1.1519\n",
      "Epoch: 16/20, Batch: 950/1388, Loss: 0.8399\n",
      "Epoch: 16/20, Batch: 1000/1388, Loss: 0.8272\n",
      "Epoch: 16/20, Batch: 1050/1388, Loss: 0.8196\n",
      "Epoch: 16/20, Batch: 1100/1388, Loss: 0.8520\n",
      "Epoch: 16/20, Batch: 1150/1388, Loss: 0.7437\n",
      "Epoch: 16/20, Batch: 1200/1388, Loss: 0.7896\n",
      "Epoch: 16/20, Batch: 1250/1388, Loss: 0.7689\n",
      "Epoch: 16/20, Batch: 1300/1388, Loss: 1.1951\n",
      "Epoch: 16/20, Batch: 1350/1388, Loss: 1.0313\n",
      "Epoch: 16, Train Loss: 0.9645\n",
      "Epoch: 17/20, Batch: 0/1388, Loss: 0.9522\n",
      "Epoch: 17/20, Batch: 50/1388, Loss: 0.9671\n",
      "Epoch: 17/20, Batch: 100/1388, Loss: 1.4254\n",
      "Epoch: 17/20, Batch: 150/1388, Loss: 0.9312\n",
      "Epoch: 17/20, Batch: 200/1388, Loss: 1.0200\n",
      "Epoch: 17/20, Batch: 250/1388, Loss: 0.8575\n",
      "Epoch: 17/20, Batch: 300/1388, Loss: 0.9443\n",
      "Epoch: 17/20, Batch: 350/1388, Loss: 0.7837\n",
      "Epoch: 17/20, Batch: 400/1388, Loss: 0.9086\n",
      "Epoch: 17/20, Batch: 450/1388, Loss: 0.9878\n",
      "Epoch: 17/20, Batch: 500/1388, Loss: 1.0645\n",
      "Epoch: 17/20, Batch: 550/1388, Loss: 1.1092\n",
      "Epoch: 17/20, Batch: 600/1388, Loss: 1.1480\n",
      "Epoch: 17/20, Batch: 650/1388, Loss: 0.9011\n",
      "Epoch: 17/20, Batch: 700/1388, Loss: 1.1451\n",
      "Epoch: 17/20, Batch: 750/1388, Loss: 0.8032\n",
      "Epoch: 17/20, Batch: 800/1388, Loss: 0.7507\n",
      "Epoch: 17/20, Batch: 850/1388, Loss: 0.9334\n",
      "Epoch: 17/20, Batch: 900/1388, Loss: 0.7228\n",
      "Epoch: 17/20, Batch: 950/1388, Loss: 0.8339\n",
      "Epoch: 17/20, Batch: 1000/1388, Loss: 0.9552\n",
      "Epoch: 17/20, Batch: 1050/1388, Loss: 0.9702\n",
      "Epoch: 17/20, Batch: 1100/1388, Loss: 0.9092\n",
      "Epoch: 17/20, Batch: 1150/1388, Loss: 0.8811\n",
      "Epoch: 17/20, Batch: 1200/1388, Loss: 0.8458\n",
      "Epoch: 17/20, Batch: 1250/1388, Loss: 0.9338\n",
      "Epoch: 17/20, Batch: 1300/1388, Loss: 0.6970\n",
      "Epoch: 17/20, Batch: 1350/1388, Loss: 1.0393\n",
      "Epoch: 17, Train Loss: 0.9649\n",
      "Epoch: 18/20, Batch: 0/1388, Loss: 0.8635\n",
      "Epoch: 18/20, Batch: 50/1388, Loss: 0.8135\n",
      "Epoch: 18/20, Batch: 100/1388, Loss: 1.1502\n",
      "Epoch: 18/20, Batch: 150/1388, Loss: 0.7613\n",
      "Epoch: 18/20, Batch: 200/1388, Loss: 0.7350\n",
      "Epoch: 18/20, Batch: 250/1388, Loss: 0.9885\n",
      "Epoch: 18/20, Batch: 300/1388, Loss: 0.7210\n",
      "Epoch: 18/20, Batch: 350/1388, Loss: 0.7472\n",
      "Epoch: 18/20, Batch: 400/1388, Loss: 0.8419\n",
      "Epoch: 18/20, Batch: 450/1388, Loss: 0.7350\n",
      "Epoch: 18/20, Batch: 500/1388, Loss: 1.0679\n",
      "Epoch: 18/20, Batch: 550/1388, Loss: 0.9605\n",
      "Epoch: 18/20, Batch: 600/1388, Loss: 0.8666\n",
      "Epoch: 18/20, Batch: 650/1388, Loss: 0.7713\n",
      "Epoch: 18/20, Batch: 700/1388, Loss: 0.9834\n",
      "Epoch: 18/20, Batch: 750/1388, Loss: 0.9074\n",
      "Epoch: 18/20, Batch: 800/1388, Loss: 0.8812\n",
      "Epoch: 18/20, Batch: 850/1388, Loss: 1.0353\n",
      "Epoch: 18/20, Batch: 900/1388, Loss: 1.1991\n",
      "Epoch: 18/20, Batch: 950/1388, Loss: 0.8644\n",
      "Epoch: 18/20, Batch: 1000/1388, Loss: 0.9521\n",
      "Epoch: 18/20, Batch: 1050/1388, Loss: 0.9455\n",
      "Epoch: 18/20, Batch: 1100/1388, Loss: 1.0549\n",
      "Epoch: 18/20, Batch: 1150/1388, Loss: 1.0537\n",
      "Epoch: 18/20, Batch: 1200/1388, Loss: 0.8985\n",
      "Epoch: 18/20, Batch: 1250/1388, Loss: 0.7648\n",
      "Epoch: 18/20, Batch: 1300/1388, Loss: 1.2246\n",
      "Epoch: 18/20, Batch: 1350/1388, Loss: 1.0441\n",
      "Epoch: 18, Train Loss: 0.9632\n",
      "Epoch: 19/20, Batch: 0/1388, Loss: 0.8030\n",
      "Epoch: 19/20, Batch: 50/1388, Loss: 1.1276\n",
      "Epoch: 19/20, Batch: 100/1388, Loss: 0.7849\n",
      "Epoch: 19/20, Batch: 150/1388, Loss: 1.0496\n",
      "Epoch: 19/20, Batch: 200/1388, Loss: 1.0806\n",
      "Epoch: 19/20, Batch: 250/1388, Loss: 0.9149\n",
      "Epoch: 19/20, Batch: 300/1388, Loss: 0.6445\n",
      "Epoch: 19/20, Batch: 350/1388, Loss: 1.0176\n",
      "Epoch: 19/20, Batch: 400/1388, Loss: 0.7900\n",
      "Epoch: 19/20, Batch: 450/1388, Loss: 0.8601\n",
      "Epoch: 19/20, Batch: 500/1388, Loss: 1.1745\n",
      "Epoch: 19/20, Batch: 550/1388, Loss: 1.1959\n",
      "Epoch: 19/20, Batch: 600/1388, Loss: 1.0497\n",
      "Epoch: 19/20, Batch: 650/1388, Loss: 0.8373\n",
      "Epoch: 19/20, Batch: 700/1388, Loss: 1.0022\n",
      "Epoch: 19/20, Batch: 750/1388, Loss: 0.7049\n",
      "Epoch: 19/20, Batch: 800/1388, Loss: 0.9141\n",
      "Epoch: 19/20, Batch: 850/1388, Loss: 0.7109\n",
      "Epoch: 19/20, Batch: 900/1388, Loss: 1.2959\n",
      "Epoch: 19/20, Batch: 950/1388, Loss: 0.9395\n",
      "Epoch: 19/20, Batch: 1000/1388, Loss: 0.8795\n",
      "Epoch: 19/20, Batch: 1050/1388, Loss: 0.9630\n",
      "Epoch: 19/20, Batch: 1100/1388, Loss: 0.7143\n",
      "Epoch: 19/20, Batch: 1150/1388, Loss: 0.7477\n",
      "Epoch: 19/20, Batch: 1200/1388, Loss: 0.9001\n",
      "Epoch: 19/20, Batch: 1250/1388, Loss: 0.9492\n",
      "Epoch: 19/20, Batch: 1300/1388, Loss: 0.9816\n",
      "Epoch: 19/20, Batch: 1350/1388, Loss: 1.1999\n",
      "Epoch: 19, Train Loss: 0.9614\n",
      "Epoch: 20/20, Batch: 0/1388, Loss: 1.0551\n",
      "Epoch: 20/20, Batch: 50/1388, Loss: 1.3804\n",
      "Epoch: 20/20, Batch: 100/1388, Loss: 0.6743\n",
      "Epoch: 20/20, Batch: 150/1388, Loss: 0.8674\n",
      "Epoch: 20/20, Batch: 200/1388, Loss: 0.6822\n",
      "Epoch: 20/20, Batch: 250/1388, Loss: 1.0602\n",
      "Epoch: 20/20, Batch: 300/1388, Loss: 1.6803\n",
      "Epoch: 20/20, Batch: 350/1388, Loss: 0.8252\n",
      "Epoch: 20/20, Batch: 400/1388, Loss: 1.0076\n",
      "Epoch: 20/20, Batch: 450/1388, Loss: 0.7731\n",
      "Epoch: 20/20, Batch: 500/1388, Loss: 0.9366\n",
      "Epoch: 20/20, Batch: 550/1388, Loss: 0.8286\n",
      "Epoch: 20/20, Batch: 600/1388, Loss: 1.2286\n",
      "Epoch: 20/20, Batch: 650/1388, Loss: 1.1325\n",
      "Epoch: 20/20, Batch: 700/1388, Loss: 0.6867\n",
      "Epoch: 20/20, Batch: 750/1388, Loss: 1.0254\n",
      "Epoch: 20/20, Batch: 800/1388, Loss: 0.8433\n",
      "Epoch: 20/20, Batch: 850/1388, Loss: 1.1097\n",
      "Epoch: 20/20, Batch: 900/1388, Loss: 0.8504\n",
      "Epoch: 20/20, Batch: 950/1388, Loss: 1.3480\n",
      "Epoch: 20/20, Batch: 1000/1388, Loss: 0.7613\n",
      "Epoch: 20/20, Batch: 1050/1388, Loss: 0.8493\n",
      "Epoch: 20/20, Batch: 1100/1388, Loss: 1.4178\n",
      "Epoch: 20/20, Batch: 1150/1388, Loss: 0.8381\n",
      "Epoch: 20/20, Batch: 1200/1388, Loss: 1.3079\n",
      "Epoch: 20/20, Batch: 1250/1388, Loss: 0.7673\n",
      "Epoch: 20/20, Batch: 1300/1388, Loss: 0.9679\n",
      "Epoch: 20/20, Batch: 1350/1388, Loss: 1.1656\n",
      "Epoch: 20, Train Loss: 0.9624\n",
      "Training finished!\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "id": "G6Ee3DRuAihU",
    "outputId": "9fd3feee-fa91-48a7-f94a-dddb430d1cb4",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:05:20.434131Z",
     "start_time": "2025-11-05T04:05:19.706998Z"
    }
   },
   "source": [
    "weighted_model_2.eval()\n",
    "\n",
    "y_true_weighted_2 = []\n",
    "y_pred_weighted_2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = weighted_model_2(data)\n",
    "\n",
    "        y_true_weighted_2.extend(target.cpu().numpy())\n",
    "        y_pred_weighted_2.extend((output > 0.5).cpu().numpy())\n",
    "\n",
    "y_true_weighted_2 = np.array(y_true_weighted_2)\n",
    "y_pred_weighted_2 = np.array(y_pred_weighted_2)\n",
    "\n",
    "print(\"\\nClassification Report (Weighted 2):\")\n",
    "print(classification_report(y_true_weighted_2, y_pred_weighted_2))\n",
    "print(\"\\nConfusion Matrix (Weighted 2):\")\n",
    "cm_weighted_2 = confusion_matrix(y_true_weighted_2, y_pred_weighted_2)\n",
    "sns.heatmap(cm_weighted_2, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Weighted 2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.72      0.83     68971\n",
      "         1.0       0.23      0.82      0.36      7133\n",
      "\n",
      "    accuracy                           0.73     76104\n",
      "   macro avg       0.60      0.77      0.60     76104\n",
      "weighted avg       0.91      0.73      0.79     76104\n",
      "\n",
      "\n",
      "Confusion Matrix (Weighted 2):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 23.52222222222222, 'Predicted')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-pxS5j0AihU"
   },
   "source": [
    "#### train:test = 6:4"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Y3Ev-34AihU",
    "outputId": "8f7659fe-fade-4a6b-9242-cc735362dd56",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:06:14.505166Z",
     "start_time": "2025-11-05T04:05:20.505502Z"
    }
   },
   "source": [
    "total_size = len(X)\n",
    "train_size = int(0.4 * total_size)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "dataset = HeartDiseaseDataset(X, y)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "input_features = X.shape[1]\n",
    "\n",
    "weighted_model_3 = HeartDiseaseMLPClassifier(input_size=input_features, class_frequencies=class_frequencies).to(device)\n",
    "\n",
    "optimizer = optim.Adam(weighted_model_3.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "num_epochs = 20\n",
    "weighted_train_losses = []\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    weighted_model_3.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = weighted_model_3(data)\n",
    "\n",
    "        target = target.float()\n",
    "        output = output.float()\n",
    "        loss = weighted_model_3.get_weighted_loss(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    weighted_train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "print('Training finished!')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch: 1/20, Batch: 0/793, Loss: 1.4751\n",
      "Epoch: 1/20, Batch: 50/793, Loss: 0.8794\n",
      "Epoch: 1/20, Batch: 100/793, Loss: 1.2703\n",
      "Epoch: 1/20, Batch: 150/793, Loss: 0.8893\n",
      "Epoch: 1/20, Batch: 200/793, Loss: 1.0495\n",
      "Epoch: 1/20, Batch: 250/793, Loss: 0.9784\n",
      "Epoch: 1/20, Batch: 300/793, Loss: 0.8098\n",
      "Epoch: 1/20, Batch: 350/793, Loss: 1.1898\n",
      "Epoch: 1/20, Batch: 400/793, Loss: 1.0679\n",
      "Epoch: 1/20, Batch: 450/793, Loss: 1.1376\n",
      "Epoch: 1/20, Batch: 500/793, Loss: 0.9281\n",
      "Epoch: 1/20, Batch: 550/793, Loss: 1.3112\n",
      "Epoch: 1/20, Batch: 600/793, Loss: 0.8355\n",
      "Epoch: 1/20, Batch: 650/793, Loss: 1.1522\n",
      "Epoch: 1/20, Batch: 700/793, Loss: 0.9090\n",
      "Epoch: 1/20, Batch: 750/793, Loss: 0.9884\n",
      "Epoch: 1, Train Loss: 1.0424\n",
      "Epoch: 2/20, Batch: 0/793, Loss: 0.7794\n",
      "Epoch: 2/20, Batch: 50/793, Loss: 1.0611\n",
      "Epoch: 2/20, Batch: 100/793, Loss: 0.8762\n",
      "Epoch: 2/20, Batch: 150/793, Loss: 1.1038\n",
      "Epoch: 2/20, Batch: 200/793, Loss: 1.0301\n",
      "Epoch: 2/20, Batch: 250/793, Loss: 0.9204\n",
      "Epoch: 2/20, Batch: 300/793, Loss: 0.9983\n",
      "Epoch: 2/20, Batch: 350/793, Loss: 0.9525\n",
      "Epoch: 2/20, Batch: 400/793, Loss: 0.8680\n",
      "Epoch: 2/20, Batch: 450/793, Loss: 0.9688\n",
      "Epoch: 2/20, Batch: 500/793, Loss: 0.8521\n",
      "Epoch: 2/20, Batch: 550/793, Loss: 0.9679\n",
      "Epoch: 2/20, Batch: 600/793, Loss: 1.2924\n",
      "Epoch: 2/20, Batch: 650/793, Loss: 1.1232\n",
      "Epoch: 2/20, Batch: 700/793, Loss: 0.8770\n",
      "Epoch: 2/20, Batch: 750/793, Loss: 0.9899\n",
      "Epoch: 2, Train Loss: 0.9933\n",
      "Epoch: 3/20, Batch: 0/793, Loss: 1.0818\n",
      "Epoch: 3/20, Batch: 50/793, Loss: 0.7034\n",
      "Epoch: 3/20, Batch: 100/793, Loss: 0.8374\n",
      "Epoch: 3/20, Batch: 150/793, Loss: 0.8801\n",
      "Epoch: 3/20, Batch: 200/793, Loss: 1.0286\n",
      "Epoch: 3/20, Batch: 250/793, Loss: 1.0080\n",
      "Epoch: 3/20, Batch: 300/793, Loss: 0.8246\n",
      "Epoch: 3/20, Batch: 350/793, Loss: 1.0180\n",
      "Epoch: 3/20, Batch: 400/793, Loss: 0.7916\n",
      "Epoch: 3/20, Batch: 450/793, Loss: 0.9822\n",
      "Epoch: 3/20, Batch: 500/793, Loss: 0.9663\n",
      "Epoch: 3/20, Batch: 550/793, Loss: 1.2172\n",
      "Epoch: 3/20, Batch: 600/793, Loss: 0.9251\n",
      "Epoch: 3/20, Batch: 650/793, Loss: 1.5365\n",
      "Epoch: 3/20, Batch: 700/793, Loss: 0.9803\n",
      "Epoch: 3/20, Batch: 750/793, Loss: 1.1433\n",
      "Epoch: 3, Train Loss: 0.9835\n",
      "Epoch: 4/20, Batch: 0/793, Loss: 1.5086\n",
      "Epoch: 4/20, Batch: 50/793, Loss: 0.6635\n",
      "Epoch: 4/20, Batch: 100/793, Loss: 0.8355\n",
      "Epoch: 4/20, Batch: 150/793, Loss: 0.9918\n",
      "Epoch: 4/20, Batch: 200/793, Loss: 0.8815\n",
      "Epoch: 4/20, Batch: 250/793, Loss: 1.0659\n",
      "Epoch: 4/20, Batch: 300/793, Loss: 1.1431\n",
      "Epoch: 4/20, Batch: 350/793, Loss: 1.0439\n",
      "Epoch: 4/20, Batch: 400/793, Loss: 0.7318\n",
      "Epoch: 4/20, Batch: 450/793, Loss: 0.8165\n",
      "Epoch: 4/20, Batch: 500/793, Loss: 0.8013\n",
      "Epoch: 4/20, Batch: 550/793, Loss: 1.1342\n",
      "Epoch: 4/20, Batch: 600/793, Loss: 1.1255\n",
      "Epoch: 4/20, Batch: 650/793, Loss: 1.0480\n",
      "Epoch: 4/20, Batch: 700/793, Loss: 0.7538\n",
      "Epoch: 4/20, Batch: 750/793, Loss: 1.6109\n",
      "Epoch: 4, Train Loss: 0.9812\n",
      "Epoch: 5/20, Batch: 0/793, Loss: 1.2093\n",
      "Epoch: 5/20, Batch: 50/793, Loss: 0.8674\n",
      "Epoch: 5/20, Batch: 100/793, Loss: 1.1919\n",
      "Epoch: 5/20, Batch: 150/793, Loss: 1.4292\n",
      "Epoch: 5/20, Batch: 200/793, Loss: 0.7329\n",
      "Epoch: 5/20, Batch: 250/793, Loss: 0.7683\n",
      "Epoch: 5/20, Batch: 300/793, Loss: 0.9036\n",
      "Epoch: 5/20, Batch: 350/793, Loss: 1.0079\n",
      "Epoch: 5/20, Batch: 400/793, Loss: 0.9420\n",
      "Epoch: 5/20, Batch: 450/793, Loss: 1.1490\n",
      "Epoch: 5/20, Batch: 500/793, Loss: 1.1497\n",
      "Epoch: 5/20, Batch: 550/793, Loss: 1.0318\n",
      "Epoch: 5/20, Batch: 600/793, Loss: 0.9739\n",
      "Epoch: 5/20, Batch: 650/793, Loss: 0.7525\n",
      "Epoch: 5/20, Batch: 700/793, Loss: 0.8045\n",
      "Epoch: 5/20, Batch: 750/793, Loss: 1.0703\n",
      "Epoch: 5, Train Loss: 0.9795\n",
      "Epoch: 6/20, Batch: 0/793, Loss: 1.3608\n",
      "Epoch: 6/20, Batch: 50/793, Loss: 0.9320\n",
      "Epoch: 6/20, Batch: 100/793, Loss: 0.8173\n",
      "Epoch: 6/20, Batch: 150/793, Loss: 1.0398\n",
      "Epoch: 6/20, Batch: 200/793, Loss: 1.2127\n",
      "Epoch: 6/20, Batch: 250/793, Loss: 1.8083\n",
      "Epoch: 6/20, Batch: 300/793, Loss: 1.5388\n",
      "Epoch: 6/20, Batch: 350/793, Loss: 0.6761\n",
      "Epoch: 6/20, Batch: 400/793, Loss: 1.1508\n",
      "Epoch: 6/20, Batch: 450/793, Loss: 0.9360\n",
      "Epoch: 6/20, Batch: 500/793, Loss: 0.9402\n",
      "Epoch: 6/20, Batch: 550/793, Loss: 0.8371\n",
      "Epoch: 6/20, Batch: 600/793, Loss: 0.8575\n",
      "Epoch: 6/20, Batch: 650/793, Loss: 1.0011\n",
      "Epoch: 6/20, Batch: 700/793, Loss: 1.1825\n",
      "Epoch: 6/20, Batch: 750/793, Loss: 0.9733\n",
      "Epoch: 6, Train Loss: 0.9754\n",
      "Epoch: 7/20, Batch: 0/793, Loss: 0.7198\n",
      "Epoch: 7/20, Batch: 50/793, Loss: 1.4010\n",
      "Epoch: 7/20, Batch: 100/793, Loss: 0.9762\n",
      "Epoch: 7/20, Batch: 150/793, Loss: 1.0388\n",
      "Epoch: 7/20, Batch: 200/793, Loss: 1.1327\n",
      "Epoch: 7/20, Batch: 250/793, Loss: 0.8981\n",
      "Epoch: 7/20, Batch: 300/793, Loss: 0.9035\n",
      "Epoch: 7/20, Batch: 350/793, Loss: 0.8323\n",
      "Epoch: 7/20, Batch: 400/793, Loss: 0.9086\n",
      "Epoch: 7/20, Batch: 450/793, Loss: 0.8793\n",
      "Epoch: 7/20, Batch: 500/793, Loss: 1.0543\n",
      "Epoch: 7/20, Batch: 550/793, Loss: 1.2254\n",
      "Epoch: 7/20, Batch: 600/793, Loss: 0.7354\n",
      "Epoch: 7/20, Batch: 650/793, Loss: 0.8968\n",
      "Epoch: 7/20, Batch: 700/793, Loss: 0.7257\n",
      "Epoch: 7/20, Batch: 750/793, Loss: 0.9601\n",
      "Epoch: 7, Train Loss: 0.9747\n",
      "Epoch: 8/20, Batch: 0/793, Loss: 0.9057\n",
      "Epoch: 8/20, Batch: 50/793, Loss: 0.7179\n",
      "Epoch: 8/20, Batch: 100/793, Loss: 0.8702\n",
      "Epoch: 8/20, Batch: 150/793, Loss: 0.9367\n",
      "Epoch: 8/20, Batch: 200/793, Loss: 0.6531\n",
      "Epoch: 8/20, Batch: 250/793, Loss: 1.0691\n",
      "Epoch: 8/20, Batch: 300/793, Loss: 0.8078\n",
      "Epoch: 8/20, Batch: 350/793, Loss: 1.1562\n",
      "Epoch: 8/20, Batch: 400/793, Loss: 0.9056\n",
      "Epoch: 8/20, Batch: 450/793, Loss: 1.1925\n",
      "Epoch: 8/20, Batch: 500/793, Loss: 1.3844\n",
      "Epoch: 8/20, Batch: 550/793, Loss: 0.8765\n",
      "Epoch: 8/20, Batch: 600/793, Loss: 1.0752\n",
      "Epoch: 8/20, Batch: 650/793, Loss: 0.9148\n",
      "Epoch: 8/20, Batch: 700/793, Loss: 1.4068\n",
      "Epoch: 8/20, Batch: 750/793, Loss: 1.0098\n",
      "Epoch: 8, Train Loss: 0.9733\n",
      "Epoch: 9/20, Batch: 0/793, Loss: 1.0546\n",
      "Epoch: 9/20, Batch: 50/793, Loss: 1.0569\n",
      "Epoch: 9/20, Batch: 100/793, Loss: 0.8186\n",
      "Epoch: 9/20, Batch: 150/793, Loss: 0.9170\n",
      "Epoch: 9/20, Batch: 200/793, Loss: 0.7430\n",
      "Epoch: 9/20, Batch: 250/793, Loss: 1.1533\n",
      "Epoch: 9/20, Batch: 300/793, Loss: 0.9284\n",
      "Epoch: 9/20, Batch: 350/793, Loss: 1.1076\n",
      "Epoch: 9/20, Batch: 400/793, Loss: 0.8721\n",
      "Epoch: 9/20, Batch: 450/793, Loss: 1.1434\n",
      "Epoch: 9/20, Batch: 500/793, Loss: 0.8753\n",
      "Epoch: 9/20, Batch: 550/793, Loss: 1.1242\n",
      "Epoch: 9/20, Batch: 600/793, Loss: 0.8319\n",
      "Epoch: 9/20, Batch: 650/793, Loss: 0.8550\n",
      "Epoch: 9/20, Batch: 700/793, Loss: 1.0210\n",
      "Epoch: 9/20, Batch: 750/793, Loss: 0.9388\n",
      "Epoch: 9, Train Loss: 0.9753\n",
      "Epoch: 10/20, Batch: 0/793, Loss: 0.9601\n",
      "Epoch: 10/20, Batch: 50/793, Loss: 0.9713\n",
      "Epoch: 10/20, Batch: 100/793, Loss: 1.4084\n",
      "Epoch: 10/20, Batch: 150/793, Loss: 0.8973\n",
      "Epoch: 10/20, Batch: 200/793, Loss: 1.1950\n",
      "Epoch: 10/20, Batch: 250/793, Loss: 1.1548\n",
      "Epoch: 10/20, Batch: 300/793, Loss: 1.1925\n",
      "Epoch: 10/20, Batch: 350/793, Loss: 0.8770\n",
      "Epoch: 10/20, Batch: 400/793, Loss: 0.9641\n",
      "Epoch: 10/20, Batch: 450/793, Loss: 1.4275\n",
      "Epoch: 10/20, Batch: 500/793, Loss: 0.7072\n",
      "Epoch: 10/20, Batch: 550/793, Loss: 1.1858\n",
      "Epoch: 10/20, Batch: 600/793, Loss: 1.0186\n",
      "Epoch: 10/20, Batch: 650/793, Loss: 0.7710\n",
      "Epoch: 10/20, Batch: 700/793, Loss: 0.7509\n",
      "Epoch: 10/20, Batch: 750/793, Loss: 0.8341\n",
      "Epoch: 10, Train Loss: 0.9699\n",
      "Epoch: 11/20, Batch: 0/793, Loss: 1.0415\n",
      "Epoch: 11/20, Batch: 50/793, Loss: 0.9286\n",
      "Epoch: 11/20, Batch: 100/793, Loss: 0.8385\n",
      "Epoch: 11/20, Batch: 150/793, Loss: 0.8292\n",
      "Epoch: 11/20, Batch: 200/793, Loss: 0.7349\n",
      "Epoch: 11/20, Batch: 250/793, Loss: 1.5781\n",
      "Epoch: 11/20, Batch: 300/793, Loss: 0.8813\n",
      "Epoch: 11/20, Batch: 350/793, Loss: 0.8479\n",
      "Epoch: 11/20, Batch: 400/793, Loss: 0.7755\n",
      "Epoch: 11/20, Batch: 450/793, Loss: 0.8227\n",
      "Epoch: 11/20, Batch: 500/793, Loss: 1.0791\n",
      "Epoch: 11/20, Batch: 550/793, Loss: 0.8195\n",
      "Epoch: 11/20, Batch: 600/793, Loss: 1.1086\n",
      "Epoch: 11/20, Batch: 650/793, Loss: 1.9256\n",
      "Epoch: 11/20, Batch: 700/793, Loss: 1.1200\n",
      "Epoch: 11/20, Batch: 750/793, Loss: 1.3135\n",
      "Epoch: 11, Train Loss: 0.9695\n",
      "Epoch: 12/20, Batch: 0/793, Loss: 1.0004\n",
      "Epoch: 12/20, Batch: 50/793, Loss: 1.0812\n",
      "Epoch: 12/20, Batch: 100/793, Loss: 0.7663\n",
      "Epoch: 12/20, Batch: 150/793, Loss: 0.9087\n",
      "Epoch: 12/20, Batch: 200/793, Loss: 1.3783\n",
      "Epoch: 12/20, Batch: 250/793, Loss: 0.8130\n",
      "Epoch: 12/20, Batch: 300/793, Loss: 0.9300\n",
      "Epoch: 12/20, Batch: 350/793, Loss: 1.3634\n",
      "Epoch: 12/20, Batch: 400/793, Loss: 1.0532\n",
      "Epoch: 12/20, Batch: 450/793, Loss: 0.8808\n",
      "Epoch: 12/20, Batch: 500/793, Loss: 1.3213\n",
      "Epoch: 12/20, Batch: 550/793, Loss: 0.8230\n",
      "Epoch: 12/20, Batch: 600/793, Loss: 0.7797\n",
      "Epoch: 12/20, Batch: 650/793, Loss: 1.4289\n",
      "Epoch: 12/20, Batch: 700/793, Loss: 0.7706\n",
      "Epoch: 12/20, Batch: 750/793, Loss: 1.1157\n",
      "Epoch: 12, Train Loss: 0.9688\n",
      "Epoch: 13/20, Batch: 0/793, Loss: 1.0319\n",
      "Epoch: 13/20, Batch: 50/793, Loss: 1.0096\n",
      "Epoch: 13/20, Batch: 100/793, Loss: 1.1724\n",
      "Epoch: 13/20, Batch: 150/793, Loss: 1.1696\n",
      "Epoch: 13/20, Batch: 200/793, Loss: 0.7306\n",
      "Epoch: 13/20, Batch: 250/793, Loss: 0.8624\n",
      "Epoch: 13/20, Batch: 300/793, Loss: 0.8594\n",
      "Epoch: 13/20, Batch: 350/793, Loss: 0.9219\n",
      "Epoch: 13/20, Batch: 400/793, Loss: 0.7640\n",
      "Epoch: 13/20, Batch: 450/793, Loss: 1.0590\n",
      "Epoch: 13/20, Batch: 500/793, Loss: 0.8156\n",
      "Epoch: 13/20, Batch: 550/793, Loss: 0.7621\n",
      "Epoch: 13/20, Batch: 600/793, Loss: 0.7480\n",
      "Epoch: 13/20, Batch: 650/793, Loss: 1.1387\n",
      "Epoch: 13/20, Batch: 700/793, Loss: 0.8466\n",
      "Epoch: 13/20, Batch: 750/793, Loss: 0.9046\n",
      "Epoch: 13, Train Loss: 0.9682\n",
      "Epoch: 14/20, Batch: 0/793, Loss: 0.9288\n",
      "Epoch: 14/20, Batch: 50/793, Loss: 0.8507\n",
      "Epoch: 14/20, Batch: 100/793, Loss: 1.7004\n",
      "Epoch: 14/20, Batch: 150/793, Loss: 0.7887\n",
      "Epoch: 14/20, Batch: 200/793, Loss: 0.8881\n",
      "Epoch: 14/20, Batch: 250/793, Loss: 1.3576\n",
      "Epoch: 14/20, Batch: 300/793, Loss: 0.9140\n",
      "Epoch: 14/20, Batch: 350/793, Loss: 1.0250\n",
      "Epoch: 14/20, Batch: 400/793, Loss: 0.9391\n",
      "Epoch: 14/20, Batch: 450/793, Loss: 1.1303\n",
      "Epoch: 14/20, Batch: 500/793, Loss: 0.9481\n",
      "Epoch: 14/20, Batch: 550/793, Loss: 1.1353\n",
      "Epoch: 14/20, Batch: 600/793, Loss: 1.4687\n",
      "Epoch: 14/20, Batch: 650/793, Loss: 0.7813\n",
      "Epoch: 14/20, Batch: 700/793, Loss: 0.8450\n",
      "Epoch: 14/20, Batch: 750/793, Loss: 1.0034\n",
      "Epoch: 14, Train Loss: 0.9690\n",
      "Epoch: 15/20, Batch: 0/793, Loss: 0.8019\n",
      "Epoch: 15/20, Batch: 50/793, Loss: 0.8836\n",
      "Epoch: 15/20, Batch: 100/793, Loss: 0.6951\n",
      "Epoch: 15/20, Batch: 150/793, Loss: 0.7587\n",
      "Epoch: 15/20, Batch: 200/793, Loss: 0.9517\n",
      "Epoch: 15/20, Batch: 250/793, Loss: 1.0770\n",
      "Epoch: 15/20, Batch: 300/793, Loss: 0.8054\n",
      "Epoch: 15/20, Batch: 350/793, Loss: 1.1739\n",
      "Epoch: 15/20, Batch: 400/793, Loss: 0.8869\n",
      "Epoch: 15/20, Batch: 450/793, Loss: 1.2109\n",
      "Epoch: 15/20, Batch: 500/793, Loss: 0.7235\n",
      "Epoch: 15/20, Batch: 550/793, Loss: 0.8193\n",
      "Epoch: 15/20, Batch: 600/793, Loss: 0.7709\n",
      "Epoch: 15/20, Batch: 650/793, Loss: 0.8338\n",
      "Epoch: 15/20, Batch: 700/793, Loss: 1.0099\n",
      "Epoch: 15/20, Batch: 750/793, Loss: 0.9492\n",
      "Epoch: 15, Train Loss: 0.9699\n",
      "Epoch: 16/20, Batch: 0/793, Loss: 0.9708\n",
      "Epoch: 16/20, Batch: 50/793, Loss: 1.0667\n",
      "Epoch: 16/20, Batch: 100/793, Loss: 0.8393\n",
      "Epoch: 16/20, Batch: 150/793, Loss: 0.9063\n",
      "Epoch: 16/20, Batch: 200/793, Loss: 0.7602\n",
      "Epoch: 16/20, Batch: 250/793, Loss: 0.8597\n",
      "Epoch: 16/20, Batch: 300/793, Loss: 0.9873\n",
      "Epoch: 16/20, Batch: 350/793, Loss: 0.7571\n",
      "Epoch: 16/20, Batch: 400/793, Loss: 1.0018\n",
      "Epoch: 16/20, Batch: 450/793, Loss: 1.1989\n",
      "Epoch: 16/20, Batch: 500/793, Loss: 0.9759\n",
      "Epoch: 16/20, Batch: 550/793, Loss: 0.9135\n",
      "Epoch: 16/20, Batch: 600/793, Loss: 0.6827\n",
      "Epoch: 16/20, Batch: 650/793, Loss: 1.1068\n",
      "Epoch: 16/20, Batch: 700/793, Loss: 0.8359\n",
      "Epoch: 16/20, Batch: 750/793, Loss: 1.3050\n",
      "Epoch: 16, Train Loss: 0.9701\n",
      "Epoch: 17/20, Batch: 0/793, Loss: 0.7500\n",
      "Epoch: 17/20, Batch: 50/793, Loss: 0.7378\n",
      "Epoch: 17/20, Batch: 100/793, Loss: 0.8640\n",
      "Epoch: 17/20, Batch: 150/793, Loss: 0.9792\n",
      "Epoch: 17/20, Batch: 200/793, Loss: 0.9588\n",
      "Epoch: 17/20, Batch: 250/793, Loss: 1.1951\n",
      "Epoch: 17/20, Batch: 300/793, Loss: 0.9574\n",
      "Epoch: 17/20, Batch: 350/793, Loss: 0.7406\n",
      "Epoch: 17/20, Batch: 400/793, Loss: 1.0070\n",
      "Epoch: 17/20, Batch: 450/793, Loss: 1.4417\n",
      "Epoch: 17/20, Batch: 500/793, Loss: 0.6787\n",
      "Epoch: 17/20, Batch: 550/793, Loss: 0.9210\n",
      "Epoch: 17/20, Batch: 600/793, Loss: 0.8001\n",
      "Epoch: 17/20, Batch: 650/793, Loss: 1.0703\n",
      "Epoch: 17/20, Batch: 700/793, Loss: 0.8773\n",
      "Epoch: 17/20, Batch: 750/793, Loss: 0.9776\n",
      "Epoch: 17, Train Loss: 0.9673\n",
      "Epoch: 18/20, Batch: 0/793, Loss: 1.0026\n",
      "Epoch: 18/20, Batch: 50/793, Loss: 1.3595\n",
      "Epoch: 18/20, Batch: 100/793, Loss: 1.1499\n",
      "Epoch: 18/20, Batch: 150/793, Loss: 0.6819\n",
      "Epoch: 18/20, Batch: 200/793, Loss: 0.8974\n",
      "Epoch: 18/20, Batch: 250/793, Loss: 0.9365\n",
      "Epoch: 18/20, Batch: 300/793, Loss: 0.9037\n",
      "Epoch: 18/20, Batch: 350/793, Loss: 1.2539\n",
      "Epoch: 18/20, Batch: 400/793, Loss: 1.0941\n",
      "Epoch: 18/20, Batch: 450/793, Loss: 0.8273\n",
      "Epoch: 18/20, Batch: 500/793, Loss: 0.9033\n",
      "Epoch: 18/20, Batch: 550/793, Loss: 1.2858\n",
      "Epoch: 18/20, Batch: 600/793, Loss: 0.7932\n",
      "Epoch: 18/20, Batch: 650/793, Loss: 1.0730\n",
      "Epoch: 18/20, Batch: 700/793, Loss: 1.1478\n",
      "Epoch: 18/20, Batch: 750/793, Loss: 0.8839\n",
      "Epoch: 18, Train Loss: 0.9650\n",
      "Epoch: 19/20, Batch: 0/793, Loss: 0.9294\n",
      "Epoch: 19/20, Batch: 50/793, Loss: 1.0999\n",
      "Epoch: 19/20, Batch: 100/793, Loss: 0.8797\n",
      "Epoch: 19/20, Batch: 150/793, Loss: 0.8156\n",
      "Epoch: 19/20, Batch: 200/793, Loss: 0.8667\n",
      "Epoch: 19/20, Batch: 250/793, Loss: 0.9964\n",
      "Epoch: 19/20, Batch: 300/793, Loss: 0.9698\n",
      "Epoch: 19/20, Batch: 350/793, Loss: 0.9190\n",
      "Epoch: 19/20, Batch: 400/793, Loss: 0.6435\n",
      "Epoch: 19/20, Batch: 450/793, Loss: 1.0978\n",
      "Epoch: 19/20, Batch: 500/793, Loss: 0.8770\n",
      "Epoch: 19/20, Batch: 550/793, Loss: 0.7332\n",
      "Epoch: 19/20, Batch: 600/793, Loss: 1.1464\n",
      "Epoch: 19/20, Batch: 650/793, Loss: 0.8176\n",
      "Epoch: 19/20, Batch: 700/793, Loss: 0.8757\n",
      "Epoch: 19/20, Batch: 750/793, Loss: 1.2315\n",
      "Epoch: 19, Train Loss: 0.9643\n",
      "Epoch: 20/20, Batch: 0/793, Loss: 1.0913\n",
      "Epoch: 20/20, Batch: 50/793, Loss: 1.1155\n",
      "Epoch: 20/20, Batch: 100/793, Loss: 0.7927\n",
      "Epoch: 20/20, Batch: 150/793, Loss: 0.9621\n",
      "Epoch: 20/20, Batch: 200/793, Loss: 0.8554\n",
      "Epoch: 20/20, Batch: 250/793, Loss: 0.9841\n",
      "Epoch: 20/20, Batch: 300/793, Loss: 1.4297\n",
      "Epoch: 20/20, Batch: 350/793, Loss: 1.5600\n",
      "Epoch: 20/20, Batch: 400/793, Loss: 1.0161\n",
      "Epoch: 20/20, Batch: 450/793, Loss: 1.1742\n",
      "Epoch: 20/20, Batch: 500/793, Loss: 0.7550\n",
      "Epoch: 20/20, Batch: 550/793, Loss: 0.6603\n",
      "Epoch: 20/20, Batch: 600/793, Loss: 1.1881\n",
      "Epoch: 20/20, Batch: 650/793, Loss: 0.6607\n",
      "Epoch: 20/20, Batch: 700/793, Loss: 0.9244\n",
      "Epoch: 20/20, Batch: 750/793, Loss: 0.9036\n",
      "Epoch: 20, Train Loss: 0.9663\n",
      "Training finished!\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "fpQFkBRuAihV",
    "outputId": "11167ed3-5ecd-4d95-bd88-cb7ff7e9c9ab",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:06:15.768200Z",
     "start_time": "2025-11-05T04:06:14.568061Z"
    }
   },
   "source": [
    "weighted_model_3.eval()\n",
    "\n",
    "y_true_weighted_3 = []\n",
    "y_pred_weighted_3 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = weighted_model_3(data)\n",
    "\n",
    "        y_true_weighted_3.extend(target.cpu().numpy())\n",
    "        y_pred_weighted_3.extend((output > 0.5).cpu().numpy())\n",
    "\n",
    "y_true_weighted_3 = np.array(y_true_weighted_3)\n",
    "y_pred_weighted_3 = np.array(y_pred_weighted_3)\n",
    "\n",
    "print(\"\\nClassification Report (Weighted 3):\")\n",
    "print(classification_report(y_true_weighted_3, y_pred_weighted_3))\n",
    "print(\"\\nConfusion Matrix (Weighted 3):\")\n",
    "cm_weighted_3 = confusion_matrix(y_true_weighted_3, y_pred_weighted_3)\n",
    "sns.heatmap(cm_weighted_3, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Weighted 3)')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Weighted 3):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.71      0.82    137899\n",
      "         1.0       0.23      0.84      0.36     14309\n",
      "\n",
      "    accuracy                           0.72    152208\n",
      "   macro avg       0.60      0.77      0.59    152208\n",
      "weighted avg       0.91      0.72      0.78    152208\n",
      "\n",
      "\n",
      "Confusion Matrix (Weighted 3):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mdNjIobAihV"
   },
   "source": [
    "## Dimensional Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnuM2p-KAihW"
   },
   "source": [
    "### train:test = 4:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcZv4bDZAihW"
   },
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KAQSaZDsAihW",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:06:16.434902Z",
     "start_time": "2025-11-05T04:06:15.864940Z"
    }
   },
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "std = StandardScaler()\n",
    "X_train_scaled = std.fit_transform(X_train)\n",
    "X_test_scaled = std.transform(X_test)\n",
    "\n",
    "lda = LDA(n_components=1)\n",
    "X_train_lda = lda.fit_transform(X_train_scaled, y_train)\n",
    "X_test_lda = lda.transform(X_test_scaled)\n",
    "\n",
    "train_dataset = HeartDiseaseDataset(X_train_lda, y_train)\n",
    "test_dataset = HeartDiseaseDataset(X_test_lda, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtMVQ4SBAihW",
    "outputId": "62ca787c-2376-47bb-c96b-1d4b80ba3def",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:07:57.693740Z",
     "start_time": "2025-11-05T04:06:16.472681Z"
    }
   },
   "source": [
    "class_0_frequency = np.sum(y_train == 0) / len(y_train)\n",
    "class_1_frequency = np.sum(y_train == 1) / len(y_train)\n",
    "class_frequencies = [class_0_frequency, class_1_frequency]\n",
    "print(f\"Class frequencies: {class_frequencies}\")\n",
    "\n",
    "input_features = X_train_lda.shape[1]\n",
    "\n",
    "weighted_model = HeartDiseaseMLPClassifier(input_size=input_features, class_frequencies=class_frequencies).to(device)\n",
    "\n",
    "optimizer = optim.Adam(weighted_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "num_epochs = 20\n",
    "weighted_train_losses = []\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    weighted_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = weighted_model(data)\n",
    "\n",
    "        target = target.float()\n",
    "        output = output.float()\n",
    "        loss = weighted_model.get_weighted_loss(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    weighted_train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "print('Training finished!')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class frequencies: [np.float64(0.9058163828445286), np.float64(0.09418361715547147)]\n",
      "\n",
      "Starting training...\n",
      "Epoch: 1/20, Batch: 0/1586, Loss: 1.4922\n",
      "Epoch: 1/20, Batch: 50/1586, Loss: 1.1024\n",
      "Epoch: 1/20, Batch: 100/1586, Loss: 1.2312\n",
      "Epoch: 1/20, Batch: 150/1586, Loss: 1.1032\n",
      "Epoch: 1/20, Batch: 200/1586, Loss: 1.1683\n",
      "Epoch: 1/20, Batch: 250/1586, Loss: 0.9839\n",
      "Epoch: 1/20, Batch: 300/1586, Loss: 0.6296\n",
      "Epoch: 1/20, Batch: 350/1586, Loss: 0.8645\n",
      "Epoch: 1/20, Batch: 400/1586, Loss: 0.9037\n",
      "Epoch: 1/20, Batch: 450/1586, Loss: 1.1042\n",
      "Epoch: 1/20, Batch: 500/1586, Loss: 1.5702\n",
      "Epoch: 1/20, Batch: 550/1586, Loss: 1.0814\n",
      "Epoch: 1/20, Batch: 600/1586, Loss: 0.9109\n",
      "Epoch: 1/20, Batch: 650/1586, Loss: 1.0043\n",
      "Epoch: 1/20, Batch: 700/1586, Loss: 1.0972\n",
      "Epoch: 1/20, Batch: 750/1586, Loss: 0.8656\n",
      "Epoch: 1/20, Batch: 800/1586, Loss: 0.8819\n",
      "Epoch: 1/20, Batch: 850/1586, Loss: 1.0515\n",
      "Epoch: 1/20, Batch: 900/1586, Loss: 0.8900\n",
      "Epoch: 1/20, Batch: 950/1586, Loss: 0.8843\n",
      "Epoch: 1/20, Batch: 1000/1586, Loss: 1.0651\n",
      "Epoch: 1/20, Batch: 1050/1586, Loss: 0.8351\n",
      "Epoch: 1/20, Batch: 1100/1586, Loss: 0.9626\n",
      "Epoch: 1/20, Batch: 1150/1586, Loss: 0.8002\n",
      "Epoch: 1/20, Batch: 1200/1586, Loss: 0.9110\n",
      "Epoch: 1/20, Batch: 1250/1586, Loss: 0.6480\n",
      "Epoch: 1/20, Batch: 1300/1586, Loss: 1.3208\n",
      "Epoch: 1/20, Batch: 1350/1586, Loss: 1.2526\n",
      "Epoch: 1/20, Batch: 1400/1586, Loss: 1.0437\n",
      "Epoch: 1/20, Batch: 1450/1586, Loss: 0.8619\n",
      "Epoch: 1/20, Batch: 1500/1586, Loss: 1.0160\n",
      "Epoch: 1/20, Batch: 1550/1586, Loss: 0.8215\n",
      "Epoch: 1, Train Loss: 0.9969\n",
      "Epoch: 2/20, Batch: 0/1586, Loss: 0.8814\n",
      "Epoch: 2/20, Batch: 50/1586, Loss: 1.3642\n",
      "Epoch: 2/20, Batch: 100/1586, Loss: 1.1442\n",
      "Epoch: 2/20, Batch: 150/1586, Loss: 0.9200\n",
      "Epoch: 2/20, Batch: 200/1586, Loss: 1.1281\n",
      "Epoch: 2/20, Batch: 250/1586, Loss: 0.9530\n",
      "Epoch: 2/20, Batch: 300/1586, Loss: 1.2677\n",
      "Epoch: 2/20, Batch: 350/1586, Loss: 1.0301\n",
      "Epoch: 2/20, Batch: 400/1586, Loss: 0.9106\n",
      "Epoch: 2/20, Batch: 450/1586, Loss: 0.9702\n",
      "Epoch: 2/20, Batch: 500/1586, Loss: 0.8665\n",
      "Epoch: 2/20, Batch: 550/1586, Loss: 0.9631\n",
      "Epoch: 2/20, Batch: 600/1586, Loss: 0.8527\n",
      "Epoch: 2/20, Batch: 650/1586, Loss: 1.0439\n",
      "Epoch: 2/20, Batch: 700/1586, Loss: 0.8229\n",
      "Epoch: 2/20, Batch: 750/1586, Loss: 0.8841\n",
      "Epoch: 2/20, Batch: 800/1586, Loss: 0.9086\n",
      "Epoch: 2/20, Batch: 850/1586, Loss: 0.9783\n",
      "Epoch: 2/20, Batch: 900/1586, Loss: 0.7879\n",
      "Epoch: 2/20, Batch: 950/1586, Loss: 1.1188\n",
      "Epoch: 2/20, Batch: 1000/1586, Loss: 0.9159\n",
      "Epoch: 2/20, Batch: 1050/1586, Loss: 0.9384\n",
      "Epoch: 2/20, Batch: 1100/1586, Loss: 0.8870\n",
      "Epoch: 2/20, Batch: 1150/1586, Loss: 1.0076\n",
      "Epoch: 2/20, Batch: 1200/1586, Loss: 1.0135\n",
      "Epoch: 2/20, Batch: 1250/1586, Loss: 0.7278\n",
      "Epoch: 2/20, Batch: 1300/1586, Loss: 1.5267\n",
      "Epoch: 2/20, Batch: 1350/1586, Loss: 1.0467\n",
      "Epoch: 2/20, Batch: 1400/1586, Loss: 1.4010\n",
      "Epoch: 2/20, Batch: 1450/1586, Loss: 0.9724\n",
      "Epoch: 2/20, Batch: 1500/1586, Loss: 0.9071\n",
      "Epoch: 2/20, Batch: 1550/1586, Loss: 1.3543\n",
      "Epoch: 2, Train Loss: 0.9953\n",
      "Epoch: 3/20, Batch: 0/1586, Loss: 0.9986\n",
      "Epoch: 3/20, Batch: 50/1586, Loss: 0.7989\n",
      "Epoch: 3/20, Batch: 100/1586, Loss: 0.8462\n",
      "Epoch: 3/20, Batch: 150/1586, Loss: 0.7832\n",
      "Epoch: 3/20, Batch: 200/1586, Loss: 0.9480\n",
      "Epoch: 3/20, Batch: 250/1586, Loss: 0.8389\n",
      "Epoch: 3/20, Batch: 300/1586, Loss: 0.8242\n",
      "Epoch: 3/20, Batch: 350/1586, Loss: 1.0779\n",
      "Epoch: 3/20, Batch: 400/1586, Loss: 1.0873\n",
      "Epoch: 3/20, Batch: 450/1586, Loss: 1.0634\n",
      "Epoch: 3/20, Batch: 500/1586, Loss: 1.2097\n",
      "Epoch: 3/20, Batch: 550/1586, Loss: 0.7929\n",
      "Epoch: 3/20, Batch: 600/1586, Loss: 0.9348\n",
      "Epoch: 3/20, Batch: 650/1586, Loss: 0.9428\n",
      "Epoch: 3/20, Batch: 700/1586, Loss: 0.7846\n",
      "Epoch: 3/20, Batch: 750/1586, Loss: 1.3514\n",
      "Epoch: 3/20, Batch: 800/1586, Loss: 1.1500\n",
      "Epoch: 3/20, Batch: 850/1586, Loss: 1.2172\n",
      "Epoch: 3/20, Batch: 900/1586, Loss: 0.8731\n",
      "Epoch: 3/20, Batch: 950/1586, Loss: 0.7719\n",
      "Epoch: 3/20, Batch: 1000/1586, Loss: 1.4124\n",
      "Epoch: 3/20, Batch: 1050/1586, Loss: 0.7681\n",
      "Epoch: 3/20, Batch: 1100/1586, Loss: 0.8228\n",
      "Epoch: 3/20, Batch: 1150/1586, Loss: 1.0627\n",
      "Epoch: 3/20, Batch: 1200/1586, Loss: 1.0799\n",
      "Epoch: 3/20, Batch: 1250/1586, Loss: 1.2184\n",
      "Epoch: 3/20, Batch: 1300/1586, Loss: 1.1017\n",
      "Epoch: 3/20, Batch: 1350/1586, Loss: 0.8664\n",
      "Epoch: 3/20, Batch: 1400/1586, Loss: 0.6828\n",
      "Epoch: 3/20, Batch: 1450/1586, Loss: 0.9031\n",
      "Epoch: 3/20, Batch: 1500/1586, Loss: 1.0014\n",
      "Epoch: 3/20, Batch: 1550/1586, Loss: 1.2604\n",
      "Epoch: 3, Train Loss: 0.9940\n",
      "Epoch: 4/20, Batch: 0/1586, Loss: 1.0026\n",
      "Epoch: 4/20, Batch: 50/1586, Loss: 1.1596\n",
      "Epoch: 4/20, Batch: 100/1586, Loss: 1.1013\n",
      "Epoch: 4/20, Batch: 150/1586, Loss: 0.7879\n",
      "Epoch: 4/20, Batch: 200/1586, Loss: 0.8433\n",
      "Epoch: 4/20, Batch: 250/1586, Loss: 0.9944\n",
      "Epoch: 4/20, Batch: 300/1586, Loss: 1.0009\n",
      "Epoch: 4/20, Batch: 350/1586, Loss: 0.9926\n",
      "Epoch: 4/20, Batch: 400/1586, Loss: 1.0374\n",
      "Epoch: 4/20, Batch: 450/1586, Loss: 0.8783\n",
      "Epoch: 4/20, Batch: 500/1586, Loss: 1.2781\n",
      "Epoch: 4/20, Batch: 550/1586, Loss: 0.8894\n",
      "Epoch: 4/20, Batch: 600/1586, Loss: 0.8342\n",
      "Epoch: 4/20, Batch: 650/1586, Loss: 0.8808\n",
      "Epoch: 4/20, Batch: 700/1586, Loss: 1.0015\n",
      "Epoch: 4/20, Batch: 750/1586, Loss: 1.2237\n",
      "Epoch: 4/20, Batch: 800/1586, Loss: 0.7325\n",
      "Epoch: 4/20, Batch: 850/1586, Loss: 0.9287\n",
      "Epoch: 4/20, Batch: 900/1586, Loss: 0.8815\n",
      "Epoch: 4/20, Batch: 950/1586, Loss: 1.0369\n",
      "Epoch: 4/20, Batch: 1000/1586, Loss: 0.8304\n",
      "Epoch: 4/20, Batch: 1050/1586, Loss: 1.0680\n",
      "Epoch: 4/20, Batch: 1100/1586, Loss: 0.9206\n",
      "Epoch: 4/20, Batch: 1150/1586, Loss: 1.0158\n",
      "Epoch: 4/20, Batch: 1200/1586, Loss: 1.1641\n",
      "Epoch: 4/20, Batch: 1250/1586, Loss: 0.6928\n",
      "Epoch: 4/20, Batch: 1300/1586, Loss: 0.8748\n",
      "Epoch: 4/20, Batch: 1350/1586, Loss: 0.9885\n",
      "Epoch: 4/20, Batch: 1400/1586, Loss: 1.0368\n",
      "Epoch: 4/20, Batch: 1450/1586, Loss: 1.1873\n",
      "Epoch: 4/20, Batch: 1500/1586, Loss: 0.6286\n",
      "Epoch: 4/20, Batch: 1550/1586, Loss: 1.0264\n",
      "Epoch: 4, Train Loss: 0.9936\n",
      "Epoch: 5/20, Batch: 0/1586, Loss: 0.9682\n",
      "Epoch: 5/20, Batch: 50/1586, Loss: 1.2689\n",
      "Epoch: 5/20, Batch: 100/1586, Loss: 1.1576\n",
      "Epoch: 5/20, Batch: 150/1586, Loss: 0.8060\n",
      "Epoch: 5/20, Batch: 200/1586, Loss: 0.8573\n",
      "Epoch: 5/20, Batch: 250/1586, Loss: 1.2427\n",
      "Epoch: 5/20, Batch: 300/1586, Loss: 0.8972\n",
      "Epoch: 5/20, Batch: 350/1586, Loss: 1.2041\n",
      "Epoch: 5/20, Batch: 400/1586, Loss: 1.1477\n",
      "Epoch: 5/20, Batch: 450/1586, Loss: 1.0439\n",
      "Epoch: 5/20, Batch: 500/1586, Loss: 1.0807\n",
      "Epoch: 5/20, Batch: 550/1586, Loss: 0.9999\n",
      "Epoch: 5/20, Batch: 600/1586, Loss: 0.7998\n",
      "Epoch: 5/20, Batch: 650/1586, Loss: 1.1436\n",
      "Epoch: 5/20, Batch: 700/1586, Loss: 1.0746\n",
      "Epoch: 5/20, Batch: 750/1586, Loss: 0.8434\n",
      "Epoch: 5/20, Batch: 800/1586, Loss: 1.3165\n",
      "Epoch: 5/20, Batch: 850/1586, Loss: 1.0587\n",
      "Epoch: 5/20, Batch: 900/1586, Loss: 0.8470\n",
      "Epoch: 5/20, Batch: 950/1586, Loss: 0.8214\n",
      "Epoch: 5/20, Batch: 1000/1586, Loss: 1.3300\n",
      "Epoch: 5/20, Batch: 1050/1586, Loss: 1.4472\n",
      "Epoch: 5/20, Batch: 1100/1586, Loss: 1.3435\n",
      "Epoch: 5/20, Batch: 1150/1586, Loss: 1.1272\n",
      "Epoch: 5/20, Batch: 1200/1586, Loss: 0.9933\n",
      "Epoch: 5/20, Batch: 1250/1586, Loss: 1.1016\n",
      "Epoch: 5/20, Batch: 1300/1586, Loss: 1.0104\n",
      "Epoch: 5/20, Batch: 1350/1586, Loss: 0.8015\n",
      "Epoch: 5/20, Batch: 1400/1586, Loss: 0.8528\n",
      "Epoch: 5/20, Batch: 1450/1586, Loss: 1.0333\n",
      "Epoch: 5/20, Batch: 1500/1586, Loss: 0.8503\n",
      "Epoch: 5/20, Batch: 1550/1586, Loss: 0.7636\n",
      "Epoch: 5, Train Loss: 0.9940\n",
      "Epoch: 6/20, Batch: 0/1586, Loss: 0.9799\n",
      "Epoch: 6/20, Batch: 50/1586, Loss: 1.1564\n",
      "Epoch: 6/20, Batch: 100/1586, Loss: 0.8649\n",
      "Epoch: 6/20, Batch: 150/1586, Loss: 1.0176\n",
      "Epoch: 6/20, Batch: 200/1586, Loss: 1.3280\n",
      "Epoch: 6/20, Batch: 250/1586, Loss: 0.7913\n",
      "Epoch: 6/20, Batch: 300/1586, Loss: 0.6402\n",
      "Epoch: 6/20, Batch: 350/1586, Loss: 0.6001\n",
      "Epoch: 6/20, Batch: 400/1586, Loss: 0.8776\n",
      "Epoch: 6/20, Batch: 450/1586, Loss: 1.1323\n",
      "Epoch: 6/20, Batch: 500/1586, Loss: 0.9651\n",
      "Epoch: 6/20, Batch: 550/1586, Loss: 0.8888\n",
      "Epoch: 6/20, Batch: 600/1586, Loss: 1.0929\n",
      "Epoch: 6/20, Batch: 650/1586, Loss: 0.9543\n",
      "Epoch: 6/20, Batch: 700/1586, Loss: 0.8800\n",
      "Epoch: 6/20, Batch: 750/1586, Loss: 0.9480\n",
      "Epoch: 6/20, Batch: 800/1586, Loss: 0.9531\n",
      "Epoch: 6/20, Batch: 850/1586, Loss: 0.8951\n",
      "Epoch: 6/20, Batch: 900/1586, Loss: 1.0668\n",
      "Epoch: 6/20, Batch: 950/1586, Loss: 1.0709\n",
      "Epoch: 6/20, Batch: 1000/1586, Loss: 0.9151\n",
      "Epoch: 6/20, Batch: 1050/1586, Loss: 0.9682\n",
      "Epoch: 6/20, Batch: 1100/1586, Loss: 1.0262\n",
      "Epoch: 6/20, Batch: 1150/1586, Loss: 0.7792\n",
      "Epoch: 6/20, Batch: 1200/1586, Loss: 0.7377\n",
      "Epoch: 6/20, Batch: 1250/1586, Loss: 0.8304\n",
      "Epoch: 6/20, Batch: 1300/1586, Loss: 1.1381\n",
      "Epoch: 6/20, Batch: 1350/1586, Loss: 0.9652\n",
      "Epoch: 6/20, Batch: 1400/1586, Loss: 0.9937\n",
      "Epoch: 6/20, Batch: 1450/1586, Loss: 1.0244\n",
      "Epoch: 6/20, Batch: 1500/1586, Loss: 1.2998\n",
      "Epoch: 6/20, Batch: 1550/1586, Loss: 0.7568\n",
      "Epoch: 6, Train Loss: 0.9910\n",
      "Epoch: 7/20, Batch: 0/1586, Loss: 1.0075\n",
      "Epoch: 7/20, Batch: 50/1586, Loss: 0.8180\n",
      "Epoch: 7/20, Batch: 100/1586, Loss: 1.2600\n",
      "Epoch: 7/20, Batch: 150/1586, Loss: 1.0451\n",
      "Epoch: 7/20, Batch: 200/1586, Loss: 0.7844\n",
      "Epoch: 7/20, Batch: 250/1586, Loss: 0.8878\n",
      "Epoch: 7/20, Batch: 300/1586, Loss: 0.7619\n",
      "Epoch: 7/20, Batch: 350/1586, Loss: 1.0400\n",
      "Epoch: 7/20, Batch: 400/1586, Loss: 1.2842\n",
      "Epoch: 7/20, Batch: 450/1586, Loss: 1.2354\n",
      "Epoch: 7/20, Batch: 500/1586, Loss: 1.0146\n",
      "Epoch: 7/20, Batch: 550/1586, Loss: 0.8893\n",
      "Epoch: 7/20, Batch: 600/1586, Loss: 1.0942\n",
      "Epoch: 7/20, Batch: 650/1586, Loss: 1.0500\n",
      "Epoch: 7/20, Batch: 700/1586, Loss: 0.9798\n",
      "Epoch: 7/20, Batch: 750/1586, Loss: 0.8612\n",
      "Epoch: 7/20, Batch: 800/1586, Loss: 1.1495\n",
      "Epoch: 7/20, Batch: 850/1586, Loss: 1.0507\n",
      "Epoch: 7/20, Batch: 900/1586, Loss: 1.1097\n",
      "Epoch: 7/20, Batch: 950/1586, Loss: 0.8429\n",
      "Epoch: 7/20, Batch: 1000/1586, Loss: 1.1060\n",
      "Epoch: 7/20, Batch: 1050/1586, Loss: 0.8692\n",
      "Epoch: 7/20, Batch: 1100/1586, Loss: 0.8128\n",
      "Epoch: 7/20, Batch: 1150/1586, Loss: 0.8184\n",
      "Epoch: 7/20, Batch: 1200/1586, Loss: 1.0630\n",
      "Epoch: 7/20, Batch: 1250/1586, Loss: 1.0681\n",
      "Epoch: 7/20, Batch: 1300/1586, Loss: 0.8748\n",
      "Epoch: 7/20, Batch: 1350/1586, Loss: 1.1835\n",
      "Epoch: 7/20, Batch: 1400/1586, Loss: 1.3794\n",
      "Epoch: 7/20, Batch: 1450/1586, Loss: 1.2903\n",
      "Epoch: 7/20, Batch: 1500/1586, Loss: 0.9471\n",
      "Epoch: 7/20, Batch: 1550/1586, Loss: 1.0348\n",
      "Epoch: 7, Train Loss: 0.9924\n",
      "Epoch: 8/20, Batch: 0/1586, Loss: 0.7991\n",
      "Epoch: 8/20, Batch: 50/1586, Loss: 1.0341\n",
      "Epoch: 8/20, Batch: 100/1586, Loss: 1.0323\n",
      "Epoch: 8/20, Batch: 150/1586, Loss: 0.7812\n",
      "Epoch: 8/20, Batch: 200/1586, Loss: 1.0465\n",
      "Epoch: 8/20, Batch: 250/1586, Loss: 0.7566\n",
      "Epoch: 8/20, Batch: 300/1586, Loss: 1.0057\n",
      "Epoch: 8/20, Batch: 350/1586, Loss: 0.9170\n",
      "Epoch: 8/20, Batch: 400/1586, Loss: 1.0947\n",
      "Epoch: 8/20, Batch: 450/1586, Loss: 1.1021\n",
      "Epoch: 8/20, Batch: 500/1586, Loss: 1.1556\n",
      "Epoch: 8/20, Batch: 550/1586, Loss: 0.7486\n",
      "Epoch: 8/20, Batch: 600/1586, Loss: 1.4530\n",
      "Epoch: 8/20, Batch: 650/1586, Loss: 1.0035\n",
      "Epoch: 8/20, Batch: 700/1586, Loss: 1.0593\n",
      "Epoch: 8/20, Batch: 750/1586, Loss: 1.0693\n",
      "Epoch: 8/20, Batch: 800/1586, Loss: 0.9966\n",
      "Epoch: 8/20, Batch: 850/1586, Loss: 1.0483\n",
      "Epoch: 8/20, Batch: 900/1586, Loss: 1.0869\n",
      "Epoch: 8/20, Batch: 950/1586, Loss: 1.3170\n",
      "Epoch: 8/20, Batch: 1000/1586, Loss: 0.9728\n",
      "Epoch: 8/20, Batch: 1050/1586, Loss: 1.2598\n",
      "Epoch: 8/20, Batch: 1100/1586, Loss: 1.0978\n",
      "Epoch: 8/20, Batch: 1150/1586, Loss: 1.0080\n",
      "Epoch: 8/20, Batch: 1200/1586, Loss: 0.7994\n",
      "Epoch: 8/20, Batch: 1250/1586, Loss: 0.7705\n",
      "Epoch: 8/20, Batch: 1300/1586, Loss: 1.1456\n",
      "Epoch: 8/20, Batch: 1350/1586, Loss: 0.7993\n",
      "Epoch: 8/20, Batch: 1400/1586, Loss: 0.7991\n",
      "Epoch: 8/20, Batch: 1450/1586, Loss: 1.2550\n",
      "Epoch: 8/20, Batch: 1500/1586, Loss: 1.1293\n",
      "Epoch: 8/20, Batch: 1550/1586, Loss: 0.9853\n",
      "Epoch: 8, Train Loss: 0.9926\n",
      "Epoch: 9/20, Batch: 0/1586, Loss: 1.0772\n",
      "Epoch: 9/20, Batch: 50/1586, Loss: 0.8546\n",
      "Epoch: 9/20, Batch: 100/1586, Loss: 0.9678\n",
      "Epoch: 9/20, Batch: 150/1586, Loss: 1.4258\n",
      "Epoch: 9/20, Batch: 200/1586, Loss: 0.7389\n",
      "Epoch: 9/20, Batch: 250/1586, Loss: 0.8786\n",
      "Epoch: 9/20, Batch: 300/1586, Loss: 0.8667\n",
      "Epoch: 9/20, Batch: 350/1586, Loss: 0.8245\n",
      "Epoch: 9/20, Batch: 400/1586, Loss: 0.8348\n",
      "Epoch: 9/20, Batch: 450/1586, Loss: 0.9462\n",
      "Epoch: 9/20, Batch: 500/1586, Loss: 1.1440\n",
      "Epoch: 9/20, Batch: 550/1586, Loss: 1.0628\n",
      "Epoch: 9/20, Batch: 600/1586, Loss: 0.9895\n",
      "Epoch: 9/20, Batch: 650/1586, Loss: 1.2248\n",
      "Epoch: 9/20, Batch: 700/1586, Loss: 0.8754\n",
      "Epoch: 9/20, Batch: 750/1586, Loss: 1.0902\n",
      "Epoch: 9/20, Batch: 800/1586, Loss: 0.9160\n",
      "Epoch: 9/20, Batch: 850/1586, Loss: 0.9443\n",
      "Epoch: 9/20, Batch: 900/1586, Loss: 0.9197\n",
      "Epoch: 9/20, Batch: 950/1586, Loss: 1.2141\n",
      "Epoch: 9/20, Batch: 1000/1586, Loss: 0.9603\n",
      "Epoch: 9/20, Batch: 1050/1586, Loss: 0.9462\n",
      "Epoch: 9/20, Batch: 1100/1586, Loss: 1.0374\n",
      "Epoch: 9/20, Batch: 1150/1586, Loss: 1.2004\n",
      "Epoch: 9/20, Batch: 1200/1586, Loss: 1.0636\n",
      "Epoch: 9/20, Batch: 1250/1586, Loss: 1.2692\n",
      "Epoch: 9/20, Batch: 1300/1586, Loss: 1.0011\n",
      "Epoch: 9/20, Batch: 1350/1586, Loss: 0.9671\n",
      "Epoch: 9/20, Batch: 1400/1586, Loss: 0.8875\n",
      "Epoch: 9/20, Batch: 1450/1586, Loss: 0.8625\n",
      "Epoch: 9/20, Batch: 1500/1586, Loss: 1.2709\n",
      "Epoch: 9/20, Batch: 1550/1586, Loss: 1.1968\n",
      "Epoch: 9, Train Loss: 0.9912\n",
      "Epoch: 10/20, Batch: 0/1586, Loss: 0.9122\n",
      "Epoch: 10/20, Batch: 50/1586, Loss: 1.2575\n",
      "Epoch: 10/20, Batch: 100/1586, Loss: 0.9672\n",
      "Epoch: 10/20, Batch: 150/1586, Loss: 1.3325\n",
      "Epoch: 10/20, Batch: 200/1586, Loss: 1.0677\n",
      "Epoch: 10/20, Batch: 250/1586, Loss: 0.8218\n",
      "Epoch: 10/20, Batch: 300/1586, Loss: 0.7905\n",
      "Epoch: 10/20, Batch: 350/1586, Loss: 1.1710\n",
      "Epoch: 10/20, Batch: 400/1586, Loss: 1.1181\n",
      "Epoch: 10/20, Batch: 450/1586, Loss: 1.3987\n",
      "Epoch: 10/20, Batch: 500/1586, Loss: 1.0426\n",
      "Epoch: 10/20, Batch: 550/1586, Loss: 1.1515\n",
      "Epoch: 10/20, Batch: 600/1586, Loss: 0.9030\n",
      "Epoch: 10/20, Batch: 650/1586, Loss: 1.1920\n",
      "Epoch: 10/20, Batch: 700/1586, Loss: 0.8235\n",
      "Epoch: 10/20, Batch: 750/1586, Loss: 0.9629\n",
      "Epoch: 10/20, Batch: 800/1586, Loss: 0.7496\n",
      "Epoch: 10/20, Batch: 850/1586, Loss: 0.8131\n",
      "Epoch: 10/20, Batch: 900/1586, Loss: 0.9216\n",
      "Epoch: 10/20, Batch: 950/1586, Loss: 0.9766\n",
      "Epoch: 10/20, Batch: 1000/1586, Loss: 1.1089\n",
      "Epoch: 10/20, Batch: 1050/1586, Loss: 1.2637\n",
      "Epoch: 10/20, Batch: 1100/1586, Loss: 0.9865\n",
      "Epoch: 10/20, Batch: 1150/1586, Loss: 0.8232\n",
      "Epoch: 10/20, Batch: 1200/1586, Loss: 0.6692\n",
      "Epoch: 10/20, Batch: 1250/1586, Loss: 0.8301\n",
      "Epoch: 10/20, Batch: 1300/1586, Loss: 1.1762\n",
      "Epoch: 10/20, Batch: 1350/1586, Loss: 1.2129\n",
      "Epoch: 10/20, Batch: 1400/1586, Loss: 1.0418\n",
      "Epoch: 10/20, Batch: 1450/1586, Loss: 0.7827\n",
      "Epoch: 10/20, Batch: 1500/1586, Loss: 1.0316\n",
      "Epoch: 10/20, Batch: 1550/1586, Loss: 1.1304\n",
      "Epoch: 10, Train Loss: 0.9929\n",
      "Epoch: 11/20, Batch: 0/1586, Loss: 0.9557\n",
      "Epoch: 11/20, Batch: 50/1586, Loss: 0.9134\n",
      "Epoch: 11/20, Batch: 100/1586, Loss: 1.1170\n",
      "Epoch: 11/20, Batch: 150/1586, Loss: 0.7664\n",
      "Epoch: 11/20, Batch: 200/1586, Loss: 0.8747\n",
      "Epoch: 11/20, Batch: 250/1586, Loss: 0.7604\n",
      "Epoch: 11/20, Batch: 300/1586, Loss: 0.9249\n",
      "Epoch: 11/20, Batch: 350/1586, Loss: 0.8275\n",
      "Epoch: 11/20, Batch: 400/1586, Loss: 0.9971\n",
      "Epoch: 11/20, Batch: 450/1586, Loss: 0.9005\n",
      "Epoch: 11/20, Batch: 500/1586, Loss: 1.2927\n",
      "Epoch: 11/20, Batch: 550/1586, Loss: 0.8943\n",
      "Epoch: 11/20, Batch: 600/1586, Loss: 1.1207\n",
      "Epoch: 11/20, Batch: 650/1586, Loss: 1.0294\n",
      "Epoch: 11/20, Batch: 700/1586, Loss: 1.0330\n",
      "Epoch: 11/20, Batch: 750/1586, Loss: 0.8863\n",
      "Epoch: 11/20, Batch: 800/1586, Loss: 0.8776\n",
      "Epoch: 11/20, Batch: 850/1586, Loss: 0.7405\n",
      "Epoch: 11/20, Batch: 900/1586, Loss: 1.2100\n",
      "Epoch: 11/20, Batch: 950/1586, Loss: 1.3349\n",
      "Epoch: 11/20, Batch: 1000/1586, Loss: 0.9790\n",
      "Epoch: 11/20, Batch: 1050/1586, Loss: 0.7933\n",
      "Epoch: 11/20, Batch: 1100/1586, Loss: 0.7808\n",
      "Epoch: 11/20, Batch: 1150/1586, Loss: 1.1386\n",
      "Epoch: 11/20, Batch: 1200/1586, Loss: 0.8085\n",
      "Epoch: 11/20, Batch: 1250/1586, Loss: 1.2130\n",
      "Epoch: 11/20, Batch: 1300/1586, Loss: 1.0217\n",
      "Epoch: 11/20, Batch: 1350/1586, Loss: 0.8320\n",
      "Epoch: 11/20, Batch: 1400/1586, Loss: 0.9578\n",
      "Epoch: 11/20, Batch: 1450/1586, Loss: 0.7503\n",
      "Epoch: 11/20, Batch: 1500/1586, Loss: 0.9154\n",
      "Epoch: 11/20, Batch: 1550/1586, Loss: 1.3786\n",
      "Epoch: 11, Train Loss: 0.9925\n",
      "Epoch: 12/20, Batch: 0/1586, Loss: 1.0386\n",
      "Epoch: 12/20, Batch: 50/1586, Loss: 0.8987\n",
      "Epoch: 12/20, Batch: 100/1586, Loss: 0.8736\n",
      "Epoch: 12/20, Batch: 150/1586, Loss: 1.1130\n",
      "Epoch: 12/20, Batch: 200/1586, Loss: 0.8501\n",
      "Epoch: 12/20, Batch: 250/1586, Loss: 1.1983\n",
      "Epoch: 12/20, Batch: 300/1586, Loss: 0.8639\n",
      "Epoch: 12/20, Batch: 350/1586, Loss: 0.9556\n",
      "Epoch: 12/20, Batch: 400/1586, Loss: 1.1245\n",
      "Epoch: 12/20, Batch: 450/1586, Loss: 1.3854\n",
      "Epoch: 12/20, Batch: 500/1586, Loss: 0.8729\n",
      "Epoch: 12/20, Batch: 550/1586, Loss: 1.0296\n",
      "Epoch: 12/20, Batch: 600/1586, Loss: 1.0644\n",
      "Epoch: 12/20, Batch: 650/1586, Loss: 0.6802\n",
      "Epoch: 12/20, Batch: 700/1586, Loss: 0.8782\n",
      "Epoch: 12/20, Batch: 750/1586, Loss: 0.8975\n",
      "Epoch: 12/20, Batch: 800/1586, Loss: 0.8869\n",
      "Epoch: 12/20, Batch: 850/1586, Loss: 1.5031\n",
      "Epoch: 12/20, Batch: 900/1586, Loss: 0.8780\n",
      "Epoch: 12/20, Batch: 950/1586, Loss: 1.2318\n",
      "Epoch: 12/20, Batch: 1000/1586, Loss: 0.9666\n",
      "Epoch: 12/20, Batch: 1050/1586, Loss: 0.8402\n",
      "Epoch: 12/20, Batch: 1100/1586, Loss: 0.7870\n",
      "Epoch: 12/20, Batch: 1150/1586, Loss: 0.8375\n",
      "Epoch: 12/20, Batch: 1200/1586, Loss: 0.7271\n",
      "Epoch: 12/20, Batch: 1250/1586, Loss: 0.9431\n",
      "Epoch: 12/20, Batch: 1300/1586, Loss: 1.1370\n",
      "Epoch: 12/20, Batch: 1350/1586, Loss: 0.8954\n",
      "Epoch: 12/20, Batch: 1400/1586, Loss: 1.0998\n",
      "Epoch: 12/20, Batch: 1450/1586, Loss: 0.8671\n",
      "Epoch: 12/20, Batch: 1500/1586, Loss: 0.9031\n",
      "Epoch: 12/20, Batch: 1550/1586, Loss: 1.1256\n",
      "Epoch: 12, Train Loss: 0.9922\n",
      "Epoch: 13/20, Batch: 0/1586, Loss: 0.8781\n",
      "Epoch: 13/20, Batch: 50/1586, Loss: 1.0481\n",
      "Epoch: 13/20, Batch: 100/1586, Loss: 1.1071\n",
      "Epoch: 13/20, Batch: 150/1586, Loss: 0.8651\n",
      "Epoch: 13/20, Batch: 200/1586, Loss: 0.8186\n",
      "Epoch: 13/20, Batch: 250/1586, Loss: 1.0320\n",
      "Epoch: 13/20, Batch: 300/1586, Loss: 1.1663\n",
      "Epoch: 13/20, Batch: 350/1586, Loss: 1.2278\n",
      "Epoch: 13/20, Batch: 400/1586, Loss: 1.0847\n",
      "Epoch: 13/20, Batch: 450/1586, Loss: 1.0547\n",
      "Epoch: 13/20, Batch: 500/1586, Loss: 1.2602\n",
      "Epoch: 13/20, Batch: 550/1586, Loss: 1.0669\n",
      "Epoch: 13/20, Batch: 600/1586, Loss: 0.8018\n",
      "Epoch: 13/20, Batch: 650/1586, Loss: 1.1915\n",
      "Epoch: 13/20, Batch: 700/1586, Loss: 1.0753\n",
      "Epoch: 13/20, Batch: 750/1586, Loss: 0.9054\n",
      "Epoch: 13/20, Batch: 800/1586, Loss: 1.3583\n",
      "Epoch: 13/20, Batch: 850/1586, Loss: 1.0800\n",
      "Epoch: 13/20, Batch: 900/1586, Loss: 0.8511\n",
      "Epoch: 13/20, Batch: 950/1586, Loss: 0.8767\n",
      "Epoch: 13/20, Batch: 1000/1586, Loss: 1.3399\n",
      "Epoch: 13/20, Batch: 1050/1586, Loss: 1.2392\n",
      "Epoch: 13/20, Batch: 1100/1586, Loss: 1.2833\n",
      "Epoch: 13/20, Batch: 1150/1586, Loss: 0.9397\n",
      "Epoch: 13/20, Batch: 1200/1586, Loss: 0.7913\n",
      "Epoch: 13/20, Batch: 1250/1586, Loss: 1.2168\n",
      "Epoch: 13/20, Batch: 1300/1586, Loss: 1.4594\n",
      "Epoch: 13/20, Batch: 1350/1586, Loss: 0.7630\n",
      "Epoch: 13/20, Batch: 1400/1586, Loss: 0.7985\n",
      "Epoch: 13/20, Batch: 1450/1586, Loss: 0.8953\n",
      "Epoch: 13/20, Batch: 1500/1586, Loss: 1.0043\n",
      "Epoch: 13/20, Batch: 1550/1586, Loss: 1.1649\n",
      "Epoch: 13, Train Loss: 0.9912\n",
      "Epoch: 14/20, Batch: 0/1586, Loss: 0.9894\n",
      "Epoch: 14/20, Batch: 50/1586, Loss: 0.7779\n",
      "Epoch: 14/20, Batch: 100/1586, Loss: 0.9994\n",
      "Epoch: 14/20, Batch: 150/1586, Loss: 0.7251\n",
      "Epoch: 14/20, Batch: 200/1586, Loss: 0.6966\n",
      "Epoch: 14/20, Batch: 250/1586, Loss: 1.0656\n",
      "Epoch: 14/20, Batch: 300/1586, Loss: 0.7990\n",
      "Epoch: 14/20, Batch: 350/1586, Loss: 0.9527\n",
      "Epoch: 14/20, Batch: 400/1586, Loss: 0.8331\n",
      "Epoch: 14/20, Batch: 450/1586, Loss: 1.0548\n",
      "Epoch: 14/20, Batch: 500/1586, Loss: 0.7328\n",
      "Epoch: 14/20, Batch: 550/1586, Loss: 1.2878\n",
      "Epoch: 14/20, Batch: 600/1586, Loss: 0.9367\n",
      "Epoch: 14/20, Batch: 650/1586, Loss: 1.0489\n",
      "Epoch: 14/20, Batch: 700/1586, Loss: 0.9576\n",
      "Epoch: 14/20, Batch: 750/1586, Loss: 0.9724\n",
      "Epoch: 14/20, Batch: 800/1586, Loss: 0.8770\n",
      "Epoch: 14/20, Batch: 850/1586, Loss: 0.9359\n",
      "Epoch: 14/20, Batch: 900/1586, Loss: 1.3415\n",
      "Epoch: 14/20, Batch: 950/1586, Loss: 1.0537\n",
      "Epoch: 14/20, Batch: 1000/1586, Loss: 1.0116\n",
      "Epoch: 14/20, Batch: 1050/1586, Loss: 0.8616\n",
      "Epoch: 14/20, Batch: 1100/1586, Loss: 0.7345\n",
      "Epoch: 14/20, Batch: 1150/1586, Loss: 1.3808\n",
      "Epoch: 14/20, Batch: 1200/1586, Loss: 1.0211\n",
      "Epoch: 14/20, Batch: 1250/1586, Loss: 0.9635\n",
      "Epoch: 14/20, Batch: 1300/1586, Loss: 0.9862\n",
      "Epoch: 14/20, Batch: 1350/1586, Loss: 0.8215\n",
      "Epoch: 14/20, Batch: 1400/1586, Loss: 1.1167\n",
      "Epoch: 14/20, Batch: 1450/1586, Loss: 0.9112\n",
      "Epoch: 14/20, Batch: 1500/1586, Loss: 0.9145\n",
      "Epoch: 14/20, Batch: 1550/1586, Loss: 0.7354\n",
      "Epoch: 14, Train Loss: 0.9916\n",
      "Epoch: 15/20, Batch: 0/1586, Loss: 0.7593\n",
      "Epoch: 15/20, Batch: 50/1586, Loss: 0.7914\n",
      "Epoch: 15/20, Batch: 100/1586, Loss: 0.8581\n",
      "Epoch: 15/20, Batch: 150/1586, Loss: 1.0018\n",
      "Epoch: 15/20, Batch: 200/1586, Loss: 1.1913\n",
      "Epoch: 15/20, Batch: 250/1586, Loss: 0.8862\n",
      "Epoch: 15/20, Batch: 300/1586, Loss: 1.1696\n",
      "Epoch: 15/20, Batch: 350/1586, Loss: 0.9362\n",
      "Epoch: 15/20, Batch: 400/1586, Loss: 1.5787\n",
      "Epoch: 15/20, Batch: 450/1586, Loss: 1.1415\n",
      "Epoch: 15/20, Batch: 500/1586, Loss: 0.7688\n",
      "Epoch: 15/20, Batch: 550/1586, Loss: 1.0726\n",
      "Epoch: 15/20, Batch: 600/1586, Loss: 0.8178\n",
      "Epoch: 15/20, Batch: 650/1586, Loss: 0.9407\n",
      "Epoch: 15/20, Batch: 700/1586, Loss: 0.9845\n",
      "Epoch: 15/20, Batch: 750/1586, Loss: 0.8343\n",
      "Epoch: 15/20, Batch: 800/1586, Loss: 0.9452\n",
      "Epoch: 15/20, Batch: 850/1586, Loss: 0.9575\n",
      "Epoch: 15/20, Batch: 900/1586, Loss: 0.8104\n",
      "Epoch: 15/20, Batch: 950/1586, Loss: 1.0836\n",
      "Epoch: 15/20, Batch: 1000/1586, Loss: 0.9934\n",
      "Epoch: 15/20, Batch: 1050/1586, Loss: 0.7376\n",
      "Epoch: 15/20, Batch: 1100/1586, Loss: 1.3717\n",
      "Epoch: 15/20, Batch: 1150/1586, Loss: 0.8221\n",
      "Epoch: 15/20, Batch: 1200/1586, Loss: 0.8049\n",
      "Epoch: 15/20, Batch: 1250/1586, Loss: 0.8354\n",
      "Epoch: 15/20, Batch: 1300/1586, Loss: 0.9977\n",
      "Epoch: 15/20, Batch: 1350/1586, Loss: 1.1096\n",
      "Epoch: 15/20, Batch: 1400/1586, Loss: 1.2412\n",
      "Epoch: 15/20, Batch: 1450/1586, Loss: 0.9226\n",
      "Epoch: 15/20, Batch: 1500/1586, Loss: 1.2257\n",
      "Epoch: 15/20, Batch: 1550/1586, Loss: 0.9442\n",
      "Epoch: 15, Train Loss: 0.9936\n",
      "Epoch: 16/20, Batch: 0/1586, Loss: 1.0275\n",
      "Epoch: 16/20, Batch: 50/1586, Loss: 0.9261\n",
      "Epoch: 16/20, Batch: 100/1586, Loss: 0.9935\n",
      "Epoch: 16/20, Batch: 150/1586, Loss: 0.8786\n",
      "Epoch: 16/20, Batch: 200/1586, Loss: 1.0807\n",
      "Epoch: 16/20, Batch: 250/1586, Loss: 0.9059\n",
      "Epoch: 16/20, Batch: 300/1586, Loss: 1.2005\n",
      "Epoch: 16/20, Batch: 350/1586, Loss: 1.0314\n",
      "Epoch: 16/20, Batch: 400/1586, Loss: 0.8676\n",
      "Epoch: 16/20, Batch: 450/1586, Loss: 1.0769\n",
      "Epoch: 16/20, Batch: 500/1586, Loss: 1.3096\n",
      "Epoch: 16/20, Batch: 550/1586, Loss: 1.1451\n",
      "Epoch: 16/20, Batch: 600/1586, Loss: 1.2550\n",
      "Epoch: 16/20, Batch: 650/1586, Loss: 1.3029\n",
      "Epoch: 16/20, Batch: 700/1586, Loss: 0.9576\n",
      "Epoch: 16/20, Batch: 750/1586, Loss: 0.9233\n",
      "Epoch: 16/20, Batch: 800/1586, Loss: 0.9373\n",
      "Epoch: 16/20, Batch: 850/1586, Loss: 1.1607\n",
      "Epoch: 16/20, Batch: 900/1586, Loss: 1.0390\n",
      "Epoch: 16/20, Batch: 950/1586, Loss: 0.9568\n",
      "Epoch: 16/20, Batch: 1000/1586, Loss: 0.8222\n",
      "Epoch: 16/20, Batch: 1050/1586, Loss: 0.7732\n",
      "Epoch: 16/20, Batch: 1100/1586, Loss: 0.8971\n",
      "Epoch: 16/20, Batch: 1150/1586, Loss: 1.1343\n",
      "Epoch: 16/20, Batch: 1200/1586, Loss: 0.8174\n",
      "Epoch: 16/20, Batch: 1250/1586, Loss: 0.9159\n",
      "Epoch: 16/20, Batch: 1300/1586, Loss: 0.8200\n",
      "Epoch: 16/20, Batch: 1350/1586, Loss: 1.0555\n",
      "Epoch: 16/20, Batch: 1400/1586, Loss: 1.0858\n",
      "Epoch: 16/20, Batch: 1450/1586, Loss: 1.4044\n",
      "Epoch: 16/20, Batch: 1500/1586, Loss: 1.5851\n",
      "Epoch: 16/20, Batch: 1550/1586, Loss: 0.7607\n",
      "Epoch: 16, Train Loss: 0.9927\n",
      "Epoch: 17/20, Batch: 0/1586, Loss: 1.0158\n",
      "Epoch: 17/20, Batch: 50/1586, Loss: 1.8887\n",
      "Epoch: 17/20, Batch: 100/1586, Loss: 1.3747\n",
      "Epoch: 17/20, Batch: 150/1586, Loss: 0.8782\n",
      "Epoch: 17/20, Batch: 200/1586, Loss: 0.8952\n",
      "Epoch: 17/20, Batch: 250/1586, Loss: 0.9762\n",
      "Epoch: 17/20, Batch: 300/1586, Loss: 1.3025\n",
      "Epoch: 17/20, Batch: 350/1586, Loss: 1.2193\n",
      "Epoch: 17/20, Batch: 400/1586, Loss: 0.8377\n",
      "Epoch: 17/20, Batch: 450/1586, Loss: 0.7548\n",
      "Epoch: 17/20, Batch: 500/1586, Loss: 0.9834\n",
      "Epoch: 17/20, Batch: 550/1586, Loss: 0.9679\n",
      "Epoch: 17/20, Batch: 600/1586, Loss: 0.9693\n",
      "Epoch: 17/20, Batch: 650/1586, Loss: 1.0875\n",
      "Epoch: 17/20, Batch: 700/1586, Loss: 0.8718\n",
      "Epoch: 17/20, Batch: 750/1586, Loss: 0.9827\n",
      "Epoch: 17/20, Batch: 800/1586, Loss: 0.7364\n",
      "Epoch: 17/20, Batch: 850/1586, Loss: 1.0275\n",
      "Epoch: 17/20, Batch: 900/1586, Loss: 1.2376\n",
      "Epoch: 17/20, Batch: 950/1586, Loss: 0.8360\n",
      "Epoch: 17/20, Batch: 1000/1586, Loss: 1.0899\n",
      "Epoch: 17/20, Batch: 1050/1586, Loss: 0.8820\n",
      "Epoch: 17/20, Batch: 1100/1586, Loss: 0.9500\n",
      "Epoch: 17/20, Batch: 1150/1586, Loss: 1.6336\n",
      "Epoch: 17/20, Batch: 1200/1586, Loss: 0.9387\n",
      "Epoch: 17/20, Batch: 1250/1586, Loss: 1.0260\n",
      "Epoch: 17/20, Batch: 1300/1586, Loss: 0.7656\n",
      "Epoch: 17/20, Batch: 1350/1586, Loss: 1.0340\n",
      "Epoch: 17/20, Batch: 1400/1586, Loss: 0.9056\n",
      "Epoch: 17/20, Batch: 1450/1586, Loss: 0.7695\n",
      "Epoch: 17/20, Batch: 1500/1586, Loss: 0.9437\n",
      "Epoch: 17/20, Batch: 1550/1586, Loss: 0.9624\n",
      "Epoch: 17, Train Loss: 0.9915\n",
      "Epoch: 18/20, Batch: 0/1586, Loss: 0.9603\n",
      "Epoch: 18/20, Batch: 50/1586, Loss: 1.2340\n",
      "Epoch: 18/20, Batch: 100/1586, Loss: 0.7670\n",
      "Epoch: 18/20, Batch: 150/1586, Loss: 1.2625\n",
      "Epoch: 18/20, Batch: 200/1586, Loss: 0.9551\n",
      "Epoch: 18/20, Batch: 250/1586, Loss: 0.9980\n",
      "Epoch: 18/20, Batch: 300/1586, Loss: 0.9718\n",
      "Epoch: 18/20, Batch: 350/1586, Loss: 1.1592\n",
      "Epoch: 18/20, Batch: 400/1586, Loss: 1.0074\n",
      "Epoch: 18/20, Batch: 450/1586, Loss: 0.7151\n",
      "Epoch: 18/20, Batch: 500/1586, Loss: 1.0666\n",
      "Epoch: 18/20, Batch: 550/1586, Loss: 0.8815\n",
      "Epoch: 18/20, Batch: 600/1586, Loss: 1.3433\n",
      "Epoch: 18/20, Batch: 650/1586, Loss: 1.1326\n",
      "Epoch: 18/20, Batch: 700/1586, Loss: 0.8533\n",
      "Epoch: 18/20, Batch: 750/1586, Loss: 1.0431\n",
      "Epoch: 18/20, Batch: 800/1586, Loss: 0.8879\n",
      "Epoch: 18/20, Batch: 850/1586, Loss: 0.8438\n",
      "Epoch: 18/20, Batch: 900/1586, Loss: 0.6965\n",
      "Epoch: 18/20, Batch: 950/1586, Loss: 0.9998\n",
      "Epoch: 18/20, Batch: 1000/1586, Loss: 0.8405\n",
      "Epoch: 18/20, Batch: 1050/1586, Loss: 0.9631\n",
      "Epoch: 18/20, Batch: 1100/1586, Loss: 0.7740\n",
      "Epoch: 18/20, Batch: 1150/1586, Loss: 0.7674\n",
      "Epoch: 18/20, Batch: 1200/1586, Loss: 1.1943\n",
      "Epoch: 18/20, Batch: 1250/1586, Loss: 0.9706\n",
      "Epoch: 18/20, Batch: 1300/1586, Loss: 0.9784\n",
      "Epoch: 18/20, Batch: 1350/1586, Loss: 0.8802\n",
      "Epoch: 18/20, Batch: 1400/1586, Loss: 0.9670\n",
      "Epoch: 18/20, Batch: 1450/1586, Loss: 1.0579\n",
      "Epoch: 18/20, Batch: 1500/1586, Loss: 0.8258\n",
      "Epoch: 18/20, Batch: 1550/1586, Loss: 1.0823\n",
      "Epoch: 18, Train Loss: 0.9929\n",
      "Epoch: 19/20, Batch: 0/1586, Loss: 0.8397\n",
      "Epoch: 19/20, Batch: 50/1586, Loss: 0.8640\n",
      "Epoch: 19/20, Batch: 100/1586, Loss: 0.9062\n",
      "Epoch: 19/20, Batch: 150/1586, Loss: 0.9921\n",
      "Epoch: 19/20, Batch: 200/1586, Loss: 1.2239\n",
      "Epoch: 19/20, Batch: 250/1586, Loss: 1.0498\n",
      "Epoch: 19/20, Batch: 300/1586, Loss: 0.7489\n",
      "Epoch: 19/20, Batch: 350/1586, Loss: 0.9064\n",
      "Epoch: 19/20, Batch: 400/1586, Loss: 0.7335\n",
      "Epoch: 19/20, Batch: 450/1586, Loss: 0.8725\n",
      "Epoch: 19/20, Batch: 500/1586, Loss: 0.9118\n",
      "Epoch: 19/20, Batch: 550/1586, Loss: 1.2265\n",
      "Epoch: 19/20, Batch: 600/1586, Loss: 1.1197\n",
      "Epoch: 19/20, Batch: 650/1586, Loss: 0.7836\n",
      "Epoch: 19/20, Batch: 700/1586, Loss: 0.8834\n",
      "Epoch: 19/20, Batch: 750/1586, Loss: 1.1000\n",
      "Epoch: 19/20, Batch: 800/1586, Loss: 1.0771\n",
      "Epoch: 19/20, Batch: 850/1586, Loss: 0.9616\n",
      "Epoch: 19/20, Batch: 900/1586, Loss: 1.2310\n",
      "Epoch: 19/20, Batch: 950/1586, Loss: 0.8422\n",
      "Epoch: 19/20, Batch: 1000/1586, Loss: 0.8627\n",
      "Epoch: 19/20, Batch: 1050/1586, Loss: 1.0210\n",
      "Epoch: 19/20, Batch: 1100/1586, Loss: 1.1095\n",
      "Epoch: 19/20, Batch: 1150/1586, Loss: 0.8266\n",
      "Epoch: 19/20, Batch: 1200/1586, Loss: 1.2320\n",
      "Epoch: 19/20, Batch: 1250/1586, Loss: 0.8670\n",
      "Epoch: 19/20, Batch: 1300/1586, Loss: 0.8676\n",
      "Epoch: 19/20, Batch: 1350/1586, Loss: 1.0434\n",
      "Epoch: 19/20, Batch: 1400/1586, Loss: 1.0195\n",
      "Epoch: 19/20, Batch: 1450/1586, Loss: 0.8039\n",
      "Epoch: 19/20, Batch: 1500/1586, Loss: 1.1941\n",
      "Epoch: 19/20, Batch: 1550/1586, Loss: 0.9783\n",
      "Epoch: 19, Train Loss: 0.9919\n",
      "Epoch: 20/20, Batch: 0/1586, Loss: 1.0197\n",
      "Epoch: 20/20, Batch: 50/1586, Loss: 0.6799\n",
      "Epoch: 20/20, Batch: 100/1586, Loss: 0.7918\n",
      "Epoch: 20/20, Batch: 150/1586, Loss: 1.0905\n",
      "Epoch: 20/20, Batch: 200/1586, Loss: 1.0402\n",
      "Epoch: 20/20, Batch: 250/1586, Loss: 1.1282\n",
      "Epoch: 20/20, Batch: 300/1586, Loss: 0.8916\n",
      "Epoch: 20/20, Batch: 350/1586, Loss: 1.3061\n",
      "Epoch: 20/20, Batch: 400/1586, Loss: 0.9345\n",
      "Epoch: 20/20, Batch: 450/1586, Loss: 0.8698\n",
      "Epoch: 20/20, Batch: 500/1586, Loss: 1.0792\n",
      "Epoch: 20/20, Batch: 550/1586, Loss: 1.0702\n",
      "Epoch: 20/20, Batch: 600/1586, Loss: 0.8740\n",
      "Epoch: 20/20, Batch: 650/1586, Loss: 1.0664\n",
      "Epoch: 20/20, Batch: 700/1586, Loss: 1.1206\n",
      "Epoch: 20/20, Batch: 750/1586, Loss: 1.0353\n",
      "Epoch: 20/20, Batch: 800/1586, Loss: 0.8859\n",
      "Epoch: 20/20, Batch: 850/1586, Loss: 1.1017\n",
      "Epoch: 20/20, Batch: 900/1586, Loss: 1.0323\n",
      "Epoch: 20/20, Batch: 950/1586, Loss: 0.9092\n",
      "Epoch: 20/20, Batch: 1000/1586, Loss: 1.0082\n",
      "Epoch: 20/20, Batch: 1050/1586, Loss: 1.1634\n",
      "Epoch: 20/20, Batch: 1100/1586, Loss: 0.9028\n",
      "Epoch: 20/20, Batch: 1150/1586, Loss: 0.8265\n",
      "Epoch: 20/20, Batch: 1200/1586, Loss: 0.8547\n",
      "Epoch: 20/20, Batch: 1250/1586, Loss: 0.9880\n",
      "Epoch: 20/20, Batch: 1300/1586, Loss: 0.6427\n",
      "Epoch: 20/20, Batch: 1350/1586, Loss: 0.9981\n",
      "Epoch: 20/20, Batch: 1400/1586, Loss: 0.9086\n",
      "Epoch: 20/20, Batch: 1450/1586, Loss: 0.9703\n",
      "Epoch: 20/20, Batch: 1500/1586, Loss: 0.8784\n",
      "Epoch: 20/20, Batch: 1550/1586, Loss: 0.8799\n",
      "Epoch: 20, Train Loss: 0.9908\n",
      "Training finished!\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "icOYfTb5AihX",
    "outputId": "d313ac56-05f8-47da-87f5-708779b8b1b1",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:07:58.280677Z",
     "start_time": "2025-11-05T04:07:57.778025Z"
    }
   },
   "source": [
    "weighted_model.eval()\n",
    "y_true_weighted = []\n",
    "y_pred_weighted = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = weighted_model(data)\n",
    "\n",
    "        y_true_weighted.extend(target.cpu().numpy())\n",
    "        y_pred_weighted.extend((output > 0.5).cpu().numpy())\n",
    "\n",
    "y_true_weighted = np.array(y_true_weighted)\n",
    "y_pred_weighted = np.array(y_pred_weighted)\n",
    "\n",
    "print(\"\\nClassification Report (Weighted):\")\n",
    "print(classification_report(y_true_weighted, y_pred_weighted))\n",
    "print(\"\\nConfusion Matrix (Weighted):\")\n",
    "cm_weighted = confusion_matrix(y_true_weighted, y_pred_weighted)\n",
    "sns.heatmap(cm_weighted, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Weighted)')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Weighted):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.73      0.83     45957\n",
      "         1.0       0.24      0.80      0.37      4779\n",
      "\n",
      "    accuracy                           0.74     50736\n",
      "   macro avg       0.60      0.77      0.60     50736\n",
      "weighted avg       0.90      0.74      0.79     50736\n",
      "\n",
      "\n",
      "Confusion Matrix (Weighted):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MevyHONqAihX"
   },
   "source": [
    "#### PCA(6)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O2z9X6YvAihX",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:07:58.523920Z",
     "start_time": "2025-11-05T04:07:58.295079Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "std = StandardScaler()\n",
    "X_train_scaled = std.fit_transform(X_train)\n",
    "X_test_scaled = std.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=6)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "train_dataset = HeartDiseaseDataset(X_train_pca, y_train)\n",
    "test_dataset = HeartDiseaseDataset(X_test_pca, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3xN7pmVAihi",
    "outputId": "38aea7f0-0eba-4260-ef9c-4f5ea1459452",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:09:41.720297Z",
     "start_time": "2025-11-05T04:07:58.543430Z"
    }
   },
   "source": [
    "class_0_frequency = np.sum(y_train == 0) / len(y_train)\n",
    "class_1_frequency = np.sum(y_train == 1) / len(y_train)\n",
    "class_frequencies = [class_0_frequency, class_1_frequency]\n",
    "print(f\"Class frequencies: {class_frequencies}\")\n",
    "\n",
    "input_features = X_train_pca.shape[1]\n",
    "\n",
    "weighted_model = HeartDiseaseMLPClassifier(input_size=input_features, class_frequencies=class_frequencies).to(device)\n",
    "\n",
    "optimizer = optim.Adam(weighted_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "num_epochs = 20\n",
    "weighted_train_losses = []\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    weighted_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = weighted_model(data)\n",
    "\n",
    "        target = target.float()\n",
    "        output = output.float()\n",
    "        loss = weighted_model.get_weighted_loss(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    weighted_train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "print('Training finished!')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class frequencies: [np.float64(0.9058163828445286), np.float64(0.09418361715547147)]\n",
      "\n",
      "Starting training...\n",
      "Epoch: 1/20, Batch: 0/1586, Loss: 1.3281\n",
      "Epoch: 1/20, Batch: 50/1586, Loss: 0.8667\n",
      "Epoch: 1/20, Batch: 100/1586, Loss: 1.1205\n",
      "Epoch: 1/20, Batch: 150/1586, Loss: 1.4602\n",
      "Epoch: 1/20, Batch: 200/1586, Loss: 1.0484\n",
      "Epoch: 1/20, Batch: 250/1586, Loss: 1.1738\n",
      "Epoch: 1/20, Batch: 300/1586, Loss: 0.7465\n",
      "Epoch: 1/20, Batch: 350/1586, Loss: 1.2448\n",
      "Epoch: 1/20, Batch: 400/1586, Loss: 1.2782\n",
      "Epoch: 1/20, Batch: 450/1586, Loss: 0.9241\n",
      "Epoch: 1/20, Batch: 500/1586, Loss: 1.0658\n",
      "Epoch: 1/20, Batch: 550/1586, Loss: 1.1492\n",
      "Epoch: 1/20, Batch: 600/1586, Loss: 0.9507\n",
      "Epoch: 1/20, Batch: 650/1586, Loss: 1.1058\n",
      "Epoch: 1/20, Batch: 700/1586, Loss: 0.7979\n",
      "Epoch: 1/20, Batch: 750/1586, Loss: 1.0993\n",
      "Epoch: 1/20, Batch: 800/1586, Loss: 0.9007\n",
      "Epoch: 1/20, Batch: 850/1586, Loss: 0.8968\n",
      "Epoch: 1/20, Batch: 900/1586, Loss: 0.9147\n",
      "Epoch: 1/20, Batch: 950/1586, Loss: 0.9121\n",
      "Epoch: 1/20, Batch: 1000/1586, Loss: 0.8922\n",
      "Epoch: 1/20, Batch: 1050/1586, Loss: 0.9618\n",
      "Epoch: 1/20, Batch: 1100/1586, Loss: 0.9391\n",
      "Epoch: 1/20, Batch: 1150/1586, Loss: 1.2847\n",
      "Epoch: 1/20, Batch: 1200/1586, Loss: 0.9640\n",
      "Epoch: 1/20, Batch: 1250/1586, Loss: 0.9577\n",
      "Epoch: 1/20, Batch: 1300/1586, Loss: 0.8789\n",
      "Epoch: 1/20, Batch: 1350/1586, Loss: 0.8728\n",
      "Epoch: 1/20, Batch: 1400/1586, Loss: 1.3482\n",
      "Epoch: 1/20, Batch: 1450/1586, Loss: 0.9396\n",
      "Epoch: 1/20, Batch: 1500/1586, Loss: 0.7613\n",
      "Epoch: 1/20, Batch: 1550/1586, Loss: 0.8891\n",
      "Epoch: 1, Train Loss: 1.0306\n",
      "Epoch: 2/20, Batch: 0/1586, Loss: 1.1614\n",
      "Epoch: 2/20, Batch: 50/1586, Loss: 1.0182\n",
      "Epoch: 2/20, Batch: 100/1586, Loss: 1.0806\n",
      "Epoch: 2/20, Batch: 150/1586, Loss: 1.0425\n",
      "Epoch: 2/20, Batch: 200/1586, Loss: 0.9670\n",
      "Epoch: 2/20, Batch: 250/1586, Loss: 0.9584\n",
      "Epoch: 2/20, Batch: 300/1586, Loss: 1.0643\n",
      "Epoch: 2/20, Batch: 350/1586, Loss: 0.7786\n",
      "Epoch: 2/20, Batch: 400/1586, Loss: 0.9945\n",
      "Epoch: 2/20, Batch: 450/1586, Loss: 0.8633\n",
      "Epoch: 2/20, Batch: 500/1586, Loss: 1.0836\n",
      "Epoch: 2/20, Batch: 550/1586, Loss: 1.1050\n",
      "Epoch: 2/20, Batch: 600/1586, Loss: 0.8843\n",
      "Epoch: 2/20, Batch: 650/1586, Loss: 0.9641\n",
      "Epoch: 2/20, Batch: 700/1586, Loss: 0.9113\n",
      "Epoch: 2/20, Batch: 750/1586, Loss: 0.7441\n",
      "Epoch: 2/20, Batch: 800/1586, Loss: 1.2491\n",
      "Epoch: 2/20, Batch: 850/1586, Loss: 0.7963\n",
      "Epoch: 2/20, Batch: 900/1586, Loss: 1.0684\n",
      "Epoch: 2/20, Batch: 950/1586, Loss: 1.1312\n",
      "Epoch: 2/20, Batch: 1000/1586, Loss: 0.7691\n",
      "Epoch: 2/20, Batch: 1050/1586, Loss: 0.8709\n",
      "Epoch: 2/20, Batch: 1100/1586, Loss: 0.9517\n",
      "Epoch: 2/20, Batch: 1150/1586, Loss: 0.9559\n",
      "Epoch: 2/20, Batch: 1200/1586, Loss: 1.1334\n",
      "Epoch: 2/20, Batch: 1250/1586, Loss: 1.0886\n",
      "Epoch: 2/20, Batch: 1300/1586, Loss: 1.1659\n",
      "Epoch: 2/20, Batch: 1350/1586, Loss: 0.8949\n",
      "Epoch: 2/20, Batch: 1400/1586, Loss: 0.8766\n",
      "Epoch: 2/20, Batch: 1450/1586, Loss: 0.9703\n",
      "Epoch: 2/20, Batch: 1500/1586, Loss: 1.0053\n",
      "Epoch: 2/20, Batch: 1550/1586, Loss: 1.1251\n",
      "Epoch: 2, Train Loss: 1.0169\n",
      "Epoch: 3/20, Batch: 0/1586, Loss: 0.9381\n",
      "Epoch: 3/20, Batch: 50/1586, Loss: 1.1286\n",
      "Epoch: 3/20, Batch: 100/1586, Loss: 1.1424\n",
      "Epoch: 3/20, Batch: 150/1586, Loss: 1.3527\n",
      "Epoch: 3/20, Batch: 200/1586, Loss: 0.7211\n",
      "Epoch: 3/20, Batch: 250/1586, Loss: 0.9183\n",
      "Epoch: 3/20, Batch: 300/1586, Loss: 0.9173\n",
      "Epoch: 3/20, Batch: 350/1586, Loss: 0.8607\n",
      "Epoch: 3/20, Batch: 400/1586, Loss: 0.8023\n",
      "Epoch: 3/20, Batch: 450/1586, Loss: 1.1539\n",
      "Epoch: 3/20, Batch: 500/1586, Loss: 1.2248\n",
      "Epoch: 3/20, Batch: 550/1586, Loss: 1.1233\n",
      "Epoch: 3/20, Batch: 600/1586, Loss: 0.9559\n",
      "Epoch: 3/20, Batch: 650/1586, Loss: 1.1806\n",
      "Epoch: 3/20, Batch: 700/1586, Loss: 1.1241\n",
      "Epoch: 3/20, Batch: 750/1586, Loss: 0.8088\n",
      "Epoch: 3/20, Batch: 800/1586, Loss: 1.1231\n",
      "Epoch: 3/20, Batch: 850/1586, Loss: 0.9930\n",
      "Epoch: 3/20, Batch: 900/1586, Loss: 0.8596\n",
      "Epoch: 3/20, Batch: 950/1586, Loss: 0.8469\n",
      "Epoch: 3/20, Batch: 1000/1586, Loss: 1.4391\n",
      "Epoch: 3/20, Batch: 1050/1586, Loss: 1.1197\n",
      "Epoch: 3/20, Batch: 1100/1586, Loss: 0.8537\n",
      "Epoch: 3/20, Batch: 1150/1586, Loss: 1.0814\n",
      "Epoch: 3/20, Batch: 1200/1586, Loss: 0.9507\n",
      "Epoch: 3/20, Batch: 1250/1586, Loss: 0.8968\n",
      "Epoch: 3/20, Batch: 1300/1586, Loss: 0.8393\n",
      "Epoch: 3/20, Batch: 1350/1586, Loss: 1.0155\n",
      "Epoch: 3/20, Batch: 1400/1586, Loss: 0.9211\n",
      "Epoch: 3/20, Batch: 1450/1586, Loss: 0.9261\n",
      "Epoch: 3/20, Batch: 1500/1586, Loss: 0.8543\n",
      "Epoch: 3/20, Batch: 1550/1586, Loss: 1.1142\n",
      "Epoch: 3, Train Loss: 1.0149\n",
      "Epoch: 4/20, Batch: 0/1586, Loss: 0.9467\n",
      "Epoch: 4/20, Batch: 50/1586, Loss: 0.7813\n",
      "Epoch: 4/20, Batch: 100/1586, Loss: 0.7690\n",
      "Epoch: 4/20, Batch: 150/1586, Loss: 1.0517\n",
      "Epoch: 4/20, Batch: 200/1586, Loss: 0.9172\n",
      "Epoch: 4/20, Batch: 250/1586, Loss: 1.0236\n",
      "Epoch: 4/20, Batch: 300/1586, Loss: 1.1729\n",
      "Epoch: 4/20, Batch: 350/1586, Loss: 1.0300\n",
      "Epoch: 4/20, Batch: 400/1586, Loss: 0.7934\n",
      "Epoch: 4/20, Batch: 450/1586, Loss: 0.6803\n",
      "Epoch: 4/20, Batch: 500/1586, Loss: 1.0265\n",
      "Epoch: 4/20, Batch: 550/1586, Loss: 1.0140\n",
      "Epoch: 4/20, Batch: 600/1586, Loss: 1.4847\n",
      "Epoch: 4/20, Batch: 650/1586, Loss: 0.7819\n",
      "Epoch: 4/20, Batch: 700/1586, Loss: 1.1130\n",
      "Epoch: 4/20, Batch: 750/1586, Loss: 1.1792\n",
      "Epoch: 4/20, Batch: 800/1586, Loss: 0.8916\n",
      "Epoch: 4/20, Batch: 850/1586, Loss: 1.2576\n",
      "Epoch: 4/20, Batch: 900/1586, Loss: 1.1056\n",
      "Epoch: 4/20, Batch: 950/1586, Loss: 0.8354\n",
      "Epoch: 4/20, Batch: 1000/1586, Loss: 1.0479\n",
      "Epoch: 4/20, Batch: 1050/1586, Loss: 1.0633\n",
      "Epoch: 4/20, Batch: 1100/1586, Loss: 0.8967\n",
      "Epoch: 4/20, Batch: 1150/1586, Loss: 1.0415\n",
      "Epoch: 4/20, Batch: 1200/1586, Loss: 1.0898\n",
      "Epoch: 4/20, Batch: 1250/1586, Loss: 0.8297\n",
      "Epoch: 4/20, Batch: 1300/1586, Loss: 0.9043\n",
      "Epoch: 4/20, Batch: 1350/1586, Loss: 1.2011\n",
      "Epoch: 4/20, Batch: 1400/1586, Loss: 0.9109\n",
      "Epoch: 4/20, Batch: 1450/1586, Loss: 1.0889\n",
      "Epoch: 4/20, Batch: 1500/1586, Loss: 0.8141\n",
      "Epoch: 4/20, Batch: 1550/1586, Loss: 1.0940\n",
      "Epoch: 4, Train Loss: 1.0132\n",
      "Epoch: 5/20, Batch: 0/1586, Loss: 0.8484\n",
      "Epoch: 5/20, Batch: 50/1586, Loss: 0.7966\n",
      "Epoch: 5/20, Batch: 100/1586, Loss: 1.0851\n",
      "Epoch: 5/20, Batch: 150/1586, Loss: 1.1133\n",
      "Epoch: 5/20, Batch: 200/1586, Loss: 1.0829\n",
      "Epoch: 5/20, Batch: 250/1586, Loss: 0.8219\n",
      "Epoch: 5/20, Batch: 300/1586, Loss: 1.5049\n",
      "Epoch: 5/20, Batch: 350/1586, Loss: 1.0532\n",
      "Epoch: 5/20, Batch: 400/1586, Loss: 1.0119\n",
      "Epoch: 5/20, Batch: 450/1586, Loss: 0.9278\n",
      "Epoch: 5/20, Batch: 500/1586, Loss: 1.2255\n",
      "Epoch: 5/20, Batch: 550/1586, Loss: 0.8078\n",
      "Epoch: 5/20, Batch: 600/1586, Loss: 1.0150\n",
      "Epoch: 5/20, Batch: 650/1586, Loss: 0.6487\n",
      "Epoch: 5/20, Batch: 700/1586, Loss: 0.9175\n",
      "Epoch: 5/20, Batch: 750/1586, Loss: 1.0603\n",
      "Epoch: 5/20, Batch: 800/1586, Loss: 0.7883\n",
      "Epoch: 5/20, Batch: 850/1586, Loss: 0.7971\n",
      "Epoch: 5/20, Batch: 900/1586, Loss: 1.1759\n",
      "Epoch: 5/20, Batch: 950/1586, Loss: 0.8451\n",
      "Epoch: 5/20, Batch: 1000/1586, Loss: 1.0138\n",
      "Epoch: 5/20, Batch: 1050/1586, Loss: 0.8622\n",
      "Epoch: 5/20, Batch: 1100/1586, Loss: 0.9482\n",
      "Epoch: 5/20, Batch: 1150/1586, Loss: 0.9499\n",
      "Epoch: 5/20, Batch: 1200/1586, Loss: 1.2238\n",
      "Epoch: 5/20, Batch: 1250/1586, Loss: 0.9996\n",
      "Epoch: 5/20, Batch: 1300/1586, Loss: 0.8779\n",
      "Epoch: 5/20, Batch: 1350/1586, Loss: 1.0194\n",
      "Epoch: 5/20, Batch: 1400/1586, Loss: 0.7495\n",
      "Epoch: 5/20, Batch: 1450/1586, Loss: 1.0113\n",
      "Epoch: 5/20, Batch: 1500/1586, Loss: 0.8261\n",
      "Epoch: 5/20, Batch: 1550/1586, Loss: 1.0416\n",
      "Epoch: 5, Train Loss: 1.0115\n",
      "Epoch: 6/20, Batch: 0/1586, Loss: 1.0098\n",
      "Epoch: 6/20, Batch: 50/1586, Loss: 1.0307\n",
      "Epoch: 6/20, Batch: 100/1586, Loss: 1.2220\n",
      "Epoch: 6/20, Batch: 150/1586, Loss: 0.7448\n",
      "Epoch: 6/20, Batch: 200/1586, Loss: 1.0721\n",
      "Epoch: 6/20, Batch: 250/1586, Loss: 1.1516\n",
      "Epoch: 6/20, Batch: 300/1586, Loss: 0.6999\n",
      "Epoch: 6/20, Batch: 350/1586, Loss: 0.7714\n",
      "Epoch: 6/20, Batch: 400/1586, Loss: 0.8763\n",
      "Epoch: 6/20, Batch: 450/1586, Loss: 0.7384\n",
      "Epoch: 6/20, Batch: 500/1586, Loss: 0.8042\n",
      "Epoch: 6/20, Batch: 550/1586, Loss: 0.9306\n",
      "Epoch: 6/20, Batch: 600/1586, Loss: 1.3145\n",
      "Epoch: 6/20, Batch: 650/1586, Loss: 0.7169\n",
      "Epoch: 6/20, Batch: 700/1586, Loss: 1.4490\n",
      "Epoch: 6/20, Batch: 750/1586, Loss: 0.8669\n",
      "Epoch: 6/20, Batch: 800/1586, Loss: 1.0714\n",
      "Epoch: 6/20, Batch: 850/1586, Loss: 0.9126\n",
      "Epoch: 6/20, Batch: 900/1586, Loss: 0.7799\n",
      "Epoch: 6/20, Batch: 950/1586, Loss: 0.7895\n",
      "Epoch: 6/20, Batch: 1000/1586, Loss: 0.9023\n",
      "Epoch: 6/20, Batch: 1050/1586, Loss: 0.9046\n",
      "Epoch: 6/20, Batch: 1100/1586, Loss: 0.9187\n",
      "Epoch: 6/20, Batch: 1150/1586, Loss: 0.9556\n",
      "Epoch: 6/20, Batch: 1200/1586, Loss: 1.3334\n",
      "Epoch: 6/20, Batch: 1250/1586, Loss: 1.0313\n",
      "Epoch: 6/20, Batch: 1300/1586, Loss: 1.1877\n",
      "Epoch: 6/20, Batch: 1350/1586, Loss: 1.0601\n",
      "Epoch: 6/20, Batch: 1400/1586, Loss: 0.9798\n",
      "Epoch: 6/20, Batch: 1450/1586, Loss: 0.7809\n",
      "Epoch: 6/20, Batch: 1500/1586, Loss: 1.3382\n",
      "Epoch: 6/20, Batch: 1550/1586, Loss: 0.8039\n",
      "Epoch: 6, Train Loss: 1.0107\n",
      "Epoch: 7/20, Batch: 0/1586, Loss: 0.8213\n",
      "Epoch: 7/20, Batch: 50/1586, Loss: 0.8975\n",
      "Epoch: 7/20, Batch: 100/1586, Loss: 1.1661\n",
      "Epoch: 7/20, Batch: 150/1586, Loss: 1.0915\n",
      "Epoch: 7/20, Batch: 200/1586, Loss: 0.9604\n",
      "Epoch: 7/20, Batch: 250/1586, Loss: 1.1599\n",
      "Epoch: 7/20, Batch: 300/1586, Loss: 0.8960\n",
      "Epoch: 7/20, Batch: 350/1586, Loss: 0.7448\n",
      "Epoch: 7/20, Batch: 400/1586, Loss: 1.0409\n",
      "Epoch: 7/20, Batch: 450/1586, Loss: 0.9181\n",
      "Epoch: 7/20, Batch: 500/1586, Loss: 1.0283\n",
      "Epoch: 7/20, Batch: 550/1586, Loss: 1.0566\n",
      "Epoch: 7/20, Batch: 600/1586, Loss: 1.5802\n",
      "Epoch: 7/20, Batch: 650/1586, Loss: 1.1040\n",
      "Epoch: 7/20, Batch: 700/1586, Loss: 1.0815\n",
      "Epoch: 7/20, Batch: 750/1586, Loss: 0.9389\n",
      "Epoch: 7/20, Batch: 800/1586, Loss: 1.6563\n",
      "Epoch: 7/20, Batch: 850/1586, Loss: 0.8792\n",
      "Epoch: 7/20, Batch: 900/1586, Loss: 1.1457\n",
      "Epoch: 7/20, Batch: 950/1586, Loss: 0.9684\n",
      "Epoch: 7/20, Batch: 1000/1586, Loss: 0.9430\n",
      "Epoch: 7/20, Batch: 1050/1586, Loss: 0.6831\n",
      "Epoch: 7/20, Batch: 1100/1586, Loss: 1.1474\n",
      "Epoch: 7/20, Batch: 1150/1586, Loss: 0.8181\n",
      "Epoch: 7/20, Batch: 1200/1586, Loss: 1.1997\n",
      "Epoch: 7/20, Batch: 1250/1586, Loss: 0.8436\n",
      "Epoch: 7/20, Batch: 1300/1586, Loss: 1.0469\n",
      "Epoch: 7/20, Batch: 1350/1586, Loss: 0.9329\n",
      "Epoch: 7/20, Batch: 1400/1586, Loss: 0.7322\n",
      "Epoch: 7/20, Batch: 1450/1586, Loss: 0.8290\n",
      "Epoch: 7/20, Batch: 1500/1586, Loss: 0.7464\n",
      "Epoch: 7/20, Batch: 1550/1586, Loss: 1.3375\n",
      "Epoch: 7, Train Loss: 1.0128\n",
      "Epoch: 8/20, Batch: 0/1586, Loss: 0.9080\n",
      "Epoch: 8/20, Batch: 50/1586, Loss: 0.7908\n",
      "Epoch: 8/20, Batch: 100/1586, Loss: 1.1168\n",
      "Epoch: 8/20, Batch: 150/1586, Loss: 1.1099\n",
      "Epoch: 8/20, Batch: 200/1586, Loss: 1.0170\n",
      "Epoch: 8/20, Batch: 250/1586, Loss: 0.7596\n",
      "Epoch: 8/20, Batch: 300/1586, Loss: 1.0545\n",
      "Epoch: 8/20, Batch: 350/1586, Loss: 0.7714\n",
      "Epoch: 8/20, Batch: 400/1586, Loss: 0.9168\n",
      "Epoch: 8/20, Batch: 450/1586, Loss: 0.8392\n",
      "Epoch: 8/20, Batch: 500/1586, Loss: 0.8219\n",
      "Epoch: 8/20, Batch: 550/1586, Loss: 1.0921\n",
      "Epoch: 8/20, Batch: 600/1586, Loss: 0.9879\n",
      "Epoch: 8/20, Batch: 650/1586, Loss: 0.7145\n",
      "Epoch: 8/20, Batch: 700/1586, Loss: 1.0657\n",
      "Epoch: 8/20, Batch: 750/1586, Loss: 0.8495\n",
      "Epoch: 8/20, Batch: 800/1586, Loss: 0.8605\n",
      "Epoch: 8/20, Batch: 850/1586, Loss: 1.0919\n",
      "Epoch: 8/20, Batch: 900/1586, Loss: 1.0705\n",
      "Epoch: 8/20, Batch: 950/1586, Loss: 0.8130\n",
      "Epoch: 8/20, Batch: 1000/1586, Loss: 0.7214\n",
      "Epoch: 8/20, Batch: 1050/1586, Loss: 0.7197\n",
      "Epoch: 8/20, Batch: 1100/1586, Loss: 0.9703\n",
      "Epoch: 8/20, Batch: 1150/1586, Loss: 1.0490\n",
      "Epoch: 8/20, Batch: 1200/1586, Loss: 0.7035\n",
      "Epoch: 8/20, Batch: 1250/1586, Loss: 0.9168\n",
      "Epoch: 8/20, Batch: 1300/1586, Loss: 1.3451\n",
      "Epoch: 8/20, Batch: 1350/1586, Loss: 0.8494\n",
      "Epoch: 8/20, Batch: 1400/1586, Loss: 0.7148\n",
      "Epoch: 8/20, Batch: 1450/1586, Loss: 1.1516\n",
      "Epoch: 8/20, Batch: 1500/1586, Loss: 0.9312\n",
      "Epoch: 8/20, Batch: 1550/1586, Loss: 1.0982\n",
      "Epoch: 8, Train Loss: 1.0084\n",
      "Epoch: 9/20, Batch: 0/1586, Loss: 0.9869\n",
      "Epoch: 9/20, Batch: 50/1586, Loss: 1.5338\n",
      "Epoch: 9/20, Batch: 100/1586, Loss: 0.7660\n",
      "Epoch: 9/20, Batch: 150/1586, Loss: 0.8046\n",
      "Epoch: 9/20, Batch: 200/1586, Loss: 0.9934\n",
      "Epoch: 9/20, Batch: 250/1586, Loss: 0.9494\n",
      "Epoch: 9/20, Batch: 300/1586, Loss: 0.9053\n",
      "Epoch: 9/20, Batch: 350/1586, Loss: 0.8391\n",
      "Epoch: 9/20, Batch: 400/1586, Loss: 1.6891\n",
      "Epoch: 9/20, Batch: 450/1586, Loss: 1.0747\n",
      "Epoch: 9/20, Batch: 500/1586, Loss: 0.8395\n",
      "Epoch: 9/20, Batch: 550/1586, Loss: 0.7984\n",
      "Epoch: 9/20, Batch: 600/1586, Loss: 0.8238\n",
      "Epoch: 9/20, Batch: 650/1586, Loss: 1.0069\n",
      "Epoch: 9/20, Batch: 700/1586, Loss: 1.3137\n",
      "Epoch: 9/20, Batch: 750/1586, Loss: 0.9383\n",
      "Epoch: 9/20, Batch: 800/1586, Loss: 0.8333\n",
      "Epoch: 9/20, Batch: 850/1586, Loss: 1.2192\n",
      "Epoch: 9/20, Batch: 900/1586, Loss: 0.9855\n",
      "Epoch: 9/20, Batch: 950/1586, Loss: 0.9166\n",
      "Epoch: 9/20, Batch: 1000/1586, Loss: 0.7643\n",
      "Epoch: 9/20, Batch: 1050/1586, Loss: 1.2605\n",
      "Epoch: 9/20, Batch: 1100/1586, Loss: 0.9315\n",
      "Epoch: 9/20, Batch: 1150/1586, Loss: 0.9069\n",
      "Epoch: 9/20, Batch: 1200/1586, Loss: 1.2580\n",
      "Epoch: 9/20, Batch: 1250/1586, Loss: 0.8548\n",
      "Epoch: 9/20, Batch: 1300/1586, Loss: 0.9671\n",
      "Epoch: 9/20, Batch: 1350/1586, Loss: 0.9194\n",
      "Epoch: 9/20, Batch: 1400/1586, Loss: 1.2112\n",
      "Epoch: 9/20, Batch: 1450/1586, Loss: 0.8147\n",
      "Epoch: 9/20, Batch: 1500/1586, Loss: 1.2915\n",
      "Epoch: 9/20, Batch: 1550/1586, Loss: 1.1918\n",
      "Epoch: 9, Train Loss: 1.0124\n",
      "Epoch: 10/20, Batch: 0/1586, Loss: 0.9836\n",
      "Epoch: 10/20, Batch: 50/1586, Loss: 0.9908\n",
      "Epoch: 10/20, Batch: 100/1586, Loss: 1.0128\n",
      "Epoch: 10/20, Batch: 150/1586, Loss: 0.9942\n",
      "Epoch: 10/20, Batch: 200/1586, Loss: 0.9187\n",
      "Epoch: 10/20, Batch: 250/1586, Loss: 0.7075\n",
      "Epoch: 10/20, Batch: 300/1586, Loss: 0.8159\n",
      "Epoch: 10/20, Batch: 350/1586, Loss: 1.1359\n",
      "Epoch: 10/20, Batch: 400/1586, Loss: 1.0155\n",
      "Epoch: 10/20, Batch: 450/1586, Loss: 1.4067\n",
      "Epoch: 10/20, Batch: 500/1586, Loss: 1.0532\n",
      "Epoch: 10/20, Batch: 550/1586, Loss: 1.0046\n",
      "Epoch: 10/20, Batch: 600/1586, Loss: 1.0809\n",
      "Epoch: 10/20, Batch: 650/1586, Loss: 0.8978\n",
      "Epoch: 10/20, Batch: 700/1586, Loss: 1.3082\n",
      "Epoch: 10/20, Batch: 750/1586, Loss: 0.8700\n",
      "Epoch: 10/20, Batch: 800/1586, Loss: 0.7927\n",
      "Epoch: 10/20, Batch: 850/1586, Loss: 1.0316\n",
      "Epoch: 10/20, Batch: 900/1586, Loss: 1.0734\n",
      "Epoch: 10/20, Batch: 950/1586, Loss: 0.9540\n",
      "Epoch: 10/20, Batch: 1000/1586, Loss: 1.2372\n",
      "Epoch: 10/20, Batch: 1050/1586, Loss: 1.1595\n",
      "Epoch: 10/20, Batch: 1100/1586, Loss: 0.8144\n",
      "Epoch: 10/20, Batch: 1150/1586, Loss: 0.8022\n",
      "Epoch: 10/20, Batch: 1200/1586, Loss: 1.0345\n",
      "Epoch: 10/20, Batch: 1250/1586, Loss: 1.4776\n",
      "Epoch: 10/20, Batch: 1300/1586, Loss: 0.9360\n",
      "Epoch: 10/20, Batch: 1350/1586, Loss: 0.9806\n",
      "Epoch: 10/20, Batch: 1400/1586, Loss: 0.9736\n",
      "Epoch: 10/20, Batch: 1450/1586, Loss: 0.9410\n",
      "Epoch: 10/20, Batch: 1500/1586, Loss: 0.9323\n",
      "Epoch: 10/20, Batch: 1550/1586, Loss: 1.2014\n",
      "Epoch: 10, Train Loss: 1.0110\n",
      "Epoch: 11/20, Batch: 0/1586, Loss: 1.2669\n",
      "Epoch: 11/20, Batch: 50/1586, Loss: 1.0688\n",
      "Epoch: 11/20, Batch: 100/1586, Loss: 1.0461\n",
      "Epoch: 11/20, Batch: 150/1586, Loss: 1.1853\n",
      "Epoch: 11/20, Batch: 200/1586, Loss: 0.9498\n",
      "Epoch: 11/20, Batch: 250/1586, Loss: 1.2160\n",
      "Epoch: 11/20, Batch: 300/1586, Loss: 1.0146\n",
      "Epoch: 11/20, Batch: 350/1586, Loss: 0.9897\n",
      "Epoch: 11/20, Batch: 400/1586, Loss: 1.0273\n",
      "Epoch: 11/20, Batch: 450/1586, Loss: 1.0234\n",
      "Epoch: 11/20, Batch: 500/1586, Loss: 1.2159\n",
      "Epoch: 11/20, Batch: 550/1586, Loss: 0.6926\n",
      "Epoch: 11/20, Batch: 600/1586, Loss: 0.9269\n",
      "Epoch: 11/20, Batch: 650/1586, Loss: 1.0482\n",
      "Epoch: 11/20, Batch: 700/1586, Loss: 1.1493\n",
      "Epoch: 11/20, Batch: 750/1586, Loss: 1.1209\n",
      "Epoch: 11/20, Batch: 800/1586, Loss: 0.8812\n",
      "Epoch: 11/20, Batch: 850/1586, Loss: 0.9442\n",
      "Epoch: 11/20, Batch: 900/1586, Loss: 0.8647\n",
      "Epoch: 11/20, Batch: 950/1586, Loss: 1.0254\n",
      "Epoch: 11/20, Batch: 1000/1586, Loss: 0.7727\n",
      "Epoch: 11/20, Batch: 1050/1586, Loss: 0.7774\n",
      "Epoch: 11/20, Batch: 1100/1586, Loss: 0.8038\n",
      "Epoch: 11/20, Batch: 1150/1586, Loss: 0.9889\n",
      "Epoch: 11/20, Batch: 1200/1586, Loss: 0.7973\n",
      "Epoch: 11/20, Batch: 1250/1586, Loss: 0.8086\n",
      "Epoch: 11/20, Batch: 1300/1586, Loss: 0.9799\n",
      "Epoch: 11/20, Batch: 1350/1586, Loss: 0.9633\n",
      "Epoch: 11/20, Batch: 1400/1586, Loss: 1.1582\n",
      "Epoch: 11/20, Batch: 1450/1586, Loss: 1.1920\n",
      "Epoch: 11/20, Batch: 1500/1586, Loss: 0.8658\n",
      "Epoch: 11/20, Batch: 1550/1586, Loss: 0.6888\n",
      "Epoch: 11, Train Loss: 1.0102\n",
      "Epoch: 12/20, Batch: 0/1586, Loss: 1.2229\n",
      "Epoch: 12/20, Batch: 50/1586, Loss: 0.8959\n",
      "Epoch: 12/20, Batch: 100/1586, Loss: 1.0356\n",
      "Epoch: 12/20, Batch: 150/1586, Loss: 1.4421\n",
      "Epoch: 12/20, Batch: 200/1586, Loss: 0.7625\n",
      "Epoch: 12/20, Batch: 250/1586, Loss: 0.8880\n",
      "Epoch: 12/20, Batch: 300/1586, Loss: 1.1175\n",
      "Epoch: 12/20, Batch: 350/1586, Loss: 1.3512\n",
      "Epoch: 12/20, Batch: 400/1586, Loss: 0.9725\n",
      "Epoch: 12/20, Batch: 450/1586, Loss: 0.9201\n",
      "Epoch: 12/20, Batch: 500/1586, Loss: 0.8288\n",
      "Epoch: 12/20, Batch: 550/1586, Loss: 1.1782\n",
      "Epoch: 12/20, Batch: 600/1586, Loss: 0.8555\n",
      "Epoch: 12/20, Batch: 650/1586, Loss: 0.8685\n",
      "Epoch: 12/20, Batch: 700/1586, Loss: 1.0232\n",
      "Epoch: 12/20, Batch: 750/1586, Loss: 1.2104\n",
      "Epoch: 12/20, Batch: 800/1586, Loss: 1.3850\n",
      "Epoch: 12/20, Batch: 850/1586, Loss: 0.8275\n",
      "Epoch: 12/20, Batch: 900/1586, Loss: 0.8555\n",
      "Epoch: 12/20, Batch: 950/1586, Loss: 0.7631\n",
      "Epoch: 12/20, Batch: 1000/1586, Loss: 0.8984\n",
      "Epoch: 12/20, Batch: 1050/1586, Loss: 0.8084\n",
      "Epoch: 12/20, Batch: 1100/1586, Loss: 0.8787\n",
      "Epoch: 12/20, Batch: 1150/1586, Loss: 0.7663\n",
      "Epoch: 12/20, Batch: 1200/1586, Loss: 1.2146\n",
      "Epoch: 12/20, Batch: 1250/1586, Loss: 1.1516\n",
      "Epoch: 12/20, Batch: 1300/1586, Loss: 0.8860\n",
      "Epoch: 12/20, Batch: 1350/1586, Loss: 1.1817\n",
      "Epoch: 12/20, Batch: 1400/1586, Loss: 0.9624\n",
      "Epoch: 12/20, Batch: 1450/1586, Loss: 1.0507\n",
      "Epoch: 12/20, Batch: 1500/1586, Loss: 0.8230\n",
      "Epoch: 12/20, Batch: 1550/1586, Loss: 1.1441\n",
      "Epoch: 12, Train Loss: 1.0092\n",
      "Epoch: 13/20, Batch: 0/1586, Loss: 1.1065\n",
      "Epoch: 13/20, Batch: 50/1586, Loss: 0.9107\n",
      "Epoch: 13/20, Batch: 100/1586, Loss: 1.2419\n",
      "Epoch: 13/20, Batch: 150/1586, Loss: 1.0126\n",
      "Epoch: 13/20, Batch: 200/1586, Loss: 1.3926\n",
      "Epoch: 13/20, Batch: 250/1586, Loss: 0.9449\n",
      "Epoch: 13/20, Batch: 300/1586, Loss: 1.1198\n",
      "Epoch: 13/20, Batch: 350/1586, Loss: 0.8889\n",
      "Epoch: 13/20, Batch: 400/1586, Loss: 0.9493\n",
      "Epoch: 13/20, Batch: 450/1586, Loss: 0.9681\n",
      "Epoch: 13/20, Batch: 500/1586, Loss: 1.1510\n",
      "Epoch: 13/20, Batch: 550/1586, Loss: 0.9711\n",
      "Epoch: 13/20, Batch: 600/1586, Loss: 1.0302\n",
      "Epoch: 13/20, Batch: 650/1586, Loss: 0.8475\n",
      "Epoch: 13/20, Batch: 700/1586, Loss: 0.6266\n",
      "Epoch: 13/20, Batch: 750/1586, Loss: 1.1040\n",
      "Epoch: 13/20, Batch: 800/1586, Loss: 0.9525\n",
      "Epoch: 13/20, Batch: 850/1586, Loss: 0.7214\n",
      "Epoch: 13/20, Batch: 900/1586, Loss: 1.1140\n",
      "Epoch: 13/20, Batch: 950/1586, Loss: 0.9872\n",
      "Epoch: 13/20, Batch: 1000/1586, Loss: 1.0974\n",
      "Epoch: 13/20, Batch: 1050/1586, Loss: 0.7615\n",
      "Epoch: 13/20, Batch: 1100/1586, Loss: 1.0347\n",
      "Epoch: 13/20, Batch: 1150/1586, Loss: 0.7561\n",
      "Epoch: 13/20, Batch: 1200/1586, Loss: 0.9207\n",
      "Epoch: 13/20, Batch: 1250/1586, Loss: 1.0823\n",
      "Epoch: 13/20, Batch: 1300/1586, Loss: 0.9605\n",
      "Epoch: 13/20, Batch: 1350/1586, Loss: 1.1174\n",
      "Epoch: 13/20, Batch: 1400/1586, Loss: 0.9853\n",
      "Epoch: 13/20, Batch: 1450/1586, Loss: 0.9410\n",
      "Epoch: 13/20, Batch: 1500/1586, Loss: 0.8340\n",
      "Epoch: 13/20, Batch: 1550/1586, Loss: 1.0640\n",
      "Epoch: 13, Train Loss: 1.0086\n",
      "Epoch: 14/20, Batch: 0/1586, Loss: 0.9063\n",
      "Epoch: 14/20, Batch: 50/1586, Loss: 0.9253\n",
      "Epoch: 14/20, Batch: 100/1586, Loss: 0.9576\n",
      "Epoch: 14/20, Batch: 150/1586, Loss: 0.9828\n",
      "Epoch: 14/20, Batch: 200/1586, Loss: 0.9894\n",
      "Epoch: 14/20, Batch: 250/1586, Loss: 1.0555\n",
      "Epoch: 14/20, Batch: 300/1586, Loss: 0.7237\n",
      "Epoch: 14/20, Batch: 350/1586, Loss: 0.8843\n",
      "Epoch: 14/20, Batch: 400/1586, Loss: 0.9870\n",
      "Epoch: 14/20, Batch: 450/1586, Loss: 0.7306\n",
      "Epoch: 14/20, Batch: 500/1586, Loss: 0.8765\n",
      "Epoch: 14/20, Batch: 550/1586, Loss: 0.9503\n",
      "Epoch: 14/20, Batch: 600/1586, Loss: 0.9153\n",
      "Epoch: 14/20, Batch: 650/1586, Loss: 0.9449\n",
      "Epoch: 14/20, Batch: 700/1586, Loss: 0.8542\n",
      "Epoch: 14/20, Batch: 750/1586, Loss: 0.7817\n",
      "Epoch: 14/20, Batch: 800/1586, Loss: 0.8126\n",
      "Epoch: 14/20, Batch: 850/1586, Loss: 1.0960\n",
      "Epoch: 14/20, Batch: 900/1586, Loss: 0.9331\n",
      "Epoch: 14/20, Batch: 950/1586, Loss: 0.7670\n",
      "Epoch: 14/20, Batch: 1000/1586, Loss: 1.1555\n",
      "Epoch: 14/20, Batch: 1050/1586, Loss: 1.1925\n",
      "Epoch: 14/20, Batch: 1100/1586, Loss: 1.0761\n",
      "Epoch: 14/20, Batch: 1150/1586, Loss: 1.1469\n",
      "Epoch: 14/20, Batch: 1200/1586, Loss: 0.8540\n",
      "Epoch: 14/20, Batch: 1250/1586, Loss: 1.1605\n",
      "Epoch: 14/20, Batch: 1300/1586, Loss: 1.1158\n",
      "Epoch: 14/20, Batch: 1350/1586, Loss: 1.0689\n",
      "Epoch: 14/20, Batch: 1400/1586, Loss: 0.8024\n",
      "Epoch: 14/20, Batch: 1450/1586, Loss: 0.7586\n",
      "Epoch: 14/20, Batch: 1500/1586, Loss: 0.7625\n",
      "Epoch: 14/20, Batch: 1550/1586, Loss: 1.2868\n",
      "Epoch: 14, Train Loss: 1.0072\n",
      "Epoch: 15/20, Batch: 0/1586, Loss: 1.1023\n",
      "Epoch: 15/20, Batch: 50/1586, Loss: 0.8563\n",
      "Epoch: 15/20, Batch: 100/1586, Loss: 0.7133\n",
      "Epoch: 15/20, Batch: 150/1586, Loss: 1.2757\n",
      "Epoch: 15/20, Batch: 200/1586, Loss: 1.0556\n",
      "Epoch: 15/20, Batch: 250/1586, Loss: 0.8887\n",
      "Epoch: 15/20, Batch: 300/1586, Loss: 0.8990\n",
      "Epoch: 15/20, Batch: 350/1586, Loss: 1.3523\n",
      "Epoch: 15/20, Batch: 400/1586, Loss: 0.9274\n",
      "Epoch: 15/20, Batch: 450/1586, Loss: 1.2775\n",
      "Epoch: 15/20, Batch: 500/1586, Loss: 1.0649\n",
      "Epoch: 15/20, Batch: 550/1586, Loss: 1.0317\n",
      "Epoch: 15/20, Batch: 600/1586, Loss: 1.0707\n",
      "Epoch: 15/20, Batch: 650/1586, Loss: 0.9240\n",
      "Epoch: 15/20, Batch: 700/1586, Loss: 0.8787\n",
      "Epoch: 15/20, Batch: 750/1586, Loss: 0.8321\n",
      "Epoch: 15/20, Batch: 800/1586, Loss: 0.9140\n",
      "Epoch: 15/20, Batch: 850/1586, Loss: 0.7812\n",
      "Epoch: 15/20, Batch: 900/1586, Loss: 0.8913\n",
      "Epoch: 15/20, Batch: 950/1586, Loss: 1.4269\n",
      "Epoch: 15/20, Batch: 1000/1586, Loss: 1.0203\n",
      "Epoch: 15/20, Batch: 1050/1586, Loss: 1.1131\n",
      "Epoch: 15/20, Batch: 1100/1586, Loss: 1.0471\n",
      "Epoch: 15/20, Batch: 1150/1586, Loss: 0.9641\n",
      "Epoch: 15/20, Batch: 1200/1586, Loss: 0.9869\n",
      "Epoch: 15/20, Batch: 1250/1586, Loss: 1.0163\n",
      "Epoch: 15/20, Batch: 1300/1586, Loss: 0.9661\n",
      "Epoch: 15/20, Batch: 1350/1586, Loss: 1.0115\n",
      "Epoch: 15/20, Batch: 1400/1586, Loss: 1.2736\n",
      "Epoch: 15/20, Batch: 1450/1586, Loss: 0.8077\n",
      "Epoch: 15/20, Batch: 1500/1586, Loss: 0.9416\n",
      "Epoch: 15/20, Batch: 1550/1586, Loss: 1.0220\n",
      "Epoch: 15, Train Loss: 1.0081\n",
      "Epoch: 16/20, Batch: 0/1586, Loss: 1.1440\n",
      "Epoch: 16/20, Batch: 50/1586, Loss: 0.8371\n",
      "Epoch: 16/20, Batch: 100/1586, Loss: 0.7702\n",
      "Epoch: 16/20, Batch: 150/1586, Loss: 1.0081\n",
      "Epoch: 16/20, Batch: 200/1586, Loss: 1.0308\n",
      "Epoch: 16/20, Batch: 250/1586, Loss: 1.2403\n",
      "Epoch: 16/20, Batch: 300/1586, Loss: 1.0096\n",
      "Epoch: 16/20, Batch: 350/1586, Loss: 0.9290\n",
      "Epoch: 16/20, Batch: 400/1586, Loss: 0.9211\n",
      "Epoch: 16/20, Batch: 450/1586, Loss: 0.8599\n",
      "Epoch: 16/20, Batch: 500/1586, Loss: 0.9252\n",
      "Epoch: 16/20, Batch: 550/1586, Loss: 1.0791\n",
      "Epoch: 16/20, Batch: 600/1586, Loss: 0.8327\n",
      "Epoch: 16/20, Batch: 650/1586, Loss: 1.2882\n",
      "Epoch: 16/20, Batch: 700/1586, Loss: 0.9166\n",
      "Epoch: 16/20, Batch: 750/1586, Loss: 0.7131\n",
      "Epoch: 16/20, Batch: 800/1586, Loss: 0.8250\n",
      "Epoch: 16/20, Batch: 850/1586, Loss: 0.8615\n",
      "Epoch: 16/20, Batch: 900/1586, Loss: 0.8125\n",
      "Epoch: 16/20, Batch: 950/1586, Loss: 0.8638\n",
      "Epoch: 16/20, Batch: 1000/1586, Loss: 0.9621\n",
      "Epoch: 16/20, Batch: 1050/1586, Loss: 1.0956\n",
      "Epoch: 16/20, Batch: 1100/1586, Loss: 0.9898\n",
      "Epoch: 16/20, Batch: 1150/1586, Loss: 0.8362\n",
      "Epoch: 16/20, Batch: 1200/1586, Loss: 1.1614\n",
      "Epoch: 16/20, Batch: 1250/1586, Loss: 0.9621\n",
      "Epoch: 16/20, Batch: 1300/1586, Loss: 0.8547\n",
      "Epoch: 16/20, Batch: 1350/1586, Loss: 0.9161\n",
      "Epoch: 16/20, Batch: 1400/1586, Loss: 0.7730\n",
      "Epoch: 16/20, Batch: 1450/1586, Loss: 0.8891\n",
      "Epoch: 16/20, Batch: 1500/1586, Loss: 0.8781\n",
      "Epoch: 16/20, Batch: 1550/1586, Loss: 0.9531\n",
      "Epoch: 16, Train Loss: 1.0077\n",
      "Epoch: 17/20, Batch: 0/1586, Loss: 0.8229\n",
      "Epoch: 17/20, Batch: 50/1586, Loss: 0.7712\n",
      "Epoch: 17/20, Batch: 100/1586, Loss: 0.9757\n",
      "Epoch: 17/20, Batch: 150/1586, Loss: 0.9966\n",
      "Epoch: 17/20, Batch: 200/1586, Loss: 1.0574\n",
      "Epoch: 17/20, Batch: 250/1586, Loss: 0.9306\n",
      "Epoch: 17/20, Batch: 300/1586, Loss: 0.8265\n",
      "Epoch: 17/20, Batch: 350/1586, Loss: 1.2381\n",
      "Epoch: 17/20, Batch: 400/1586, Loss: 0.7346\n",
      "Epoch: 17/20, Batch: 450/1586, Loss: 1.0435\n",
      "Epoch: 17/20, Batch: 500/1586, Loss: 1.0141\n",
      "Epoch: 17/20, Batch: 550/1586, Loss: 0.7068\n",
      "Epoch: 17/20, Batch: 600/1586, Loss: 0.9695\n",
      "Epoch: 17/20, Batch: 650/1586, Loss: 0.8725\n",
      "Epoch: 17/20, Batch: 700/1586, Loss: 1.2789\n",
      "Epoch: 17/20, Batch: 750/1586, Loss: 1.1065\n",
      "Epoch: 17/20, Batch: 800/1586, Loss: 1.4907\n",
      "Epoch: 17/20, Batch: 850/1586, Loss: 1.6980\n",
      "Epoch: 17/20, Batch: 900/1586, Loss: 0.9734\n",
      "Epoch: 17/20, Batch: 950/1586, Loss: 0.8766\n",
      "Epoch: 17/20, Batch: 1000/1586, Loss: 0.8176\n",
      "Epoch: 17/20, Batch: 1050/1586, Loss: 0.8131\n",
      "Epoch: 17/20, Batch: 1100/1586, Loss: 0.8189\n",
      "Epoch: 17/20, Batch: 1150/1586, Loss: 0.8892\n",
      "Epoch: 17/20, Batch: 1200/1586, Loss: 1.0260\n",
      "Epoch: 17/20, Batch: 1250/1586, Loss: 1.6038\n",
      "Epoch: 17/20, Batch: 1300/1586, Loss: 0.8019\n",
      "Epoch: 17/20, Batch: 1350/1586, Loss: 1.1249\n",
      "Epoch: 17/20, Batch: 1400/1586, Loss: 1.2872\n",
      "Epoch: 17/20, Batch: 1450/1586, Loss: 0.6801\n",
      "Epoch: 17/20, Batch: 1500/1586, Loss: 0.7288\n",
      "Epoch: 17/20, Batch: 1550/1586, Loss: 0.8930\n",
      "Epoch: 17, Train Loss: 1.0082\n",
      "Epoch: 18/20, Batch: 0/1586, Loss: 1.1575\n",
      "Epoch: 18/20, Batch: 50/1586, Loss: 1.2354\n",
      "Epoch: 18/20, Batch: 100/1586, Loss: 0.9164\n",
      "Epoch: 18/20, Batch: 150/1586, Loss: 0.8320\n",
      "Epoch: 18/20, Batch: 200/1586, Loss: 1.1735\n",
      "Epoch: 18/20, Batch: 250/1586, Loss: 1.5179\n",
      "Epoch: 18/20, Batch: 300/1586, Loss: 0.8767\n",
      "Epoch: 18/20, Batch: 350/1586, Loss: 0.9786\n",
      "Epoch: 18/20, Batch: 400/1586, Loss: 1.3205\n",
      "Epoch: 18/20, Batch: 450/1586, Loss: 0.8530\n",
      "Epoch: 18/20, Batch: 500/1586, Loss: 0.9952\n",
      "Epoch: 18/20, Batch: 550/1586, Loss: 1.0358\n",
      "Epoch: 18/20, Batch: 600/1586, Loss: 1.0211\n",
      "Epoch: 18/20, Batch: 650/1586, Loss: 0.9539\n",
      "Epoch: 18/20, Batch: 700/1586, Loss: 0.9353\n",
      "Epoch: 18/20, Batch: 750/1586, Loss: 0.8998\n",
      "Epoch: 18/20, Batch: 800/1586, Loss: 0.9241\n",
      "Epoch: 18/20, Batch: 850/1586, Loss: 1.1287\n",
      "Epoch: 18/20, Batch: 900/1586, Loss: 1.4239\n",
      "Epoch: 18/20, Batch: 950/1586, Loss: 1.0924\n",
      "Epoch: 18/20, Batch: 1000/1586, Loss: 0.8968\n",
      "Epoch: 18/20, Batch: 1050/1586, Loss: 1.0863\n",
      "Epoch: 18/20, Batch: 1100/1586, Loss: 1.1537\n",
      "Epoch: 18/20, Batch: 1150/1586, Loss: 0.7934\n",
      "Epoch: 18/20, Batch: 1200/1586, Loss: 1.2273\n",
      "Epoch: 18/20, Batch: 1250/1586, Loss: 0.7445\n",
      "Epoch: 18/20, Batch: 1300/1586, Loss: 0.9232\n",
      "Epoch: 18/20, Batch: 1350/1586, Loss: 1.2023\n",
      "Epoch: 18/20, Batch: 1400/1586, Loss: 1.2125\n",
      "Epoch: 18/20, Batch: 1450/1586, Loss: 1.0515\n",
      "Epoch: 18/20, Batch: 1500/1586, Loss: 0.9760\n",
      "Epoch: 18/20, Batch: 1550/1586, Loss: 0.8309\n",
      "Epoch: 18, Train Loss: 1.0077\n",
      "Epoch: 19/20, Batch: 0/1586, Loss: 0.7998\n",
      "Epoch: 19/20, Batch: 50/1586, Loss: 1.1796\n",
      "Epoch: 19/20, Batch: 100/1586, Loss: 0.8506\n",
      "Epoch: 19/20, Batch: 150/1586, Loss: 0.8311\n",
      "Epoch: 19/20, Batch: 200/1586, Loss: 1.0499\n",
      "Epoch: 19/20, Batch: 250/1586, Loss: 0.9722\n",
      "Epoch: 19/20, Batch: 300/1586, Loss: 0.6845\n",
      "Epoch: 19/20, Batch: 350/1586, Loss: 1.0039\n",
      "Epoch: 19/20, Batch: 400/1586, Loss: 1.1277\n",
      "Epoch: 19/20, Batch: 450/1586, Loss: 1.2018\n",
      "Epoch: 19/20, Batch: 500/1586, Loss: 1.0119\n",
      "Epoch: 19/20, Batch: 550/1586, Loss: 0.9032\n",
      "Epoch: 19/20, Batch: 600/1586, Loss: 0.9611\n",
      "Epoch: 19/20, Batch: 650/1586, Loss: 0.9749\n",
      "Epoch: 19/20, Batch: 700/1586, Loss: 0.8442\n",
      "Epoch: 19/20, Batch: 750/1586, Loss: 0.8679\n",
      "Epoch: 19/20, Batch: 800/1586, Loss: 1.0289\n",
      "Epoch: 19/20, Batch: 850/1586, Loss: 0.8287\n",
      "Epoch: 19/20, Batch: 900/1586, Loss: 1.0496\n",
      "Epoch: 19/20, Batch: 950/1586, Loss: 1.0652\n",
      "Epoch: 19/20, Batch: 1000/1586, Loss: 1.1602\n",
      "Epoch: 19/20, Batch: 1050/1586, Loss: 1.0939\n",
      "Epoch: 19/20, Batch: 1100/1586, Loss: 0.7720\n",
      "Epoch: 19/20, Batch: 1150/1586, Loss: 0.8073\n",
      "Epoch: 19/20, Batch: 1200/1586, Loss: 0.9044\n",
      "Epoch: 19/20, Batch: 1250/1586, Loss: 1.8124\n",
      "Epoch: 19/20, Batch: 1300/1586, Loss: 0.8833\n",
      "Epoch: 19/20, Batch: 1350/1586, Loss: 0.9365\n",
      "Epoch: 19/20, Batch: 1400/1586, Loss: 0.9710\n",
      "Epoch: 19/20, Batch: 1450/1586, Loss: 1.7656\n",
      "Epoch: 19/20, Batch: 1500/1586, Loss: 1.0583\n",
      "Epoch: 19/20, Batch: 1550/1586, Loss: 1.2488\n",
      "Epoch: 19, Train Loss: 1.0083\n",
      "Epoch: 20/20, Batch: 0/1586, Loss: 0.7782\n",
      "Epoch: 20/20, Batch: 50/1586, Loss: 1.0732\n",
      "Epoch: 20/20, Batch: 100/1586, Loss: 0.7734\n",
      "Epoch: 20/20, Batch: 150/1586, Loss: 1.0998\n",
      "Epoch: 20/20, Batch: 200/1586, Loss: 0.9353\n",
      "Epoch: 20/20, Batch: 250/1586, Loss: 0.7680\n",
      "Epoch: 20/20, Batch: 300/1586, Loss: 1.0586\n",
      "Epoch: 20/20, Batch: 350/1586, Loss: 1.1881\n",
      "Epoch: 20/20, Batch: 400/1586, Loss: 1.0477\n",
      "Epoch: 20/20, Batch: 450/1586, Loss: 1.0750\n",
      "Epoch: 20/20, Batch: 500/1586, Loss: 0.8643\n",
      "Epoch: 20/20, Batch: 550/1586, Loss: 0.8737\n",
      "Epoch: 20/20, Batch: 600/1586, Loss: 0.9404\n",
      "Epoch: 20/20, Batch: 650/1586, Loss: 1.2103\n",
      "Epoch: 20/20, Batch: 700/1586, Loss: 0.8609\n",
      "Epoch: 20/20, Batch: 750/1586, Loss: 0.9709\n",
      "Epoch: 20/20, Batch: 800/1586, Loss: 0.7294\n",
      "Epoch: 20/20, Batch: 850/1586, Loss: 0.7741\n",
      "Epoch: 20/20, Batch: 900/1586, Loss: 0.9279\n",
      "Epoch: 20/20, Batch: 950/1586, Loss: 0.8807\n",
      "Epoch: 20/20, Batch: 1000/1586, Loss: 1.2887\n",
      "Epoch: 20/20, Batch: 1050/1586, Loss: 1.0733\n",
      "Epoch: 20/20, Batch: 1100/1586, Loss: 0.8388\n",
      "Epoch: 20/20, Batch: 1150/1586, Loss: 0.8473\n",
      "Epoch: 20/20, Batch: 1200/1586, Loss: 1.0482\n",
      "Epoch: 20/20, Batch: 1250/1586, Loss: 1.0389\n",
      "Epoch: 20/20, Batch: 1300/1586, Loss: 0.8223\n",
      "Epoch: 20/20, Batch: 1350/1586, Loss: 0.9198\n",
      "Epoch: 20/20, Batch: 1400/1586, Loss: 0.8839\n",
      "Epoch: 20/20, Batch: 1450/1586, Loss: 0.8136\n",
      "Epoch: 20/20, Batch: 1500/1586, Loss: 0.8531\n",
      "Epoch: 20/20, Batch: 1550/1586, Loss: 1.0035\n",
      "Epoch: 20, Train Loss: 1.0070\n",
      "Training finished!\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "TOmfVoUDAihi",
    "outputId": "3e13a34d-eb99-43c4-95d8-542b738299dc",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:09:42.194915Z",
     "start_time": "2025-11-05T04:09:41.799923Z"
    }
   },
   "source": [
    "weighted_model.eval()\n",
    "y_true_weighted = []\n",
    "y_pred_weighted = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = weighted_model(data)\n",
    "\n",
    "        y_true_weighted.extend(target.cpu().numpy())\n",
    "        y_pred_weighted.extend((output > 0.5).cpu().numpy())\n",
    "\n",
    "y_true_weighted = np.array(y_true_weighted)\n",
    "y_pred_weighted = np.array(y_pred_weighted)\n",
    "\n",
    "print(\"\\nClassification Report (Weighted):\")\n",
    "print(classification_report(y_true_weighted, y_pred_weighted))\n",
    "print(\"\\nConfusion Matrix (Weighted):\")\n",
    "cm_weighted = confusion_matrix(y_true_weighted, y_pred_weighted)\n",
    "sns.heatmap(cm_weighted, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Weighted)')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Weighted):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.69      0.81     45957\n",
      "         1.0       0.22      0.83      0.34      4779\n",
      "\n",
      "    accuracy                           0.70     50736\n",
      "   macro avg       0.60      0.76      0.57     50736\n",
      "weighted avg       0.90      0.70      0.76     50736\n",
      "\n",
      "\n",
      "Confusion Matrix (Weighted):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCpmAEnvAihi"
   },
   "source": [
    "#### PCA(14)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oOYv_EBdAihi",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:09:42.492006Z",
     "start_time": "2025-11-05T04:09:42.223399Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "std = StandardScaler()\n",
    "X_train_scaled = std.fit_transform(X_train)\n",
    "X_test_scaled = std.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=14)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "train_dataset = HeartDiseaseDataset(X_train_pca, y_train)\n",
    "test_dataset = HeartDiseaseDataset(X_test_pca, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNxcA-lmAihj",
    "outputId": "5f06e5c5-d9f3-4990-9753-41157b2a43d2",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:11:26.537924Z",
     "start_time": "2025-11-05T04:09:42.509488Z"
    }
   },
   "source": [
    "input_features = X_train_pca.shape[1]\n",
    "\n",
    "weighted_model = HeartDiseaseMLPClassifier(input_size=input_features, class_frequencies=class_frequencies).to(device)\n",
    "\n",
    "optimizer = optim.Adam(weighted_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "num_epochs = 20\n",
    "weighted_train_losses = []\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    weighted_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = weighted_model(data)\n",
    "\n",
    "        target = target.float()\n",
    "        output = output.float()\n",
    "        loss = weighted_model.get_weighted_loss(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    weighted_train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "print('Training finished!')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch: 1/20, Batch: 0/1586, Loss: 1.4895\n",
      "Epoch: 1/20, Batch: 50/1586, Loss: 0.9427\n",
      "Epoch: 1/20, Batch: 100/1586, Loss: 1.0137\n",
      "Epoch: 1/20, Batch: 150/1586, Loss: 1.2412\n",
      "Epoch: 1/20, Batch: 200/1586, Loss: 1.0794\n",
      "Epoch: 1/20, Batch: 250/1586, Loss: 1.5260\n",
      "Epoch: 1/20, Batch: 300/1586, Loss: 1.1233\n",
      "Epoch: 1/20, Batch: 350/1586, Loss: 0.7436\n",
      "Epoch: 1/20, Batch: 400/1586, Loss: 0.9176\n",
      "Epoch: 1/20, Batch: 450/1586, Loss: 1.5213\n",
      "Epoch: 1/20, Batch: 500/1586, Loss: 1.0129\n",
      "Epoch: 1/20, Batch: 550/1586, Loss: 0.7920\n",
      "Epoch: 1/20, Batch: 600/1586, Loss: 0.8147\n",
      "Epoch: 1/20, Batch: 650/1586, Loss: 1.0291\n",
      "Epoch: 1/20, Batch: 700/1586, Loss: 1.0953\n",
      "Epoch: 1/20, Batch: 750/1586, Loss: 1.0817\n",
      "Epoch: 1/20, Batch: 800/1586, Loss: 1.0540\n",
      "Epoch: 1/20, Batch: 850/1586, Loss: 0.8838\n",
      "Epoch: 1/20, Batch: 900/1586, Loss: 1.0347\n",
      "Epoch: 1/20, Batch: 950/1586, Loss: 0.9174\n",
      "Epoch: 1/20, Batch: 1000/1586, Loss: 0.8584\n",
      "Epoch: 1/20, Batch: 1050/1586, Loss: 0.9732\n",
      "Epoch: 1/20, Batch: 1100/1586, Loss: 1.1449\n",
      "Epoch: 1/20, Batch: 1150/1586, Loss: 1.0615\n",
      "Epoch: 1/20, Batch: 1200/1586, Loss: 0.9992\n",
      "Epoch: 1/20, Batch: 1250/1586, Loss: 1.2323\n",
      "Epoch: 1/20, Batch: 1300/1586, Loss: 1.0981\n",
      "Epoch: 1/20, Batch: 1350/1586, Loss: 0.8973\n",
      "Epoch: 1/20, Batch: 1400/1586, Loss: 1.3692\n",
      "Epoch: 1/20, Batch: 1450/1586, Loss: 1.1093\n",
      "Epoch: 1/20, Batch: 1500/1586, Loss: 1.1661\n",
      "Epoch: 1/20, Batch: 1550/1586, Loss: 1.0423\n",
      "Epoch: 1, Train Loss: 1.0134\n",
      "Epoch: 2/20, Batch: 0/1586, Loss: 1.3312\n",
      "Epoch: 2/20, Batch: 50/1586, Loss: 1.0555\n",
      "Epoch: 2/20, Batch: 100/1586, Loss: 1.2338\n",
      "Epoch: 2/20, Batch: 150/1586, Loss: 1.0851\n",
      "Epoch: 2/20, Batch: 200/1586, Loss: 1.1914\n",
      "Epoch: 2/20, Batch: 250/1586, Loss: 0.6918\n",
      "Epoch: 2/20, Batch: 300/1586, Loss: 1.0193\n",
      "Epoch: 2/20, Batch: 350/1586, Loss: 0.7254\n",
      "Epoch: 2/20, Batch: 400/1586, Loss: 1.2967\n",
      "Epoch: 2/20, Batch: 450/1586, Loss: 1.0569\n",
      "Epoch: 2/20, Batch: 500/1586, Loss: 0.8983\n",
      "Epoch: 2/20, Batch: 550/1586, Loss: 0.7468\n",
      "Epoch: 2/20, Batch: 600/1586, Loss: 0.9865\n",
      "Epoch: 2/20, Batch: 650/1586, Loss: 1.1733\n",
      "Epoch: 2/20, Batch: 700/1586, Loss: 0.9522\n",
      "Epoch: 2/20, Batch: 750/1586, Loss: 0.9363\n",
      "Epoch: 2/20, Batch: 800/1586, Loss: 1.1072\n",
      "Epoch: 2/20, Batch: 850/1586, Loss: 1.2416\n",
      "Epoch: 2/20, Batch: 900/1586, Loss: 0.8775\n",
      "Epoch: 2/20, Batch: 950/1586, Loss: 1.0621\n",
      "Epoch: 2/20, Batch: 1000/1586, Loss: 0.9654\n",
      "Epoch: 2/20, Batch: 1050/1586, Loss: 0.8056\n",
      "Epoch: 2/20, Batch: 1100/1586, Loss: 0.8108\n",
      "Epoch: 2/20, Batch: 1150/1586, Loss: 1.4780\n",
      "Epoch: 2/20, Batch: 1200/1586, Loss: 0.8767\n",
      "Epoch: 2/20, Batch: 1250/1586, Loss: 0.9302\n",
      "Epoch: 2/20, Batch: 1300/1586, Loss: 0.7109\n",
      "Epoch: 2/20, Batch: 1350/1586, Loss: 1.0977\n",
      "Epoch: 2/20, Batch: 1400/1586, Loss: 1.4545\n",
      "Epoch: 2/20, Batch: 1450/1586, Loss: 0.9359\n",
      "Epoch: 2/20, Batch: 1500/1586, Loss: 1.0536\n",
      "Epoch: 2/20, Batch: 1550/1586, Loss: 1.1578\n",
      "Epoch: 2, Train Loss: 0.9935\n",
      "Epoch: 3/20, Batch: 0/1586, Loss: 0.7525\n",
      "Epoch: 3/20, Batch: 50/1586, Loss: 0.9736\n",
      "Epoch: 3/20, Batch: 100/1586, Loss: 1.4328\n",
      "Epoch: 3/20, Batch: 150/1586, Loss: 0.9766\n",
      "Epoch: 3/20, Batch: 200/1586, Loss: 0.9512\n",
      "Epoch: 3/20, Batch: 250/1586, Loss: 0.7885\n",
      "Epoch: 3/20, Batch: 300/1586, Loss: 1.0168\n",
      "Epoch: 3/20, Batch: 350/1586, Loss: 0.8500\n",
      "Epoch: 3/20, Batch: 400/1586, Loss: 1.1295\n",
      "Epoch: 3/20, Batch: 450/1586, Loss: 1.0306\n",
      "Epoch: 3/20, Batch: 500/1586, Loss: 0.8880\n",
      "Epoch: 3/20, Batch: 550/1586, Loss: 0.9839\n",
      "Epoch: 3/20, Batch: 600/1586, Loss: 0.9704\n",
      "Epoch: 3/20, Batch: 650/1586, Loss: 1.0033\n",
      "Epoch: 3/20, Batch: 700/1586, Loss: 1.3816\n",
      "Epoch: 3/20, Batch: 750/1586, Loss: 1.1260\n",
      "Epoch: 3/20, Batch: 800/1586, Loss: 1.0066\n",
      "Epoch: 3/20, Batch: 850/1586, Loss: 1.2971\n",
      "Epoch: 3/20, Batch: 900/1586, Loss: 0.9284\n",
      "Epoch: 3/20, Batch: 950/1586, Loss: 0.9533\n",
      "Epoch: 3/20, Batch: 1000/1586, Loss: 0.6429\n",
      "Epoch: 3/20, Batch: 1050/1586, Loss: 1.1550\n",
      "Epoch: 3/20, Batch: 1100/1586, Loss: 1.0982\n",
      "Epoch: 3/20, Batch: 1150/1586, Loss: 1.0928\n",
      "Epoch: 3/20, Batch: 1200/1586, Loss: 2.1300\n",
      "Epoch: 3/20, Batch: 1250/1586, Loss: 1.2696\n",
      "Epoch: 3/20, Batch: 1300/1586, Loss: 0.9353\n",
      "Epoch: 3/20, Batch: 1350/1586, Loss: 0.9078\n",
      "Epoch: 3/20, Batch: 1400/1586, Loss: 0.9781\n",
      "Epoch: 3/20, Batch: 1450/1586, Loss: 1.1344\n",
      "Epoch: 3/20, Batch: 1500/1586, Loss: 1.0392\n",
      "Epoch: 3/20, Batch: 1550/1586, Loss: 0.7848\n",
      "Epoch: 3, Train Loss: 0.9922\n",
      "Epoch: 4/20, Batch: 0/1586, Loss: 0.8890\n",
      "Epoch: 4/20, Batch: 50/1586, Loss: 0.9528\n",
      "Epoch: 4/20, Batch: 100/1586, Loss: 1.0389\n",
      "Epoch: 4/20, Batch: 150/1586, Loss: 0.7832\n",
      "Epoch: 4/20, Batch: 200/1586, Loss: 1.2802\n",
      "Epoch: 4/20, Batch: 250/1586, Loss: 0.9110\n",
      "Epoch: 4/20, Batch: 300/1586, Loss: 1.1281\n",
      "Epoch: 4/20, Batch: 350/1586, Loss: 0.8189\n",
      "Epoch: 4/20, Batch: 400/1586, Loss: 1.1448\n",
      "Epoch: 4/20, Batch: 450/1586, Loss: 0.9595\n",
      "Epoch: 4/20, Batch: 500/1586, Loss: 1.1464\n",
      "Epoch: 4/20, Batch: 550/1586, Loss: 1.0990\n",
      "Epoch: 4/20, Batch: 600/1586, Loss: 0.7694\n",
      "Epoch: 4/20, Batch: 650/1586, Loss: 0.9893\n",
      "Epoch: 4/20, Batch: 700/1586, Loss: 0.9542\n",
      "Epoch: 4/20, Batch: 750/1586, Loss: 0.9012\n",
      "Epoch: 4/20, Batch: 800/1586, Loss: 1.0746\n",
      "Epoch: 4/20, Batch: 850/1586, Loss: 1.4366\n",
      "Epoch: 4/20, Batch: 900/1586, Loss: 0.9398\n",
      "Epoch: 4/20, Batch: 950/1586, Loss: 0.8700\n",
      "Epoch: 4/20, Batch: 1000/1586, Loss: 1.1294\n",
      "Epoch: 4/20, Batch: 1050/1586, Loss: 0.7474\n",
      "Epoch: 4/20, Batch: 1100/1586, Loss: 1.0174\n",
      "Epoch: 4/20, Batch: 1150/1586, Loss: 0.9296\n",
      "Epoch: 4/20, Batch: 1200/1586, Loss: 0.7722\n",
      "Epoch: 4/20, Batch: 1250/1586, Loss: 0.9046\n",
      "Epoch: 4/20, Batch: 1300/1586, Loss: 1.0717\n",
      "Epoch: 4/20, Batch: 1350/1586, Loss: 0.9255\n",
      "Epoch: 4/20, Batch: 1400/1586, Loss: 1.2827\n",
      "Epoch: 4/20, Batch: 1450/1586, Loss: 0.8391\n",
      "Epoch: 4/20, Batch: 1500/1586, Loss: 0.8434\n",
      "Epoch: 4/20, Batch: 1550/1586, Loss: 1.0764\n",
      "Epoch: 4, Train Loss: 0.9896\n",
      "Epoch: 5/20, Batch: 0/1586, Loss: 0.8520\n",
      "Epoch: 5/20, Batch: 50/1586, Loss: 0.8060\n",
      "Epoch: 5/20, Batch: 100/1586, Loss: 1.5357\n",
      "Epoch: 5/20, Batch: 150/1586, Loss: 1.5207\n",
      "Epoch: 5/20, Batch: 200/1586, Loss: 0.8749\n",
      "Epoch: 5/20, Batch: 250/1586, Loss: 0.9001\n",
      "Epoch: 5/20, Batch: 300/1586, Loss: 0.7991\n",
      "Epoch: 5/20, Batch: 350/1586, Loss: 0.8745\n",
      "Epoch: 5/20, Batch: 400/1586, Loss: 0.8864\n",
      "Epoch: 5/20, Batch: 450/1586, Loss: 1.1203\n",
      "Epoch: 5/20, Batch: 500/1586, Loss: 1.6520\n",
      "Epoch: 5/20, Batch: 550/1586, Loss: 0.7617\n",
      "Epoch: 5/20, Batch: 600/1586, Loss: 1.0889\n",
      "Epoch: 5/20, Batch: 650/1586, Loss: 1.7074\n",
      "Epoch: 5/20, Batch: 700/1586, Loss: 0.9008\n",
      "Epoch: 5/20, Batch: 750/1586, Loss: 0.9954\n",
      "Epoch: 5/20, Batch: 800/1586, Loss: 0.9300\n",
      "Epoch: 5/20, Batch: 850/1586, Loss: 0.9048\n",
      "Epoch: 5/20, Batch: 900/1586, Loss: 0.9796\n",
      "Epoch: 5/20, Batch: 950/1586, Loss: 0.8087\n",
      "Epoch: 5/20, Batch: 1000/1586, Loss: 1.2468\n",
      "Epoch: 5/20, Batch: 1050/1586, Loss: 1.1843\n",
      "Epoch: 5/20, Batch: 1100/1586, Loss: 1.0032\n",
      "Epoch: 5/20, Batch: 1150/1586, Loss: 1.1489\n",
      "Epoch: 5/20, Batch: 1200/1586, Loss: 0.9529\n",
      "Epoch: 5/20, Batch: 1250/1586, Loss: 1.0985\n",
      "Epoch: 5/20, Batch: 1300/1586, Loss: 1.2695\n",
      "Epoch: 5/20, Batch: 1350/1586, Loss: 1.0167\n",
      "Epoch: 5/20, Batch: 1400/1586, Loss: 1.0561\n",
      "Epoch: 5/20, Batch: 1450/1586, Loss: 0.9579\n",
      "Epoch: 5/20, Batch: 1500/1586, Loss: 1.0154\n",
      "Epoch: 5/20, Batch: 1550/1586, Loss: 0.9510\n",
      "Epoch: 5, Train Loss: 0.9871\n",
      "Epoch: 6/20, Batch: 0/1586, Loss: 0.9822\n",
      "Epoch: 6/20, Batch: 50/1586, Loss: 1.4118\n",
      "Epoch: 6/20, Batch: 100/1586, Loss: 0.8396\n",
      "Epoch: 6/20, Batch: 150/1586, Loss: 0.9492\n",
      "Epoch: 6/20, Batch: 200/1586, Loss: 0.9629\n",
      "Epoch: 6/20, Batch: 250/1586, Loss: 1.0736\n",
      "Epoch: 6/20, Batch: 300/1586, Loss: 1.0589\n",
      "Epoch: 6/20, Batch: 350/1586, Loss: 0.7101\n",
      "Epoch: 6/20, Batch: 400/1586, Loss: 1.1132\n",
      "Epoch: 6/20, Batch: 450/1586, Loss: 0.7953\n",
      "Epoch: 6/20, Batch: 500/1586, Loss: 1.4317\n",
      "Epoch: 6/20, Batch: 550/1586, Loss: 1.1768\n",
      "Epoch: 6/20, Batch: 600/1586, Loss: 0.9314\n",
      "Epoch: 6/20, Batch: 650/1586, Loss: 1.0664\n",
      "Epoch: 6/20, Batch: 700/1586, Loss: 0.6485\n",
      "Epoch: 6/20, Batch: 750/1586, Loss: 1.1738\n",
      "Epoch: 6/20, Batch: 800/1586, Loss: 0.9224\n",
      "Epoch: 6/20, Batch: 850/1586, Loss: 1.2149\n",
      "Epoch: 6/20, Batch: 900/1586, Loss: 1.0133\n",
      "Epoch: 6/20, Batch: 950/1586, Loss: 0.6680\n",
      "Epoch: 6/20, Batch: 1000/1586, Loss: 0.9175\n",
      "Epoch: 6/20, Batch: 1050/1586, Loss: 0.8627\n",
      "Epoch: 6/20, Batch: 1100/1586, Loss: 1.2248\n",
      "Epoch: 6/20, Batch: 1150/1586, Loss: 1.0486\n",
      "Epoch: 6/20, Batch: 1200/1586, Loss: 1.0440\n",
      "Epoch: 6/20, Batch: 1250/1586, Loss: 0.8885\n",
      "Epoch: 6/20, Batch: 1300/1586, Loss: 1.0843\n",
      "Epoch: 6/20, Batch: 1350/1586, Loss: 0.9021\n",
      "Epoch: 6/20, Batch: 1400/1586, Loss: 0.9019\n",
      "Epoch: 6/20, Batch: 1450/1586, Loss: 1.0181\n",
      "Epoch: 6/20, Batch: 1500/1586, Loss: 0.7546\n",
      "Epoch: 6/20, Batch: 1550/1586, Loss: 1.2157\n",
      "Epoch: 6, Train Loss: 0.9873\n",
      "Epoch: 7/20, Batch: 0/1586, Loss: 1.1111\n",
      "Epoch: 7/20, Batch: 50/1586, Loss: 1.1005\n",
      "Epoch: 7/20, Batch: 100/1586, Loss: 0.9132\n",
      "Epoch: 7/20, Batch: 150/1586, Loss: 0.8063\n",
      "Epoch: 7/20, Batch: 200/1586, Loss: 0.7758\n",
      "Epoch: 7/20, Batch: 250/1586, Loss: 0.7911\n",
      "Epoch: 7/20, Batch: 300/1586, Loss: 0.9467\n",
      "Epoch: 7/20, Batch: 350/1586, Loss: 0.7080\n",
      "Epoch: 7/20, Batch: 400/1586, Loss: 0.9181\n",
      "Epoch: 7/20, Batch: 450/1586, Loss: 1.0569\n",
      "Epoch: 7/20, Batch: 500/1586, Loss: 0.9545\n",
      "Epoch: 7/20, Batch: 550/1586, Loss: 0.7643\n",
      "Epoch: 7/20, Batch: 600/1586, Loss: 1.0352\n",
      "Epoch: 7/20, Batch: 650/1586, Loss: 0.9084\n",
      "Epoch: 7/20, Batch: 700/1586, Loss: 0.7870\n",
      "Epoch: 7/20, Batch: 750/1586, Loss: 1.3056\n",
      "Epoch: 7/20, Batch: 800/1586, Loss: 1.2277\n",
      "Epoch: 7/20, Batch: 850/1586, Loss: 0.9131\n",
      "Epoch: 7/20, Batch: 900/1586, Loss: 0.8512\n",
      "Epoch: 7/20, Batch: 950/1586, Loss: 1.0696\n",
      "Epoch: 7/20, Batch: 1000/1586, Loss: 0.9107\n",
      "Epoch: 7/20, Batch: 1050/1586, Loss: 0.8748\n",
      "Epoch: 7/20, Batch: 1100/1586, Loss: 0.7307\n",
      "Epoch: 7/20, Batch: 1150/1586, Loss: 1.2041\n",
      "Epoch: 7/20, Batch: 1200/1586, Loss: 1.1563\n",
      "Epoch: 7/20, Batch: 1250/1586, Loss: 0.8305\n",
      "Epoch: 7/20, Batch: 1300/1586, Loss: 0.6280\n",
      "Epoch: 7/20, Batch: 1350/1586, Loss: 0.7979\n",
      "Epoch: 7/20, Batch: 1400/1586, Loss: 0.7775\n",
      "Epoch: 7/20, Batch: 1450/1586, Loss: 1.0298\n",
      "Epoch: 7/20, Batch: 1500/1586, Loss: 0.8970\n",
      "Epoch: 7/20, Batch: 1550/1586, Loss: 1.1940\n",
      "Epoch: 7, Train Loss: 0.9849\n",
      "Epoch: 8/20, Batch: 0/1586, Loss: 0.9088\n",
      "Epoch: 8/20, Batch: 50/1586, Loss: 1.0713\n",
      "Epoch: 8/20, Batch: 100/1586, Loss: 0.6453\n",
      "Epoch: 8/20, Batch: 150/1586, Loss: 0.9586\n",
      "Epoch: 8/20, Batch: 200/1586, Loss: 1.0086\n",
      "Epoch: 8/20, Batch: 250/1586, Loss: 0.9160\n",
      "Epoch: 8/20, Batch: 300/1586, Loss: 0.6809\n",
      "Epoch: 8/20, Batch: 350/1586, Loss: 0.6962\n",
      "Epoch: 8/20, Batch: 400/1586, Loss: 1.1241\n",
      "Epoch: 8/20, Batch: 450/1586, Loss: 0.7797\n",
      "Epoch: 8/20, Batch: 500/1586, Loss: 0.7210\n",
      "Epoch: 8/20, Batch: 550/1586, Loss: 0.8219\n",
      "Epoch: 8/20, Batch: 600/1586, Loss: 0.9184\n",
      "Epoch: 8/20, Batch: 650/1586, Loss: 0.8566\n",
      "Epoch: 8/20, Batch: 700/1586, Loss: 0.7238\n",
      "Epoch: 8/20, Batch: 750/1586, Loss: 0.6616\n",
      "Epoch: 8/20, Batch: 800/1586, Loss: 0.9123\n",
      "Epoch: 8/20, Batch: 850/1586, Loss: 0.8948\n",
      "Epoch: 8/20, Batch: 900/1586, Loss: 0.8620\n",
      "Epoch: 8/20, Batch: 950/1586, Loss: 0.9295\n",
      "Epoch: 8/20, Batch: 1000/1586, Loss: 0.9869\n",
      "Epoch: 8/20, Batch: 1050/1586, Loss: 0.8544\n",
      "Epoch: 8/20, Batch: 1100/1586, Loss: 0.8439\n",
      "Epoch: 8/20, Batch: 1150/1586, Loss: 0.8258\n",
      "Epoch: 8/20, Batch: 1200/1586, Loss: 1.2725\n",
      "Epoch: 8/20, Batch: 1250/1586, Loss: 1.1755\n",
      "Epoch: 8/20, Batch: 1300/1586, Loss: 0.7651\n",
      "Epoch: 8/20, Batch: 1350/1586, Loss: 1.0404\n",
      "Epoch: 8/20, Batch: 1400/1586, Loss: 0.7946\n",
      "Epoch: 8/20, Batch: 1450/1586, Loss: 0.9147\n",
      "Epoch: 8/20, Batch: 1500/1586, Loss: 0.7421\n",
      "Epoch: 8/20, Batch: 1550/1586, Loss: 0.9783\n",
      "Epoch: 8, Train Loss: 0.9844\n",
      "Epoch: 9/20, Batch: 0/1586, Loss: 1.2374\n",
      "Epoch: 9/20, Batch: 50/1586, Loss: 0.7467\n",
      "Epoch: 9/20, Batch: 100/1586, Loss: 0.9966\n",
      "Epoch: 9/20, Batch: 150/1586, Loss: 0.7855\n",
      "Epoch: 9/20, Batch: 200/1586, Loss: 0.7440\n",
      "Epoch: 9/20, Batch: 250/1586, Loss: 1.4000\n",
      "Epoch: 9/20, Batch: 300/1586, Loss: 1.3343\n",
      "Epoch: 9/20, Batch: 350/1586, Loss: 0.9276\n",
      "Epoch: 9/20, Batch: 400/1586, Loss: 1.1113\n",
      "Epoch: 9/20, Batch: 450/1586, Loss: 0.9646\n",
      "Epoch: 9/20, Batch: 500/1586, Loss: 0.7221\n",
      "Epoch: 9/20, Batch: 550/1586, Loss: 0.8663\n",
      "Epoch: 9/20, Batch: 600/1586, Loss: 0.9895\n",
      "Epoch: 9/20, Batch: 650/1586, Loss: 1.3334\n",
      "Epoch: 9/20, Batch: 700/1586, Loss: 0.8805\n",
      "Epoch: 9/20, Batch: 750/1586, Loss: 1.3834\n",
      "Epoch: 9/20, Batch: 800/1586, Loss: 0.7170\n",
      "Epoch: 9/20, Batch: 850/1586, Loss: 1.2492\n",
      "Epoch: 9/20, Batch: 900/1586, Loss: 0.9745\n",
      "Epoch: 9/20, Batch: 950/1586, Loss: 1.2489\n",
      "Epoch: 9/20, Batch: 1000/1586, Loss: 1.0806\n",
      "Epoch: 9/20, Batch: 1050/1586, Loss: 0.7980\n",
      "Epoch: 9/20, Batch: 1100/1586, Loss: 1.2589\n",
      "Epoch: 9/20, Batch: 1150/1586, Loss: 1.1465\n",
      "Epoch: 9/20, Batch: 1200/1586, Loss: 1.0380\n",
      "Epoch: 9/20, Batch: 1250/1586, Loss: 0.9760\n",
      "Epoch: 9/20, Batch: 1300/1586, Loss: 1.0849\n",
      "Epoch: 9/20, Batch: 1350/1586, Loss: 1.0828\n",
      "Epoch: 9/20, Batch: 1400/1586, Loss: 1.0084\n",
      "Epoch: 9/20, Batch: 1450/1586, Loss: 0.7920\n",
      "Epoch: 9/20, Batch: 1500/1586, Loss: 0.9042\n",
      "Epoch: 9/20, Batch: 1550/1586, Loss: 0.9636\n",
      "Epoch: 9, Train Loss: 0.9873\n",
      "Epoch: 10/20, Batch: 0/1586, Loss: 0.9953\n",
      "Epoch: 10/20, Batch: 50/1586, Loss: 0.8962\n",
      "Epoch: 10/20, Batch: 100/1586, Loss: 1.0570\n",
      "Epoch: 10/20, Batch: 150/1586, Loss: 0.9874\n",
      "Epoch: 10/20, Batch: 200/1586, Loss: 0.7443\n",
      "Epoch: 10/20, Batch: 250/1586, Loss: 0.8763\n",
      "Epoch: 10/20, Batch: 300/1586, Loss: 0.7748\n",
      "Epoch: 10/20, Batch: 350/1586, Loss: 1.1143\n",
      "Epoch: 10/20, Batch: 400/1586, Loss: 1.0286\n",
      "Epoch: 10/20, Batch: 450/1586, Loss: 0.8969\n",
      "Epoch: 10/20, Batch: 500/1586, Loss: 1.1229\n",
      "Epoch: 10/20, Batch: 550/1586, Loss: 1.2159\n",
      "Epoch: 10/20, Batch: 600/1586, Loss: 0.9461\n",
      "Epoch: 10/20, Batch: 650/1586, Loss: 0.9255\n",
      "Epoch: 10/20, Batch: 700/1586, Loss: 0.8081\n",
      "Epoch: 10/20, Batch: 750/1586, Loss: 1.2127\n",
      "Epoch: 10/20, Batch: 800/1586, Loss: 0.9598\n",
      "Epoch: 10/20, Batch: 850/1586, Loss: 0.7927\n",
      "Epoch: 10/20, Batch: 900/1586, Loss: 1.0889\n",
      "Epoch: 10/20, Batch: 950/1586, Loss: 0.8604\n",
      "Epoch: 10/20, Batch: 1000/1586, Loss: 0.7467\n",
      "Epoch: 10/20, Batch: 1050/1586, Loss: 0.6870\n",
      "Epoch: 10/20, Batch: 1100/1586, Loss: 0.7903\n",
      "Epoch: 10/20, Batch: 1150/1586, Loss: 0.7470\n",
      "Epoch: 10/20, Batch: 1200/1586, Loss: 0.9848\n",
      "Epoch: 10/20, Batch: 1250/1586, Loss: 0.7801\n",
      "Epoch: 10/20, Batch: 1300/1586, Loss: 0.8851\n",
      "Epoch: 10/20, Batch: 1350/1586, Loss: 1.0295\n",
      "Epoch: 10/20, Batch: 1400/1586, Loss: 0.9204\n",
      "Epoch: 10/20, Batch: 1450/1586, Loss: 0.9676\n",
      "Epoch: 10/20, Batch: 1500/1586, Loss: 0.9712\n",
      "Epoch: 10/20, Batch: 1550/1586, Loss: 1.0928\n",
      "Epoch: 10, Train Loss: 0.9848\n",
      "Epoch: 11/20, Batch: 0/1586, Loss: 1.0362\n",
      "Epoch: 11/20, Batch: 50/1586, Loss: 1.3850\n",
      "Epoch: 11/20, Batch: 100/1586, Loss: 1.0499\n",
      "Epoch: 11/20, Batch: 150/1586, Loss: 1.1917\n",
      "Epoch: 11/20, Batch: 200/1586, Loss: 0.8076\n",
      "Epoch: 11/20, Batch: 250/1586, Loss: 0.8029\n",
      "Epoch: 11/20, Batch: 300/1586, Loss: 0.9600\n",
      "Epoch: 11/20, Batch: 350/1586, Loss: 0.9590\n",
      "Epoch: 11/20, Batch: 400/1586, Loss: 0.8305\n",
      "Epoch: 11/20, Batch: 450/1586, Loss: 1.1164\n",
      "Epoch: 11/20, Batch: 500/1586, Loss: 0.8283\n",
      "Epoch: 11/20, Batch: 550/1586, Loss: 0.8235\n",
      "Epoch: 11/20, Batch: 600/1586, Loss: 1.0878\n",
      "Epoch: 11/20, Batch: 650/1586, Loss: 1.0214\n",
      "Epoch: 11/20, Batch: 700/1586, Loss: 1.0787\n",
      "Epoch: 11/20, Batch: 750/1586, Loss: 0.7383\n",
      "Epoch: 11/20, Batch: 800/1586, Loss: 1.4094\n",
      "Epoch: 11/20, Batch: 850/1586, Loss: 1.2067\n",
      "Epoch: 11/20, Batch: 900/1586, Loss: 1.4019\n",
      "Epoch: 11/20, Batch: 950/1586, Loss: 1.2807\n",
      "Epoch: 11/20, Batch: 1000/1586, Loss: 1.1824\n",
      "Epoch: 11/20, Batch: 1050/1586, Loss: 0.7743\n",
      "Epoch: 11/20, Batch: 1100/1586, Loss: 0.8865\n",
      "Epoch: 11/20, Batch: 1150/1586, Loss: 0.7906\n",
      "Epoch: 11/20, Batch: 1200/1586, Loss: 1.0085\n",
      "Epoch: 11/20, Batch: 1250/1586, Loss: 0.8155\n",
      "Epoch: 11/20, Batch: 1300/1586, Loss: 0.8598\n",
      "Epoch: 11/20, Batch: 1350/1586, Loss: 0.8024\n",
      "Epoch: 11/20, Batch: 1400/1586, Loss: 1.1636\n",
      "Epoch: 11/20, Batch: 1450/1586, Loss: 1.1861\n",
      "Epoch: 11/20, Batch: 1500/1586, Loss: 0.8438\n",
      "Epoch: 11/20, Batch: 1550/1586, Loss: 0.9479\n",
      "Epoch: 11, Train Loss: 0.9845\n",
      "Epoch: 12/20, Batch: 0/1586, Loss: 0.7371\n",
      "Epoch: 12/20, Batch: 50/1586, Loss: 0.9459\n",
      "Epoch: 12/20, Batch: 100/1586, Loss: 0.9284\n",
      "Epoch: 12/20, Batch: 150/1586, Loss: 0.9912\n",
      "Epoch: 12/20, Batch: 200/1586, Loss: 1.0128\n",
      "Epoch: 12/20, Batch: 250/1586, Loss: 0.9333\n",
      "Epoch: 12/20, Batch: 300/1586, Loss: 1.1030\n",
      "Epoch: 12/20, Batch: 350/1586, Loss: 0.7358\n",
      "Epoch: 12/20, Batch: 400/1586, Loss: 1.0082\n",
      "Epoch: 12/20, Batch: 450/1586, Loss: 1.1099\n",
      "Epoch: 12/20, Batch: 500/1586, Loss: 0.9555\n",
      "Epoch: 12/20, Batch: 550/1586, Loss: 0.9381\n",
      "Epoch: 12/20, Batch: 600/1586, Loss: 1.2588\n",
      "Epoch: 12/20, Batch: 650/1586, Loss: 1.6411\n",
      "Epoch: 12/20, Batch: 700/1586, Loss: 0.9139\n",
      "Epoch: 12/20, Batch: 750/1586, Loss: 1.1627\n",
      "Epoch: 12/20, Batch: 800/1586, Loss: 0.8035\n",
      "Epoch: 12/20, Batch: 850/1586, Loss: 0.8015\n",
      "Epoch: 12/20, Batch: 900/1586, Loss: 0.9144\n",
      "Epoch: 12/20, Batch: 950/1586, Loss: 0.8875\n",
      "Epoch: 12/20, Batch: 1000/1586, Loss: 1.2404\n",
      "Epoch: 12/20, Batch: 1050/1586, Loss: 0.9813\n",
      "Epoch: 12/20, Batch: 1100/1586, Loss: 1.2131\n",
      "Epoch: 12/20, Batch: 1150/1586, Loss: 0.6798\n",
      "Epoch: 12/20, Batch: 1200/1586, Loss: 0.8074\n",
      "Epoch: 12/20, Batch: 1250/1586, Loss: 1.0353\n",
      "Epoch: 12/20, Batch: 1300/1586, Loss: 0.8514\n",
      "Epoch: 12/20, Batch: 1350/1586, Loss: 1.4851\n",
      "Epoch: 12/20, Batch: 1400/1586, Loss: 1.5083\n",
      "Epoch: 12/20, Batch: 1450/1586, Loss: 1.2228\n",
      "Epoch: 12/20, Batch: 1500/1586, Loss: 0.8564\n",
      "Epoch: 12/20, Batch: 1550/1586, Loss: 0.9255\n",
      "Epoch: 12, Train Loss: 0.9837\n",
      "Epoch: 13/20, Batch: 0/1586, Loss: 1.0238\n",
      "Epoch: 13/20, Batch: 50/1586, Loss: 1.0701\n",
      "Epoch: 13/20, Batch: 100/1586, Loss: 1.0213\n",
      "Epoch: 13/20, Batch: 150/1586, Loss: 1.0189\n",
      "Epoch: 13/20, Batch: 200/1586, Loss: 0.8576\n",
      "Epoch: 13/20, Batch: 250/1586, Loss: 0.8387\n",
      "Epoch: 13/20, Batch: 300/1586, Loss: 1.0811\n",
      "Epoch: 13/20, Batch: 350/1586, Loss: 1.1460\n",
      "Epoch: 13/20, Batch: 400/1586, Loss: 0.8243\n",
      "Epoch: 13/20, Batch: 450/1586, Loss: 1.1484\n",
      "Epoch: 13/20, Batch: 500/1586, Loss: 0.9926\n",
      "Epoch: 13/20, Batch: 550/1586, Loss: 0.9041\n",
      "Epoch: 13/20, Batch: 600/1586, Loss: 0.8215\n",
      "Epoch: 13/20, Batch: 650/1586, Loss: 1.1624\n",
      "Epoch: 13/20, Batch: 700/1586, Loss: 0.8357\n",
      "Epoch: 13/20, Batch: 750/1586, Loss: 1.2960\n",
      "Epoch: 13/20, Batch: 800/1586, Loss: 0.8430\n",
      "Epoch: 13/20, Batch: 850/1586, Loss: 0.8192\n",
      "Epoch: 13/20, Batch: 900/1586, Loss: 0.9341\n",
      "Epoch: 13/20, Batch: 950/1586, Loss: 1.3011\n",
      "Epoch: 13/20, Batch: 1000/1586, Loss: 0.8888\n",
      "Epoch: 13/20, Batch: 1050/1586, Loss: 0.7939\n",
      "Epoch: 13/20, Batch: 1100/1586, Loss: 0.9083\n",
      "Epoch: 13/20, Batch: 1150/1586, Loss: 1.1809\n",
      "Epoch: 13/20, Batch: 1200/1586, Loss: 0.9014\n",
      "Epoch: 13/20, Batch: 1250/1586, Loss: 1.1871\n",
      "Epoch: 13/20, Batch: 1300/1586, Loss: 1.0764\n",
      "Epoch: 13/20, Batch: 1350/1586, Loss: 1.4243\n",
      "Epoch: 13/20, Batch: 1400/1586, Loss: 1.0710\n",
      "Epoch: 13/20, Batch: 1450/1586, Loss: 0.7433\n",
      "Epoch: 13/20, Batch: 1500/1586, Loss: 0.8420\n",
      "Epoch: 13/20, Batch: 1550/1586, Loss: 1.0662\n",
      "Epoch: 13, Train Loss: 0.9811\n",
      "Epoch: 14/20, Batch: 0/1586, Loss: 0.7982\n",
      "Epoch: 14/20, Batch: 50/1586, Loss: 0.7879\n",
      "Epoch: 14/20, Batch: 100/1586, Loss: 1.1244\n",
      "Epoch: 14/20, Batch: 150/1586, Loss: 0.7986\n",
      "Epoch: 14/20, Batch: 200/1586, Loss: 0.8985\n",
      "Epoch: 14/20, Batch: 250/1586, Loss: 0.9084\n",
      "Epoch: 14/20, Batch: 300/1586, Loss: 0.9096\n",
      "Epoch: 14/20, Batch: 350/1586, Loss: 1.1174\n",
      "Epoch: 14/20, Batch: 400/1586, Loss: 0.8868\n",
      "Epoch: 14/20, Batch: 450/1586, Loss: 1.2402\n",
      "Epoch: 14/20, Batch: 500/1586, Loss: 1.0534\n",
      "Epoch: 14/20, Batch: 550/1586, Loss: 1.0378\n",
      "Epoch: 14/20, Batch: 600/1586, Loss: 1.1346\n",
      "Epoch: 14/20, Batch: 650/1586, Loss: 0.8297\n",
      "Epoch: 14/20, Batch: 700/1586, Loss: 0.8396\n",
      "Epoch: 14/20, Batch: 750/1586, Loss: 1.1872\n",
      "Epoch: 14/20, Batch: 800/1586, Loss: 0.9220\n",
      "Epoch: 14/20, Batch: 850/1586, Loss: 1.0140\n",
      "Epoch: 14/20, Batch: 900/1586, Loss: 0.8227\n",
      "Epoch: 14/20, Batch: 950/1586, Loss: 0.7523\n",
      "Epoch: 14/20, Batch: 1000/1586, Loss: 0.9477\n",
      "Epoch: 14/20, Batch: 1050/1586, Loss: 0.8794\n",
      "Epoch: 14/20, Batch: 1100/1586, Loss: 0.8215\n",
      "Epoch: 14/20, Batch: 1150/1586, Loss: 0.8641\n",
      "Epoch: 14/20, Batch: 1200/1586, Loss: 1.0664\n",
      "Epoch: 14/20, Batch: 1250/1586, Loss: 0.9940\n",
      "Epoch: 14/20, Batch: 1300/1586, Loss: 0.8909\n",
      "Epoch: 14/20, Batch: 1350/1586, Loss: 0.9326\n",
      "Epoch: 14/20, Batch: 1400/1586, Loss: 0.7663\n",
      "Epoch: 14/20, Batch: 1450/1586, Loss: 0.6968\n",
      "Epoch: 14/20, Batch: 1500/1586, Loss: 1.1040\n",
      "Epoch: 14/20, Batch: 1550/1586, Loss: 0.7256\n",
      "Epoch: 14, Train Loss: 0.9804\n",
      "Epoch: 15/20, Batch: 0/1586, Loss: 1.0101\n",
      "Epoch: 15/20, Batch: 50/1586, Loss: 0.8406\n",
      "Epoch: 15/20, Batch: 100/1586, Loss: 1.0240\n",
      "Epoch: 15/20, Batch: 150/1586, Loss: 0.8949\n",
      "Epoch: 15/20, Batch: 200/1586, Loss: 1.5350\n",
      "Epoch: 15/20, Batch: 250/1586, Loss: 0.7605\n",
      "Epoch: 15/20, Batch: 300/1586, Loss: 1.2108\n",
      "Epoch: 15/20, Batch: 350/1586, Loss: 0.9692\n",
      "Epoch: 15/20, Batch: 400/1586, Loss: 0.9651\n",
      "Epoch: 15/20, Batch: 450/1586, Loss: 0.7240\n",
      "Epoch: 15/20, Batch: 500/1586, Loss: 1.4106\n",
      "Epoch: 15/20, Batch: 550/1586, Loss: 0.8210\n",
      "Epoch: 15/20, Batch: 600/1586, Loss: 0.9777\n",
      "Epoch: 15/20, Batch: 650/1586, Loss: 1.0582\n",
      "Epoch: 15/20, Batch: 700/1586, Loss: 0.7933\n",
      "Epoch: 15/20, Batch: 750/1586, Loss: 1.3288\n",
      "Epoch: 15/20, Batch: 800/1586, Loss: 1.1657\n",
      "Epoch: 15/20, Batch: 850/1586, Loss: 0.8471\n",
      "Epoch: 15/20, Batch: 900/1586, Loss: 0.7348\n",
      "Epoch: 15/20, Batch: 950/1586, Loss: 0.7899\n",
      "Epoch: 15/20, Batch: 1000/1586, Loss: 1.4712\n",
      "Epoch: 15/20, Batch: 1050/1586, Loss: 1.0918\n",
      "Epoch: 15/20, Batch: 1100/1586, Loss: 0.8777\n",
      "Epoch: 15/20, Batch: 1150/1586, Loss: 1.4811\n",
      "Epoch: 15/20, Batch: 1200/1586, Loss: 1.2555\n",
      "Epoch: 15/20, Batch: 1250/1586, Loss: 0.9695\n",
      "Epoch: 15/20, Batch: 1300/1586, Loss: 1.1082\n",
      "Epoch: 15/20, Batch: 1350/1586, Loss: 0.6687\n",
      "Epoch: 15/20, Batch: 1400/1586, Loss: 0.8834\n",
      "Epoch: 15/20, Batch: 1450/1586, Loss: 0.8085\n",
      "Epoch: 15/20, Batch: 1500/1586, Loss: 1.4508\n",
      "Epoch: 15/20, Batch: 1550/1586, Loss: 1.1955\n",
      "Epoch: 15, Train Loss: 0.9828\n",
      "Epoch: 16/20, Batch: 0/1586, Loss: 0.7628\n",
      "Epoch: 16/20, Batch: 50/1586, Loss: 1.3656\n",
      "Epoch: 16/20, Batch: 100/1586, Loss: 1.1070\n",
      "Epoch: 16/20, Batch: 150/1586, Loss: 1.0500\n",
      "Epoch: 16/20, Batch: 200/1586, Loss: 1.4334\n",
      "Epoch: 16/20, Batch: 250/1586, Loss: 1.0915\n",
      "Epoch: 16/20, Batch: 300/1586, Loss: 1.3091\n",
      "Epoch: 16/20, Batch: 350/1586, Loss: 1.3000\n",
      "Epoch: 16/20, Batch: 400/1586, Loss: 0.6476\n",
      "Epoch: 16/20, Batch: 450/1586, Loss: 0.8699\n",
      "Epoch: 16/20, Batch: 500/1586, Loss: 0.9809\n",
      "Epoch: 16/20, Batch: 550/1586, Loss: 1.4658\n",
      "Epoch: 16/20, Batch: 600/1586, Loss: 1.0069\n",
      "Epoch: 16/20, Batch: 650/1586, Loss: 1.1462\n",
      "Epoch: 16/20, Batch: 700/1586, Loss: 1.0589\n",
      "Epoch: 16/20, Batch: 750/1586, Loss: 0.7735\n",
      "Epoch: 16/20, Batch: 800/1586, Loss: 0.9827\n",
      "Epoch: 16/20, Batch: 850/1586, Loss: 0.8795\n",
      "Epoch: 16/20, Batch: 900/1586, Loss: 1.0524\n",
      "Epoch: 16/20, Batch: 950/1586, Loss: 0.9793\n",
      "Epoch: 16/20, Batch: 1000/1586, Loss: 1.3444\n",
      "Epoch: 16/20, Batch: 1050/1586, Loss: 0.9384\n",
      "Epoch: 16/20, Batch: 1100/1586, Loss: 0.9315\n",
      "Epoch: 16/20, Batch: 1150/1586, Loss: 0.9721\n",
      "Epoch: 16/20, Batch: 1200/1586, Loss: 1.2444\n",
      "Epoch: 16/20, Batch: 1250/1586, Loss: 0.9087\n",
      "Epoch: 16/20, Batch: 1300/1586, Loss: 1.0713\n",
      "Epoch: 16/20, Batch: 1350/1586, Loss: 0.7516\n",
      "Epoch: 16/20, Batch: 1400/1586, Loss: 0.9869\n",
      "Epoch: 16/20, Batch: 1450/1586, Loss: 0.8792\n",
      "Epoch: 16/20, Batch: 1500/1586, Loss: 0.8562\n",
      "Epoch: 16/20, Batch: 1550/1586, Loss: 1.4862\n",
      "Epoch: 16, Train Loss: 0.9798\n",
      "Epoch: 17/20, Batch: 0/1586, Loss: 0.8559\n",
      "Epoch: 17/20, Batch: 50/1586, Loss: 0.9956\n",
      "Epoch: 17/20, Batch: 100/1586, Loss: 1.1033\n",
      "Epoch: 17/20, Batch: 150/1586, Loss: 0.8520\n",
      "Epoch: 17/20, Batch: 200/1586, Loss: 0.8382\n",
      "Epoch: 17/20, Batch: 250/1586, Loss: 0.9711\n",
      "Epoch: 17/20, Batch: 300/1586, Loss: 0.8350\n",
      "Epoch: 17/20, Batch: 350/1586, Loss: 0.9817\n",
      "Epoch: 17/20, Batch: 400/1586, Loss: 0.8351\n",
      "Epoch: 17/20, Batch: 450/1586, Loss: 0.8768\n",
      "Epoch: 17/20, Batch: 500/1586, Loss: 0.9401\n",
      "Epoch: 17/20, Batch: 550/1586, Loss: 0.8184\n",
      "Epoch: 17/20, Batch: 600/1586, Loss: 0.7630\n",
      "Epoch: 17/20, Batch: 650/1586, Loss: 1.0603\n",
      "Epoch: 17/20, Batch: 700/1586, Loss: 0.9944\n",
      "Epoch: 17/20, Batch: 750/1586, Loss: 0.8567\n",
      "Epoch: 17/20, Batch: 800/1586, Loss: 0.8514\n",
      "Epoch: 17/20, Batch: 850/1586, Loss: 0.6774\n",
      "Epoch: 17/20, Batch: 900/1586, Loss: 1.3659\n",
      "Epoch: 17/20, Batch: 950/1586, Loss: 0.9518\n",
      "Epoch: 17/20, Batch: 1000/1586, Loss: 0.9864\n",
      "Epoch: 17/20, Batch: 1050/1586, Loss: 0.9750\n",
      "Epoch: 17/20, Batch: 1100/1586, Loss: 1.0617\n",
      "Epoch: 17/20, Batch: 1150/1586, Loss: 0.9544\n",
      "Epoch: 17/20, Batch: 1200/1586, Loss: 1.3625\n",
      "Epoch: 17/20, Batch: 1250/1586, Loss: 1.0379\n",
      "Epoch: 17/20, Batch: 1300/1586, Loss: 1.2864\n",
      "Epoch: 17/20, Batch: 1350/1586, Loss: 0.8552\n",
      "Epoch: 17/20, Batch: 1400/1586, Loss: 1.0817\n",
      "Epoch: 17/20, Batch: 1450/1586, Loss: 1.4041\n",
      "Epoch: 17/20, Batch: 1500/1586, Loss: 0.8546\n",
      "Epoch: 17/20, Batch: 1550/1586, Loss: 1.1049\n",
      "Epoch: 17, Train Loss: 0.9805\n",
      "Epoch: 18/20, Batch: 0/1586, Loss: 0.8044\n",
      "Epoch: 18/20, Batch: 50/1586, Loss: 0.7198\n",
      "Epoch: 18/20, Batch: 100/1586, Loss: 1.0982\n",
      "Epoch: 18/20, Batch: 150/1586, Loss: 0.7187\n",
      "Epoch: 18/20, Batch: 200/1586, Loss: 0.9746\n",
      "Epoch: 18/20, Batch: 250/1586, Loss: 1.7169\n",
      "Epoch: 18/20, Batch: 300/1586, Loss: 0.7675\n",
      "Epoch: 18/20, Batch: 350/1586, Loss: 0.7608\n",
      "Epoch: 18/20, Batch: 400/1586, Loss: 0.9384\n",
      "Epoch: 18/20, Batch: 450/1586, Loss: 1.2408\n",
      "Epoch: 18/20, Batch: 500/1586, Loss: 0.7411\n",
      "Epoch: 18/20, Batch: 550/1586, Loss: 0.9483\n",
      "Epoch: 18/20, Batch: 600/1586, Loss: 1.1286\n",
      "Epoch: 18/20, Batch: 650/1586, Loss: 0.9336\n",
      "Epoch: 18/20, Batch: 700/1586, Loss: 1.1076\n",
      "Epoch: 18/20, Batch: 750/1586, Loss: 1.2463\n",
      "Epoch: 18/20, Batch: 800/1586, Loss: 0.7998\n",
      "Epoch: 18/20, Batch: 850/1586, Loss: 0.8838\n",
      "Epoch: 18/20, Batch: 900/1586, Loss: 0.9111\n",
      "Epoch: 18/20, Batch: 950/1586, Loss: 1.0648\n",
      "Epoch: 18/20, Batch: 1000/1586, Loss: 1.1723\n",
      "Epoch: 18/20, Batch: 1050/1586, Loss: 1.2103\n",
      "Epoch: 18/20, Batch: 1100/1586, Loss: 0.8449\n",
      "Epoch: 18/20, Batch: 1150/1586, Loss: 0.8519\n",
      "Epoch: 18/20, Batch: 1200/1586, Loss: 1.1679\n",
      "Epoch: 18/20, Batch: 1250/1586, Loss: 1.2488\n",
      "Epoch: 18/20, Batch: 1300/1586, Loss: 0.7752\n",
      "Epoch: 18/20, Batch: 1350/1586, Loss: 0.9613\n",
      "Epoch: 18/20, Batch: 1400/1586, Loss: 0.9135\n",
      "Epoch: 18/20, Batch: 1450/1586, Loss: 0.8817\n",
      "Epoch: 18/20, Batch: 1500/1586, Loss: 0.7120\n",
      "Epoch: 18/20, Batch: 1550/1586, Loss: 0.8025\n",
      "Epoch: 18, Train Loss: 0.9806\n",
      "Epoch: 19/20, Batch: 0/1586, Loss: 0.7466\n",
      "Epoch: 19/20, Batch: 50/1586, Loss: 1.0469\n",
      "Epoch: 19/20, Batch: 100/1586, Loss: 1.1687\n",
      "Epoch: 19/20, Batch: 150/1586, Loss: 0.9840\n",
      "Epoch: 19/20, Batch: 200/1586, Loss: 0.8956\n",
      "Epoch: 19/20, Batch: 250/1586, Loss: 1.0321\n",
      "Epoch: 19/20, Batch: 300/1586, Loss: 1.0317\n",
      "Epoch: 19/20, Batch: 350/1586, Loss: 1.3003\n",
      "Epoch: 19/20, Batch: 400/1586, Loss: 1.0000\n",
      "Epoch: 19/20, Batch: 450/1586, Loss: 1.0104\n",
      "Epoch: 19/20, Batch: 500/1586, Loss: 0.8584\n",
      "Epoch: 19/20, Batch: 550/1586, Loss: 1.0605\n",
      "Epoch: 19/20, Batch: 600/1586, Loss: 1.3026\n",
      "Epoch: 19/20, Batch: 650/1586, Loss: 1.0192\n",
      "Epoch: 19/20, Batch: 700/1586, Loss: 0.6941\n",
      "Epoch: 19/20, Batch: 750/1586, Loss: 1.1079\n",
      "Epoch: 19/20, Batch: 800/1586, Loss: 0.8457\n",
      "Epoch: 19/20, Batch: 850/1586, Loss: 0.8183\n",
      "Epoch: 19/20, Batch: 900/1586, Loss: 0.9720\n",
      "Epoch: 19/20, Batch: 950/1586, Loss: 0.9777\n",
      "Epoch: 19/20, Batch: 1000/1586, Loss: 1.0780\n",
      "Epoch: 19/20, Batch: 1050/1586, Loss: 0.7535\n",
      "Epoch: 19/20, Batch: 1100/1586, Loss: 1.0234\n",
      "Epoch: 19/20, Batch: 1150/1586, Loss: 0.9002\n",
      "Epoch: 19/20, Batch: 1200/1586, Loss: 0.9921\n",
      "Epoch: 19/20, Batch: 1250/1586, Loss: 0.9329\n",
      "Epoch: 19/20, Batch: 1300/1586, Loss: 1.1790\n",
      "Epoch: 19/20, Batch: 1350/1586, Loss: 1.0224\n",
      "Epoch: 19/20, Batch: 1400/1586, Loss: 0.9096\n",
      "Epoch: 19/20, Batch: 1450/1586, Loss: 0.8891\n",
      "Epoch: 19/20, Batch: 1500/1586, Loss: 0.7394\n",
      "Epoch: 19/20, Batch: 1550/1586, Loss: 1.2718\n",
      "Epoch: 19, Train Loss: 0.9786\n",
      "Epoch: 20/20, Batch: 0/1586, Loss: 0.7769\n",
      "Epoch: 20/20, Batch: 50/1586, Loss: 1.2265\n",
      "Epoch: 20/20, Batch: 100/1586, Loss: 0.7543\n",
      "Epoch: 20/20, Batch: 150/1586, Loss: 0.7506\n",
      "Epoch: 20/20, Batch: 200/1586, Loss: 0.7309\n",
      "Epoch: 20/20, Batch: 250/1586, Loss: 0.9848\n",
      "Epoch: 20/20, Batch: 300/1586, Loss: 0.7641\n",
      "Epoch: 20/20, Batch: 350/1586, Loss: 1.2296\n",
      "Epoch: 20/20, Batch: 400/1586, Loss: 1.4840\n",
      "Epoch: 20/20, Batch: 450/1586, Loss: 0.7681\n",
      "Epoch: 20/20, Batch: 500/1586, Loss: 1.3208\n",
      "Epoch: 20/20, Batch: 550/1586, Loss: 0.7151\n",
      "Epoch: 20/20, Batch: 600/1586, Loss: 1.0963\n",
      "Epoch: 20/20, Batch: 650/1586, Loss: 0.9884\n",
      "Epoch: 20/20, Batch: 700/1586, Loss: 0.8363\n",
      "Epoch: 20/20, Batch: 750/1586, Loss: 0.8162\n",
      "Epoch: 20/20, Batch: 800/1586, Loss: 1.1787\n",
      "Epoch: 20/20, Batch: 850/1586, Loss: 0.6757\n",
      "Epoch: 20/20, Batch: 900/1586, Loss: 1.3930\n",
      "Epoch: 20/20, Batch: 950/1586, Loss: 1.1785\n",
      "Epoch: 20/20, Batch: 1000/1586, Loss: 1.1213\n",
      "Epoch: 20/20, Batch: 1050/1586, Loss: 0.8411\n",
      "Epoch: 20/20, Batch: 1100/1586, Loss: 0.7479\n",
      "Epoch: 20/20, Batch: 1150/1586, Loss: 1.2167\n",
      "Epoch: 20/20, Batch: 1200/1586, Loss: 0.9297\n",
      "Epoch: 20/20, Batch: 1250/1586, Loss: 0.6263\n",
      "Epoch: 20/20, Batch: 1300/1586, Loss: 1.1117\n",
      "Epoch: 20/20, Batch: 1350/1586, Loss: 1.1758\n",
      "Epoch: 20/20, Batch: 1400/1586, Loss: 0.8723\n",
      "Epoch: 20/20, Batch: 1450/1586, Loss: 0.9463\n",
      "Epoch: 20/20, Batch: 1500/1586, Loss: 0.9215\n",
      "Epoch: 20/20, Batch: 1550/1586, Loss: 0.9748\n",
      "Epoch: 20, Train Loss: 0.9797\n",
      "Training finished!\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "Nbkhga6yAihj",
    "outputId": "d343153e-0e36-4038-a79a-0dd1f68a3e95",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:11:27.126622Z",
     "start_time": "2025-11-05T04:11:26.619006Z"
    }
   },
   "source": [
    "weighted_model.eval()\n",
    "y_true_weighted = []\n",
    "y_pred_weighted = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = weighted_model(data)\n",
    "\n",
    "        y_true_weighted.extend(target.cpu().numpy())\n",
    "        y_pred_weighted.extend((output > 0.5).cpu().numpy())\n",
    "\n",
    "y_true_weighted = np.array(y_true_weighted)\n",
    "y_pred_weighted = np.array(y_pred_weighted)\n",
    "\n",
    "print(\"\\nClassification Report (Weighted):\")\n",
    "print(classification_report(y_true_weighted, y_pred_weighted))\n",
    "print(\"\\nConfusion Matrix (Weighted):\")\n",
    "cm_weighted = confusion_matrix(y_true_weighted, y_pred_weighted)\n",
    "sns.heatmap(cm_weighted, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Weighted)')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Weighted):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.71      0.82     45957\n",
      "         1.0       0.23      0.82      0.36      4779\n",
      "\n",
      "    accuracy                           0.72     50736\n",
      "   macro avg       0.60      0.77      0.59     50736\n",
      "weighted avg       0.90      0.72      0.78     50736\n",
      "\n",
      "\n",
      "Confusion Matrix (Weighted):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAy8poAUAihj"
   },
   "source": [
    "### train:test = 7:3"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLOBAiXIAihj",
    "outputId": "ffe2f383-20bf-4602-ef51-29c395bab812",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:12:59.823065Z",
     "start_time": "2025-11-05T04:11:27.161095Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "std = StandardScaler()\n",
    "X_train_scaled = std.fit_transform(X_train)\n",
    "X_test_scaled = std.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=14)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "train_dataset = HeartDiseaseDataset(X_train_pca, y_train)\n",
    "test_dataset = HeartDiseaseDataset(X_test_pca, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "input_features = X_train_pca.shape[1]\n",
    "\n",
    "weighted_model = HeartDiseaseMLPClassifier(input_size=input_features, class_frequencies=class_frequencies).to(device)\n",
    "\n",
    "optimizer = optim.Adam(weighted_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "num_epochs = 20\n",
    "weighted_train_losses = []\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    weighted_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = weighted_model(data)\n",
    "\n",
    "        target = target.float()\n",
    "        output = output.float()\n",
    "        loss = weighted_model.get_weighted_loss(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    weighted_train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "print('Training finished!')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch: 1/20, Batch: 0/1388, Loss: 1.3998\n",
      "Epoch: 1/20, Batch: 50/1388, Loss: 1.2430\n",
      "Epoch: 1/20, Batch: 100/1388, Loss: 0.8134\n",
      "Epoch: 1/20, Batch: 150/1388, Loss: 1.3514\n",
      "Epoch: 1/20, Batch: 200/1388, Loss: 0.8667\n",
      "Epoch: 1/20, Batch: 250/1388, Loss: 1.2523\n",
      "Epoch: 1/20, Batch: 300/1388, Loss: 0.9416\n",
      "Epoch: 1/20, Batch: 350/1388, Loss: 0.9671\n",
      "Epoch: 1/20, Batch: 400/1388, Loss: 1.1623\n",
      "Epoch: 1/20, Batch: 450/1388, Loss: 0.8751\n",
      "Epoch: 1/20, Batch: 500/1388, Loss: 1.2501\n",
      "Epoch: 1/20, Batch: 550/1388, Loss: 0.8684\n",
      "Epoch: 1/20, Batch: 600/1388, Loss: 0.8705\n",
      "Epoch: 1/20, Batch: 650/1388, Loss: 1.1019\n",
      "Epoch: 1/20, Batch: 700/1388, Loss: 1.0823\n",
      "Epoch: 1/20, Batch: 750/1388, Loss: 0.9366\n",
      "Epoch: 1/20, Batch: 800/1388, Loss: 1.1636\n",
      "Epoch: 1/20, Batch: 850/1388, Loss: 0.7221\n",
      "Epoch: 1/20, Batch: 900/1388, Loss: 1.0927\n",
      "Epoch: 1/20, Batch: 950/1388, Loss: 0.8526\n",
      "Epoch: 1/20, Batch: 1000/1388, Loss: 1.3168\n",
      "Epoch: 1/20, Batch: 1050/1388, Loss: 1.0884\n",
      "Epoch: 1/20, Batch: 1100/1388, Loss: 1.0231\n",
      "Epoch: 1/20, Batch: 1150/1388, Loss: 1.1129\n",
      "Epoch: 1/20, Batch: 1200/1388, Loss: 0.7253\n",
      "Epoch: 1/20, Batch: 1250/1388, Loss: 0.7385\n",
      "Epoch: 1/20, Batch: 1300/1388, Loss: 1.3650\n",
      "Epoch: 1/20, Batch: 1350/1388, Loss: 1.0376\n",
      "Epoch: 1, Train Loss: 1.0151\n",
      "Epoch: 2/20, Batch: 0/1388, Loss: 0.8871\n",
      "Epoch: 2/20, Batch: 50/1388, Loss: 0.8264\n",
      "Epoch: 2/20, Batch: 100/1388, Loss: 0.9363\n",
      "Epoch: 2/20, Batch: 150/1388, Loss: 1.2276\n",
      "Epoch: 2/20, Batch: 200/1388, Loss: 1.1477\n",
      "Epoch: 2/20, Batch: 250/1388, Loss: 1.1055\n",
      "Epoch: 2/20, Batch: 300/1388, Loss: 1.0145\n",
      "Epoch: 2/20, Batch: 350/1388, Loss: 0.9907\n",
      "Epoch: 2/20, Batch: 400/1388, Loss: 0.9454\n",
      "Epoch: 2/20, Batch: 450/1388, Loss: 0.8959\n",
      "Epoch: 2/20, Batch: 500/1388, Loss: 0.8935\n",
      "Epoch: 2/20, Batch: 550/1388, Loss: 1.0891\n",
      "Epoch: 2/20, Batch: 600/1388, Loss: 1.2559\n",
      "Epoch: 2/20, Batch: 650/1388, Loss: 1.1811\n",
      "Epoch: 2/20, Batch: 700/1388, Loss: 0.8814\n",
      "Epoch: 2/20, Batch: 750/1388, Loss: 0.9725\n",
      "Epoch: 2/20, Batch: 800/1388, Loss: 0.9979\n",
      "Epoch: 2/20, Batch: 850/1388, Loss: 0.9979\n",
      "Epoch: 2/20, Batch: 900/1388, Loss: 0.7253\n",
      "Epoch: 2/20, Batch: 950/1388, Loss: 1.0461\n",
      "Epoch: 2/20, Batch: 1000/1388, Loss: 1.2257\n",
      "Epoch: 2/20, Batch: 1050/1388, Loss: 0.9215\n",
      "Epoch: 2/20, Batch: 1100/1388, Loss: 0.8919\n",
      "Epoch: 2/20, Batch: 1150/1388, Loss: 0.9891\n",
      "Epoch: 2/20, Batch: 1200/1388, Loss: 1.0607\n",
      "Epoch: 2/20, Batch: 1250/1388, Loss: 1.0329\n",
      "Epoch: 2/20, Batch: 1300/1388, Loss: 1.1053\n",
      "Epoch: 2/20, Batch: 1350/1388, Loss: 1.3293\n",
      "Epoch: 2, Train Loss: 0.9954\n",
      "Epoch: 3/20, Batch: 0/1388, Loss: 1.1980\n",
      "Epoch: 3/20, Batch: 50/1388, Loss: 0.7594\n",
      "Epoch: 3/20, Batch: 100/1388, Loss: 1.0315\n",
      "Epoch: 3/20, Batch: 150/1388, Loss: 0.9548\n",
      "Epoch: 3/20, Batch: 200/1388, Loss: 0.8090\n",
      "Epoch: 3/20, Batch: 250/1388, Loss: 0.9133\n",
      "Epoch: 3/20, Batch: 300/1388, Loss: 0.8145\n",
      "Epoch: 3/20, Batch: 350/1388, Loss: 0.8961\n",
      "Epoch: 3/20, Batch: 400/1388, Loss: 0.9802\n",
      "Epoch: 3/20, Batch: 450/1388, Loss: 0.9108\n",
      "Epoch: 3/20, Batch: 500/1388, Loss: 0.8405\n",
      "Epoch: 3/20, Batch: 550/1388, Loss: 1.1138\n",
      "Epoch: 3/20, Batch: 600/1388, Loss: 1.3772\n",
      "Epoch: 3/20, Batch: 650/1388, Loss: 0.7118\n",
      "Epoch: 3/20, Batch: 700/1388, Loss: 0.9512\n",
      "Epoch: 3/20, Batch: 750/1388, Loss: 0.9807\n",
      "Epoch: 3/20, Batch: 800/1388, Loss: 0.9956\n",
      "Epoch: 3/20, Batch: 850/1388, Loss: 1.1323\n",
      "Epoch: 3/20, Batch: 900/1388, Loss: 1.2585\n",
      "Epoch: 3/20, Batch: 950/1388, Loss: 0.7822\n",
      "Epoch: 3/20, Batch: 1000/1388, Loss: 1.2468\n",
      "Epoch: 3/20, Batch: 1050/1388, Loss: 1.0637\n",
      "Epoch: 3/20, Batch: 1100/1388, Loss: 0.8064\n",
      "Epoch: 3/20, Batch: 1150/1388, Loss: 0.8916\n",
      "Epoch: 3/20, Batch: 1200/1388, Loss: 0.8326\n",
      "Epoch: 3/20, Batch: 1250/1388, Loss: 0.8366\n",
      "Epoch: 3/20, Batch: 1300/1388, Loss: 0.8621\n",
      "Epoch: 3/20, Batch: 1350/1388, Loss: 1.1020\n",
      "Epoch: 3, Train Loss: 0.9929\n",
      "Epoch: 4/20, Batch: 0/1388, Loss: 0.8945\n",
      "Epoch: 4/20, Batch: 50/1388, Loss: 0.9764\n",
      "Epoch: 4/20, Batch: 100/1388, Loss: 0.8805\n",
      "Epoch: 4/20, Batch: 150/1388, Loss: 1.0676\n",
      "Epoch: 4/20, Batch: 200/1388, Loss: 1.2675\n",
      "Epoch: 4/20, Batch: 250/1388, Loss: 1.0698\n",
      "Epoch: 4/20, Batch: 300/1388, Loss: 1.6140\n",
      "Epoch: 4/20, Batch: 350/1388, Loss: 0.8570\n",
      "Epoch: 4/20, Batch: 400/1388, Loss: 0.8191\n",
      "Epoch: 4/20, Batch: 450/1388, Loss: 0.6600\n",
      "Epoch: 4/20, Batch: 500/1388, Loss: 1.0705\n",
      "Epoch: 4/20, Batch: 550/1388, Loss: 1.3395\n",
      "Epoch: 4/20, Batch: 600/1388, Loss: 0.8754\n",
      "Epoch: 4/20, Batch: 650/1388, Loss: 0.9296\n",
      "Epoch: 4/20, Batch: 700/1388, Loss: 0.7985\n",
      "Epoch: 4/20, Batch: 750/1388, Loss: 1.0089\n",
      "Epoch: 4/20, Batch: 800/1388, Loss: 1.1809\n",
      "Epoch: 4/20, Batch: 850/1388, Loss: 0.8849\n",
      "Epoch: 4/20, Batch: 900/1388, Loss: 1.0570\n",
      "Epoch: 4/20, Batch: 950/1388, Loss: 1.0941\n",
      "Epoch: 4/20, Batch: 1000/1388, Loss: 1.1137\n",
      "Epoch: 4/20, Batch: 1050/1388, Loss: 1.1367\n",
      "Epoch: 4/20, Batch: 1100/1388, Loss: 0.9104\n",
      "Epoch: 4/20, Batch: 1150/1388, Loss: 0.7445\n",
      "Epoch: 4/20, Batch: 1200/1388, Loss: 1.0623\n",
      "Epoch: 4/20, Batch: 1250/1388, Loss: 0.8137\n",
      "Epoch: 4/20, Batch: 1300/1388, Loss: 0.9646\n",
      "Epoch: 4/20, Batch: 1350/1388, Loss: 0.9483\n",
      "Epoch: 4, Train Loss: 0.9910\n",
      "Epoch: 5/20, Batch: 0/1388, Loss: 0.9701\n",
      "Epoch: 5/20, Batch: 50/1388, Loss: 1.0215\n",
      "Epoch: 5/20, Batch: 100/1388, Loss: 1.1710\n",
      "Epoch: 5/20, Batch: 150/1388, Loss: 1.0444\n",
      "Epoch: 5/20, Batch: 200/1388, Loss: 0.6975\n",
      "Epoch: 5/20, Batch: 250/1388, Loss: 1.2204\n",
      "Epoch: 5/20, Batch: 300/1388, Loss: 0.9241\n",
      "Epoch: 5/20, Batch: 350/1388, Loss: 0.9554\n",
      "Epoch: 5/20, Batch: 400/1388, Loss: 0.8685\n",
      "Epoch: 5/20, Batch: 450/1388, Loss: 0.9797\n",
      "Epoch: 5/20, Batch: 500/1388, Loss: 1.1778\n",
      "Epoch: 5/20, Batch: 550/1388, Loss: 0.8017\n",
      "Epoch: 5/20, Batch: 600/1388, Loss: 0.7141\n",
      "Epoch: 5/20, Batch: 650/1388, Loss: 1.5688\n",
      "Epoch: 5/20, Batch: 700/1388, Loss: 0.8757\n",
      "Epoch: 5/20, Batch: 750/1388, Loss: 1.2045\n",
      "Epoch: 5/20, Batch: 800/1388, Loss: 0.8625\n",
      "Epoch: 5/20, Batch: 850/1388, Loss: 1.3530\n",
      "Epoch: 5/20, Batch: 900/1388, Loss: 1.1183\n",
      "Epoch: 5/20, Batch: 950/1388, Loss: 1.2146\n",
      "Epoch: 5/20, Batch: 1000/1388, Loss: 0.8338\n",
      "Epoch: 5/20, Batch: 1050/1388, Loss: 0.9283\n",
      "Epoch: 5/20, Batch: 1100/1388, Loss: 1.2629\n",
      "Epoch: 5/20, Batch: 1150/1388, Loss: 1.0511\n",
      "Epoch: 5/20, Batch: 1200/1388, Loss: 0.9765\n",
      "Epoch: 5/20, Batch: 1250/1388, Loss: 0.8974\n",
      "Epoch: 5/20, Batch: 1300/1388, Loss: 0.9851\n",
      "Epoch: 5/20, Batch: 1350/1388, Loss: 0.8335\n",
      "Epoch: 5, Train Loss: 0.9888\n",
      "Epoch: 6/20, Batch: 0/1388, Loss: 0.8677\n",
      "Epoch: 6/20, Batch: 50/1388, Loss: 1.0232\n",
      "Epoch: 6/20, Batch: 100/1388, Loss: 1.0046\n",
      "Epoch: 6/20, Batch: 150/1388, Loss: 1.0912\n",
      "Epoch: 6/20, Batch: 200/1388, Loss: 0.7245\n",
      "Epoch: 6/20, Batch: 250/1388, Loss: 1.1023\n",
      "Epoch: 6/20, Batch: 300/1388, Loss: 1.1592\n",
      "Epoch: 6/20, Batch: 350/1388, Loss: 0.8863\n",
      "Epoch: 6/20, Batch: 400/1388, Loss: 0.7783\n",
      "Epoch: 6/20, Batch: 450/1388, Loss: 1.1123\n",
      "Epoch: 6/20, Batch: 500/1388, Loss: 0.9662\n",
      "Epoch: 6/20, Batch: 550/1388, Loss: 1.1806\n",
      "Epoch: 6/20, Batch: 600/1388, Loss: 1.0505\n",
      "Epoch: 6/20, Batch: 650/1388, Loss: 1.3194\n",
      "Epoch: 6/20, Batch: 700/1388, Loss: 0.6782\n",
      "Epoch: 6/20, Batch: 750/1388, Loss: 1.1854\n",
      "Epoch: 6/20, Batch: 800/1388, Loss: 1.1750\n",
      "Epoch: 6/20, Batch: 850/1388, Loss: 1.5727\n",
      "Epoch: 6/20, Batch: 900/1388, Loss: 0.9803\n",
      "Epoch: 6/20, Batch: 950/1388, Loss: 1.1110\n",
      "Epoch: 6/20, Batch: 1000/1388, Loss: 1.1524\n",
      "Epoch: 6/20, Batch: 1050/1388, Loss: 0.7951\n",
      "Epoch: 6/20, Batch: 1100/1388, Loss: 1.2279\n",
      "Epoch: 6/20, Batch: 1150/1388, Loss: 0.8712\n",
      "Epoch: 6/20, Batch: 1200/1388, Loss: 1.0777\n",
      "Epoch: 6/20, Batch: 1250/1388, Loss: 1.2780\n",
      "Epoch: 6/20, Batch: 1300/1388, Loss: 0.9189\n",
      "Epoch: 6/20, Batch: 1350/1388, Loss: 0.7170\n",
      "Epoch: 6, Train Loss: 0.9886\n",
      "Epoch: 7/20, Batch: 0/1388, Loss: 0.9101\n",
      "Epoch: 7/20, Batch: 50/1388, Loss: 1.1110\n",
      "Epoch: 7/20, Batch: 100/1388, Loss: 1.0536\n",
      "Epoch: 7/20, Batch: 150/1388, Loss: 0.9856\n",
      "Epoch: 7/20, Batch: 200/1388, Loss: 1.0781\n",
      "Epoch: 7/20, Batch: 250/1388, Loss: 1.1407\n",
      "Epoch: 7/20, Batch: 300/1388, Loss: 0.9235\n",
      "Epoch: 7/20, Batch: 350/1388, Loss: 1.0387\n",
      "Epoch: 7/20, Batch: 400/1388, Loss: 1.2843\n",
      "Epoch: 7/20, Batch: 450/1388, Loss: 1.3844\n",
      "Epoch: 7/20, Batch: 500/1388, Loss: 0.7477\n",
      "Epoch: 7/20, Batch: 550/1388, Loss: 0.7412\n",
      "Epoch: 7/20, Batch: 600/1388, Loss: 1.1144\n",
      "Epoch: 7/20, Batch: 650/1388, Loss: 0.7384\n",
      "Epoch: 7/20, Batch: 700/1388, Loss: 1.1122\n",
      "Epoch: 7/20, Batch: 750/1388, Loss: 1.0002\n",
      "Epoch: 7/20, Batch: 800/1388, Loss: 1.1479\n",
      "Epoch: 7/20, Batch: 850/1388, Loss: 0.8632\n",
      "Epoch: 7/20, Batch: 900/1388, Loss: 0.9329\n",
      "Epoch: 7/20, Batch: 950/1388, Loss: 1.0649\n",
      "Epoch: 7/20, Batch: 1000/1388, Loss: 1.2016\n",
      "Epoch: 7/20, Batch: 1050/1388, Loss: 1.2902\n",
      "Epoch: 7/20, Batch: 1100/1388, Loss: 1.0281\n",
      "Epoch: 7/20, Batch: 1150/1388, Loss: 0.8010\n",
      "Epoch: 7/20, Batch: 1200/1388, Loss: 1.1132\n",
      "Epoch: 7/20, Batch: 1250/1388, Loss: 0.8975\n",
      "Epoch: 7/20, Batch: 1300/1388, Loss: 0.9098\n",
      "Epoch: 7/20, Batch: 1350/1388, Loss: 0.7393\n",
      "Epoch: 7, Train Loss: 0.9878\n",
      "Epoch: 8/20, Batch: 0/1388, Loss: 1.1804\n",
      "Epoch: 8/20, Batch: 50/1388, Loss: 0.8267\n",
      "Epoch: 8/20, Batch: 100/1388, Loss: 1.1093\n",
      "Epoch: 8/20, Batch: 150/1388, Loss: 0.8064\n",
      "Epoch: 8/20, Batch: 200/1388, Loss: 1.1296\n",
      "Epoch: 8/20, Batch: 250/1388, Loss: 0.8923\n",
      "Epoch: 8/20, Batch: 300/1388, Loss: 1.1434\n",
      "Epoch: 8/20, Batch: 350/1388, Loss: 0.9088\n",
      "Epoch: 8/20, Batch: 400/1388, Loss: 1.3487\n",
      "Epoch: 8/20, Batch: 450/1388, Loss: 1.0406\n",
      "Epoch: 8/20, Batch: 500/1388, Loss: 0.8129\n",
      "Epoch: 8/20, Batch: 550/1388, Loss: 1.3354\n",
      "Epoch: 8/20, Batch: 600/1388, Loss: 1.2137\n",
      "Epoch: 8/20, Batch: 650/1388, Loss: 1.2492\n",
      "Epoch: 8/20, Batch: 700/1388, Loss: 0.7198\n",
      "Epoch: 8/20, Batch: 750/1388, Loss: 1.3206\n",
      "Epoch: 8/20, Batch: 800/1388, Loss: 1.0734\n",
      "Epoch: 8/20, Batch: 850/1388, Loss: 0.8403\n",
      "Epoch: 8/20, Batch: 900/1388, Loss: 0.8045\n",
      "Epoch: 8/20, Batch: 950/1388, Loss: 1.0228\n",
      "Epoch: 8/20, Batch: 1000/1388, Loss: 1.1211\n",
      "Epoch: 8/20, Batch: 1050/1388, Loss: 1.2905\n",
      "Epoch: 8/20, Batch: 1100/1388, Loss: 1.1879\n",
      "Epoch: 8/20, Batch: 1150/1388, Loss: 1.2521\n",
      "Epoch: 8/20, Batch: 1200/1388, Loss: 0.8941\n",
      "Epoch: 8/20, Batch: 1250/1388, Loss: 0.8421\n",
      "Epoch: 8/20, Batch: 1300/1388, Loss: 1.0136\n",
      "Epoch: 8/20, Batch: 1350/1388, Loss: 0.8403\n",
      "Epoch: 8, Train Loss: 0.9860\n",
      "Epoch: 9/20, Batch: 0/1388, Loss: 0.9476\n",
      "Epoch: 9/20, Batch: 50/1388, Loss: 1.0997\n",
      "Epoch: 9/20, Batch: 100/1388, Loss: 0.8112\n",
      "Epoch: 9/20, Batch: 150/1388, Loss: 1.0803\n",
      "Epoch: 9/20, Batch: 200/1388, Loss: 0.8939\n",
      "Epoch: 9/20, Batch: 250/1388, Loss: 0.9288\n",
      "Epoch: 9/20, Batch: 300/1388, Loss: 0.8619\n",
      "Epoch: 9/20, Batch: 350/1388, Loss: 0.8468\n",
      "Epoch: 9/20, Batch: 400/1388, Loss: 0.6695\n",
      "Epoch: 9/20, Batch: 450/1388, Loss: 1.0734\n",
      "Epoch: 9/20, Batch: 500/1388, Loss: 0.7372\n",
      "Epoch: 9/20, Batch: 550/1388, Loss: 1.1165\n",
      "Epoch: 9/20, Batch: 600/1388, Loss: 1.1687\n",
      "Epoch: 9/20, Batch: 650/1388, Loss: 0.8281\n",
      "Epoch: 9/20, Batch: 700/1388, Loss: 0.7954\n",
      "Epoch: 9/20, Batch: 750/1388, Loss: 1.0418\n",
      "Epoch: 9/20, Batch: 800/1388, Loss: 1.6066\n",
      "Epoch: 9/20, Batch: 850/1388, Loss: 1.3206\n",
      "Epoch: 9/20, Batch: 900/1388, Loss: 0.8759\n",
      "Epoch: 9/20, Batch: 950/1388, Loss: 0.9212\n",
      "Epoch: 9/20, Batch: 1000/1388, Loss: 0.9691\n",
      "Epoch: 9/20, Batch: 1050/1388, Loss: 0.9527\n",
      "Epoch: 9/20, Batch: 1100/1388, Loss: 1.0795\n",
      "Epoch: 9/20, Batch: 1150/1388, Loss: 0.8919\n",
      "Epoch: 9/20, Batch: 1200/1388, Loss: 0.9187\n",
      "Epoch: 9/20, Batch: 1250/1388, Loss: 1.1792\n",
      "Epoch: 9/20, Batch: 1300/1388, Loss: 1.1539\n",
      "Epoch: 9/20, Batch: 1350/1388, Loss: 1.0062\n",
      "Epoch: 9, Train Loss: 0.9839\n",
      "Epoch: 10/20, Batch: 0/1388, Loss: 0.8448\n",
      "Epoch: 10/20, Batch: 50/1388, Loss: 0.9907\n",
      "Epoch: 10/20, Batch: 100/1388, Loss: 0.8938\n",
      "Epoch: 10/20, Batch: 150/1388, Loss: 0.6476\n",
      "Epoch: 10/20, Batch: 200/1388, Loss: 0.7173\n",
      "Epoch: 10/20, Batch: 250/1388, Loss: 0.7693\n",
      "Epoch: 10/20, Batch: 300/1388, Loss: 0.9781\n",
      "Epoch: 10/20, Batch: 350/1388, Loss: 0.8936\n",
      "Epoch: 10/20, Batch: 400/1388, Loss: 0.7741\n",
      "Epoch: 10/20, Batch: 450/1388, Loss: 1.1220\n",
      "Epoch: 10/20, Batch: 500/1388, Loss: 0.9406\n",
      "Epoch: 10/20, Batch: 550/1388, Loss: 1.1440\n",
      "Epoch: 10/20, Batch: 600/1388, Loss: 0.9654\n",
      "Epoch: 10/20, Batch: 650/1388, Loss: 1.2597\n",
      "Epoch: 10/20, Batch: 700/1388, Loss: 0.7192\n",
      "Epoch: 10/20, Batch: 750/1388, Loss: 0.8456\n",
      "Epoch: 10/20, Batch: 800/1388, Loss: 0.8284\n",
      "Epoch: 10/20, Batch: 850/1388, Loss: 0.9010\n",
      "Epoch: 10/20, Batch: 900/1388, Loss: 1.1718\n",
      "Epoch: 10/20, Batch: 950/1388, Loss: 1.1302\n",
      "Epoch: 10/20, Batch: 1000/1388, Loss: 0.6801\n",
      "Epoch: 10/20, Batch: 1050/1388, Loss: 0.8651\n",
      "Epoch: 10/20, Batch: 1100/1388, Loss: 1.2401\n",
      "Epoch: 10/20, Batch: 1150/1388, Loss: 1.0626\n",
      "Epoch: 10/20, Batch: 1200/1388, Loss: 0.9957\n",
      "Epoch: 10/20, Batch: 1250/1388, Loss: 0.8897\n",
      "Epoch: 10/20, Batch: 1300/1388, Loss: 1.0605\n",
      "Epoch: 10/20, Batch: 1350/1388, Loss: 0.8308\n",
      "Epoch: 10, Train Loss: 0.9842\n",
      "Epoch: 11/20, Batch: 0/1388, Loss: 0.8489\n",
      "Epoch: 11/20, Batch: 50/1388, Loss: 0.9595\n",
      "Epoch: 11/20, Batch: 100/1388, Loss: 1.2434\n",
      "Epoch: 11/20, Batch: 150/1388, Loss: 0.8298\n",
      "Epoch: 11/20, Batch: 200/1388, Loss: 0.8011\n",
      "Epoch: 11/20, Batch: 250/1388, Loss: 1.4381\n",
      "Epoch: 11/20, Batch: 300/1388, Loss: 1.1088\n",
      "Epoch: 11/20, Batch: 350/1388, Loss: 0.9622\n",
      "Epoch: 11/20, Batch: 400/1388, Loss: 1.2007\n",
      "Epoch: 11/20, Batch: 450/1388, Loss: 0.8771\n",
      "Epoch: 11/20, Batch: 500/1388, Loss: 1.2807\n",
      "Epoch: 11/20, Batch: 550/1388, Loss: 0.9505\n",
      "Epoch: 11/20, Batch: 600/1388, Loss: 1.1052\n",
      "Epoch: 11/20, Batch: 650/1388, Loss: 0.6919\n",
      "Epoch: 11/20, Batch: 700/1388, Loss: 1.1530\n",
      "Epoch: 11/20, Batch: 750/1388, Loss: 0.7894\n",
      "Epoch: 11/20, Batch: 800/1388, Loss: 0.9473\n",
      "Epoch: 11/20, Batch: 850/1388, Loss: 1.1478\n",
      "Epoch: 11/20, Batch: 900/1388, Loss: 0.9205\n",
      "Epoch: 11/20, Batch: 950/1388, Loss: 1.0670\n",
      "Epoch: 11/20, Batch: 1000/1388, Loss: 1.3642\n",
      "Epoch: 11/20, Batch: 1050/1388, Loss: 0.9678\n",
      "Epoch: 11/20, Batch: 1100/1388, Loss: 0.9508\n",
      "Epoch: 11/20, Batch: 1150/1388, Loss: 0.8358\n",
      "Epoch: 11/20, Batch: 1200/1388, Loss: 1.2239\n",
      "Epoch: 11/20, Batch: 1250/1388, Loss: 0.7569\n",
      "Epoch: 11/20, Batch: 1300/1388, Loss: 1.1611\n",
      "Epoch: 11/20, Batch: 1350/1388, Loss: 1.4056\n",
      "Epoch: 11, Train Loss: 0.9837\n",
      "Epoch: 12/20, Batch: 0/1388, Loss: 1.0106\n",
      "Epoch: 12/20, Batch: 50/1388, Loss: 0.8608\n",
      "Epoch: 12/20, Batch: 100/1388, Loss: 0.8623\n",
      "Epoch: 12/20, Batch: 150/1388, Loss: 1.4123\n",
      "Epoch: 12/20, Batch: 200/1388, Loss: 0.9432\n",
      "Epoch: 12/20, Batch: 250/1388, Loss: 0.7033\n",
      "Epoch: 12/20, Batch: 300/1388, Loss: 0.7130\n",
      "Epoch: 12/20, Batch: 350/1388, Loss: 0.9165\n",
      "Epoch: 12/20, Batch: 400/1388, Loss: 0.8901\n",
      "Epoch: 12/20, Batch: 450/1388, Loss: 1.2065\n",
      "Epoch: 12/20, Batch: 500/1388, Loss: 0.9677\n",
      "Epoch: 12/20, Batch: 550/1388, Loss: 1.1350\n",
      "Epoch: 12/20, Batch: 600/1388, Loss: 0.8332\n",
      "Epoch: 12/20, Batch: 650/1388, Loss: 0.8647\n",
      "Epoch: 12/20, Batch: 700/1388, Loss: 0.7780\n",
      "Epoch: 12/20, Batch: 750/1388, Loss: 1.4891\n",
      "Epoch: 12/20, Batch: 800/1388, Loss: 0.6856\n",
      "Epoch: 12/20, Batch: 850/1388, Loss: 0.9780\n",
      "Epoch: 12/20, Batch: 900/1388, Loss: 0.8924\n",
      "Epoch: 12/20, Batch: 950/1388, Loss: 1.0747\n",
      "Epoch: 12/20, Batch: 1000/1388, Loss: 0.9583\n",
      "Epoch: 12/20, Batch: 1050/1388, Loss: 0.9760\n",
      "Epoch: 12/20, Batch: 1100/1388, Loss: 1.7276\n",
      "Epoch: 12/20, Batch: 1150/1388, Loss: 1.4809\n",
      "Epoch: 12/20, Batch: 1200/1388, Loss: 0.8058\n",
      "Epoch: 12/20, Batch: 1250/1388, Loss: 1.3086\n",
      "Epoch: 12/20, Batch: 1300/1388, Loss: 0.9710\n",
      "Epoch: 12/20, Batch: 1350/1388, Loss: 0.8669\n",
      "Epoch: 12, Train Loss: 0.9833\n",
      "Epoch: 13/20, Batch: 0/1388, Loss: 0.9560\n",
      "Epoch: 13/20, Batch: 50/1388, Loss: 0.8827\n",
      "Epoch: 13/20, Batch: 100/1388, Loss: 0.8478\n",
      "Epoch: 13/20, Batch: 150/1388, Loss: 0.9351\n",
      "Epoch: 13/20, Batch: 200/1388, Loss: 1.0993\n",
      "Epoch: 13/20, Batch: 250/1388, Loss: 0.8609\n",
      "Epoch: 13/20, Batch: 300/1388, Loss: 0.8322\n",
      "Epoch: 13/20, Batch: 350/1388, Loss: 1.3690\n",
      "Epoch: 13/20, Batch: 400/1388, Loss: 1.1526\n",
      "Epoch: 13/20, Batch: 450/1388, Loss: 0.8691\n",
      "Epoch: 13/20, Batch: 500/1388, Loss: 1.0463\n",
      "Epoch: 13/20, Batch: 550/1388, Loss: 0.7933\n",
      "Epoch: 13/20, Batch: 600/1388, Loss: 1.1830\n",
      "Epoch: 13/20, Batch: 650/1388, Loss: 0.7292\n",
      "Epoch: 13/20, Batch: 700/1388, Loss: 0.6361\n",
      "Epoch: 13/20, Batch: 750/1388, Loss: 0.9898\n",
      "Epoch: 13/20, Batch: 800/1388, Loss: 0.7925\n",
      "Epoch: 13/20, Batch: 850/1388, Loss: 1.1066\n",
      "Epoch: 13/20, Batch: 900/1388, Loss: 0.8619\n",
      "Epoch: 13/20, Batch: 950/1388, Loss: 0.9299\n",
      "Epoch: 13/20, Batch: 1000/1388, Loss: 0.7533\n",
      "Epoch: 13/20, Batch: 1050/1388, Loss: 0.6990\n",
      "Epoch: 13/20, Batch: 1100/1388, Loss: 0.7301\n",
      "Epoch: 13/20, Batch: 1150/1388, Loss: 0.6745\n",
      "Epoch: 13/20, Batch: 1200/1388, Loss: 0.9373\n",
      "Epoch: 13/20, Batch: 1250/1388, Loss: 1.2423\n",
      "Epoch: 13/20, Batch: 1300/1388, Loss: 0.8234\n",
      "Epoch: 13/20, Batch: 1350/1388, Loss: 1.0144\n",
      "Epoch: 13, Train Loss: 0.9819\n",
      "Epoch: 14/20, Batch: 0/1388, Loss: 0.8243\n",
      "Epoch: 14/20, Batch: 50/1388, Loss: 0.9052\n",
      "Epoch: 14/20, Batch: 100/1388, Loss: 1.3166\n",
      "Epoch: 14/20, Batch: 150/1388, Loss: 0.7635\n",
      "Epoch: 14/20, Batch: 200/1388, Loss: 1.0715\n",
      "Epoch: 14/20, Batch: 250/1388, Loss: 1.0863\n",
      "Epoch: 14/20, Batch: 300/1388, Loss: 0.9599\n",
      "Epoch: 14/20, Batch: 350/1388, Loss: 0.9734\n",
      "Epoch: 14/20, Batch: 400/1388, Loss: 0.9651\n",
      "Epoch: 14/20, Batch: 450/1388, Loss: 1.0175\n",
      "Epoch: 14/20, Batch: 500/1388, Loss: 1.0262\n",
      "Epoch: 14/20, Batch: 550/1388, Loss: 0.7354\n",
      "Epoch: 14/20, Batch: 600/1388, Loss: 0.8178\n",
      "Epoch: 14/20, Batch: 650/1388, Loss: 1.0856\n",
      "Epoch: 14/20, Batch: 700/1388, Loss: 1.0434\n",
      "Epoch: 14/20, Batch: 750/1388, Loss: 0.7204\n",
      "Epoch: 14/20, Batch: 800/1388, Loss: 1.2387\n",
      "Epoch: 14/20, Batch: 850/1388, Loss: 1.1226\n",
      "Epoch: 14/20, Batch: 900/1388, Loss: 0.9394\n",
      "Epoch: 14/20, Batch: 950/1388, Loss: 0.9924\n",
      "Epoch: 14/20, Batch: 1000/1388, Loss: 1.2542\n",
      "Epoch: 14/20, Batch: 1050/1388, Loss: 1.6568\n",
      "Epoch: 14/20, Batch: 1100/1388, Loss: 1.4763\n",
      "Epoch: 14/20, Batch: 1150/1388, Loss: 0.7742\n",
      "Epoch: 14/20, Batch: 1200/1388, Loss: 0.8406\n",
      "Epoch: 14/20, Batch: 1250/1388, Loss: 0.9618\n",
      "Epoch: 14/20, Batch: 1300/1388, Loss: 1.2836\n",
      "Epoch: 14/20, Batch: 1350/1388, Loss: 0.7269\n",
      "Epoch: 14, Train Loss: 0.9817\n",
      "Epoch: 15/20, Batch: 0/1388, Loss: 0.9795\n",
      "Epoch: 15/20, Batch: 50/1388, Loss: 0.9059\n",
      "Epoch: 15/20, Batch: 100/1388, Loss: 0.8801\n",
      "Epoch: 15/20, Batch: 150/1388, Loss: 1.0380\n",
      "Epoch: 15/20, Batch: 200/1388, Loss: 1.1303\n",
      "Epoch: 15/20, Batch: 250/1388, Loss: 1.1021\n",
      "Epoch: 15/20, Batch: 300/1388, Loss: 1.2302\n",
      "Epoch: 15/20, Batch: 350/1388, Loss: 0.9256\n",
      "Epoch: 15/20, Batch: 400/1388, Loss: 0.8827\n",
      "Epoch: 15/20, Batch: 450/1388, Loss: 1.0465\n",
      "Epoch: 15/20, Batch: 500/1388, Loss: 0.9567\n",
      "Epoch: 15/20, Batch: 550/1388, Loss: 1.0499\n",
      "Epoch: 15/20, Batch: 600/1388, Loss: 0.7711\n",
      "Epoch: 15/20, Batch: 650/1388, Loss: 0.8955\n",
      "Epoch: 15/20, Batch: 700/1388, Loss: 0.8940\n",
      "Epoch: 15/20, Batch: 750/1388, Loss: 0.9883\n",
      "Epoch: 15/20, Batch: 800/1388, Loss: 1.3503\n",
      "Epoch: 15/20, Batch: 850/1388, Loss: 1.1825\n",
      "Epoch: 15/20, Batch: 900/1388, Loss: 0.8362\n",
      "Epoch: 15/20, Batch: 950/1388, Loss: 0.8782\n",
      "Epoch: 15/20, Batch: 1000/1388, Loss: 0.9397\n",
      "Epoch: 15/20, Batch: 1050/1388, Loss: 1.0363\n",
      "Epoch: 15/20, Batch: 1100/1388, Loss: 1.3318\n",
      "Epoch: 15/20, Batch: 1150/1388, Loss: 0.8382\n",
      "Epoch: 15/20, Batch: 1200/1388, Loss: 0.9517\n",
      "Epoch: 15/20, Batch: 1250/1388, Loss: 1.2404\n",
      "Epoch: 15/20, Batch: 1300/1388, Loss: 1.1486\n",
      "Epoch: 15/20, Batch: 1350/1388, Loss: 0.8882\n",
      "Epoch: 15, Train Loss: 0.9834\n",
      "Epoch: 16/20, Batch: 0/1388, Loss: 0.7578\n",
      "Epoch: 16/20, Batch: 50/1388, Loss: 0.7695\n",
      "Epoch: 16/20, Batch: 100/1388, Loss: 0.7963\n",
      "Epoch: 16/20, Batch: 150/1388, Loss: 0.6709\n",
      "Epoch: 16/20, Batch: 200/1388, Loss: 0.9806\n",
      "Epoch: 16/20, Batch: 250/1388, Loss: 1.0957\n",
      "Epoch: 16/20, Batch: 300/1388, Loss: 1.3370\n",
      "Epoch: 16/20, Batch: 350/1388, Loss: 0.8713\n",
      "Epoch: 16/20, Batch: 400/1388, Loss: 0.9554\n",
      "Epoch: 16/20, Batch: 450/1388, Loss: 0.7893\n",
      "Epoch: 16/20, Batch: 500/1388, Loss: 0.8941\n",
      "Epoch: 16/20, Batch: 550/1388, Loss: 1.0757\n",
      "Epoch: 16/20, Batch: 600/1388, Loss: 0.9294\n",
      "Epoch: 16/20, Batch: 650/1388, Loss: 0.8099\n",
      "Epoch: 16/20, Batch: 700/1388, Loss: 0.7090\n",
      "Epoch: 16/20, Batch: 750/1388, Loss: 0.8678\n",
      "Epoch: 16/20, Batch: 800/1388, Loss: 1.3805\n",
      "Epoch: 16/20, Batch: 850/1388, Loss: 0.7973\n",
      "Epoch: 16/20, Batch: 900/1388, Loss: 0.7156\n",
      "Epoch: 16/20, Batch: 950/1388, Loss: 0.7361\n",
      "Epoch: 16/20, Batch: 1000/1388, Loss: 0.8406\n",
      "Epoch: 16/20, Batch: 1050/1388, Loss: 0.7912\n",
      "Epoch: 16/20, Batch: 1100/1388, Loss: 1.4574\n",
      "Epoch: 16/20, Batch: 1150/1388, Loss: 1.0986\n",
      "Epoch: 16/20, Batch: 1200/1388, Loss: 0.8432\n",
      "Epoch: 16/20, Batch: 1250/1388, Loss: 1.4326\n",
      "Epoch: 16/20, Batch: 1300/1388, Loss: 0.8252\n",
      "Epoch: 16/20, Batch: 1350/1388, Loss: 1.1275\n",
      "Epoch: 16, Train Loss: 0.9812\n",
      "Epoch: 17/20, Batch: 0/1388, Loss: 0.6434\n",
      "Epoch: 17/20, Batch: 50/1388, Loss: 1.2422\n",
      "Epoch: 17/20, Batch: 100/1388, Loss: 0.9817\n",
      "Epoch: 17/20, Batch: 150/1388, Loss: 0.9914\n",
      "Epoch: 17/20, Batch: 200/1388, Loss: 0.6588\n",
      "Epoch: 17/20, Batch: 250/1388, Loss: 1.3362\n",
      "Epoch: 17/20, Batch: 300/1388, Loss: 0.9168\n",
      "Epoch: 17/20, Batch: 350/1388, Loss: 0.7701\n",
      "Epoch: 17/20, Batch: 400/1388, Loss: 0.8921\n",
      "Epoch: 17/20, Batch: 450/1388, Loss: 0.8688\n",
      "Epoch: 17/20, Batch: 500/1388, Loss: 1.0825\n",
      "Epoch: 17/20, Batch: 550/1388, Loss: 0.8257\n",
      "Epoch: 17/20, Batch: 600/1388, Loss: 1.0656\n",
      "Epoch: 17/20, Batch: 650/1388, Loss: 1.1227\n",
      "Epoch: 17/20, Batch: 700/1388, Loss: 0.7703\n",
      "Epoch: 17/20, Batch: 750/1388, Loss: 0.9598\n",
      "Epoch: 17/20, Batch: 800/1388, Loss: 0.9984\n",
      "Epoch: 17/20, Batch: 850/1388, Loss: 1.0143\n",
      "Epoch: 17/20, Batch: 900/1388, Loss: 0.9765\n",
      "Epoch: 17/20, Batch: 950/1388, Loss: 1.1769\n",
      "Epoch: 17/20, Batch: 1000/1388, Loss: 0.9972\n",
      "Epoch: 17/20, Batch: 1050/1388, Loss: 0.8717\n",
      "Epoch: 17/20, Batch: 1100/1388, Loss: 0.8041\n",
      "Epoch: 17/20, Batch: 1150/1388, Loss: 0.7498\n",
      "Epoch: 17/20, Batch: 1200/1388, Loss: 1.0418\n",
      "Epoch: 17/20, Batch: 1250/1388, Loss: 0.9729\n",
      "Epoch: 17/20, Batch: 1300/1388, Loss: 1.6680\n",
      "Epoch: 17/20, Batch: 1350/1388, Loss: 1.0738\n",
      "Epoch: 17, Train Loss: 0.9813\n",
      "Epoch: 18/20, Batch: 0/1388, Loss: 0.9221\n",
      "Epoch: 18/20, Batch: 50/1388, Loss: 0.9305\n",
      "Epoch: 18/20, Batch: 100/1388, Loss: 1.2494\n",
      "Epoch: 18/20, Batch: 150/1388, Loss: 0.8464\n",
      "Epoch: 18/20, Batch: 200/1388, Loss: 0.8553\n",
      "Epoch: 18/20, Batch: 250/1388, Loss: 0.6340\n",
      "Epoch: 18/20, Batch: 300/1388, Loss: 1.2293\n",
      "Epoch: 18/20, Batch: 350/1388, Loss: 0.7894\n",
      "Epoch: 18/20, Batch: 400/1388, Loss: 1.0666\n",
      "Epoch: 18/20, Batch: 450/1388, Loss: 0.8540\n",
      "Epoch: 18/20, Batch: 500/1388, Loss: 1.0993\n",
      "Epoch: 18/20, Batch: 550/1388, Loss: 1.2300\n",
      "Epoch: 18/20, Batch: 600/1388, Loss: 0.8380\n",
      "Epoch: 18/20, Batch: 650/1388, Loss: 1.0149\n",
      "Epoch: 18/20, Batch: 700/1388, Loss: 1.2024\n",
      "Epoch: 18/20, Batch: 750/1388, Loss: 0.7039\n",
      "Epoch: 18/20, Batch: 800/1388, Loss: 0.7160\n",
      "Epoch: 18/20, Batch: 850/1388, Loss: 0.9542\n",
      "Epoch: 18/20, Batch: 900/1388, Loss: 1.1100\n",
      "Epoch: 18/20, Batch: 950/1388, Loss: 0.8155\n",
      "Epoch: 18/20, Batch: 1000/1388, Loss: 0.9824\n",
      "Epoch: 18/20, Batch: 1050/1388, Loss: 0.9820\n",
      "Epoch: 18/20, Batch: 1100/1388, Loss: 1.0030\n",
      "Epoch: 18/20, Batch: 1150/1388, Loss: 0.8331\n",
      "Epoch: 18/20, Batch: 1200/1388, Loss: 0.7525\n",
      "Epoch: 18/20, Batch: 1250/1388, Loss: 1.2693\n",
      "Epoch: 18/20, Batch: 1300/1388, Loss: 0.6938\n",
      "Epoch: 18/20, Batch: 1350/1388, Loss: 1.0061\n",
      "Epoch: 18, Train Loss: 0.9793\n",
      "Epoch: 19/20, Batch: 0/1388, Loss: 0.9187\n",
      "Epoch: 19/20, Batch: 50/1388, Loss: 1.0649\n",
      "Epoch: 19/20, Batch: 100/1388, Loss: 1.0282\n",
      "Epoch: 19/20, Batch: 150/1388, Loss: 1.2959\n",
      "Epoch: 19/20, Batch: 200/1388, Loss: 0.8586\n",
      "Epoch: 19/20, Batch: 250/1388, Loss: 0.9889\n",
      "Epoch: 19/20, Batch: 300/1388, Loss: 0.8631\n",
      "Epoch: 19/20, Batch: 350/1388, Loss: 1.5279\n",
      "Epoch: 19/20, Batch: 400/1388, Loss: 0.7539\n",
      "Epoch: 19/20, Batch: 450/1388, Loss: 0.9291\n",
      "Epoch: 19/20, Batch: 500/1388, Loss: 0.9613\n",
      "Epoch: 19/20, Batch: 550/1388, Loss: 0.7573\n",
      "Epoch: 19/20, Batch: 600/1388, Loss: 0.7282\n",
      "Epoch: 19/20, Batch: 650/1388, Loss: 0.8678\n",
      "Epoch: 19/20, Batch: 700/1388, Loss: 0.8950\n",
      "Epoch: 19/20, Batch: 750/1388, Loss: 0.7491\n",
      "Epoch: 19/20, Batch: 800/1388, Loss: 1.1850\n",
      "Epoch: 19/20, Batch: 850/1388, Loss: 1.4783\n",
      "Epoch: 19/20, Batch: 900/1388, Loss: 1.0259\n",
      "Epoch: 19/20, Batch: 950/1388, Loss: 0.7767\n",
      "Epoch: 19/20, Batch: 1000/1388, Loss: 1.1523\n",
      "Epoch: 19/20, Batch: 1050/1388, Loss: 1.0138\n",
      "Epoch: 19/20, Batch: 1100/1388, Loss: 0.7495\n",
      "Epoch: 19/20, Batch: 1150/1388, Loss: 1.3149\n",
      "Epoch: 19/20, Batch: 1200/1388, Loss: 0.7464\n",
      "Epoch: 19/20, Batch: 1250/1388, Loss: 0.8446\n",
      "Epoch: 19/20, Batch: 1300/1388, Loss: 0.9734\n",
      "Epoch: 19/20, Batch: 1350/1388, Loss: 1.1094\n",
      "Epoch: 19, Train Loss: 0.9796\n",
      "Epoch: 20/20, Batch: 0/1388, Loss: 1.0890\n",
      "Epoch: 20/20, Batch: 50/1388, Loss: 0.8506\n",
      "Epoch: 20/20, Batch: 100/1388, Loss: 0.8621\n",
      "Epoch: 20/20, Batch: 150/1388, Loss: 1.1378\n",
      "Epoch: 20/20, Batch: 200/1388, Loss: 0.9887\n",
      "Epoch: 20/20, Batch: 250/1388, Loss: 0.9601\n",
      "Epoch: 20/20, Batch: 300/1388, Loss: 0.8580\n",
      "Epoch: 20/20, Batch: 350/1388, Loss: 1.4302\n",
      "Epoch: 20/20, Batch: 400/1388, Loss: 1.1098\n",
      "Epoch: 20/20, Batch: 450/1388, Loss: 0.7307\n",
      "Epoch: 20/20, Batch: 500/1388, Loss: 1.1780\n",
      "Epoch: 20/20, Batch: 550/1388, Loss: 1.2058\n",
      "Epoch: 20/20, Batch: 600/1388, Loss: 0.8494\n",
      "Epoch: 20/20, Batch: 650/1388, Loss: 0.7267\n",
      "Epoch: 20/20, Batch: 700/1388, Loss: 0.7122\n",
      "Epoch: 20/20, Batch: 750/1388, Loss: 1.0338\n",
      "Epoch: 20/20, Batch: 800/1388, Loss: 0.6891\n",
      "Epoch: 20/20, Batch: 850/1388, Loss: 0.8388\n",
      "Epoch: 20/20, Batch: 900/1388, Loss: 1.2963\n",
      "Epoch: 20/20, Batch: 950/1388, Loss: 1.4228\n",
      "Epoch: 20/20, Batch: 1000/1388, Loss: 1.4247\n",
      "Epoch: 20/20, Batch: 1050/1388, Loss: 1.1551\n",
      "Epoch: 20/20, Batch: 1100/1388, Loss: 0.7426\n",
      "Epoch: 20/20, Batch: 1150/1388, Loss: 1.0974\n",
      "Epoch: 20/20, Batch: 1200/1388, Loss: 0.7386\n",
      "Epoch: 20/20, Batch: 1250/1388, Loss: 0.9712\n",
      "Epoch: 20/20, Batch: 1300/1388, Loss: 0.9778\n",
      "Epoch: 20/20, Batch: 1350/1388, Loss: 0.9102\n",
      "Epoch: 20, Train Loss: 0.9783\n",
      "Training finished!\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "5ReEI-waAihj",
    "outputId": "f786cfaa-e60e-499d-fecb-d9aef3b5dc7b",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:13:00.464644Z",
     "start_time": "2025-11-05T04:12:59.908225Z"
    }
   },
   "source": [
    "weighted_model.eval()\n",
    "y_true_weighted = []\n",
    "y_pred_weighted = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = weighted_model(data)\n",
    "\n",
    "        y_true_weighted.extend(target.cpu().numpy())\n",
    "        y_pred_weighted.extend((output > 0.5).cpu().numpy())\n",
    "\n",
    "y_true_weighted = np.array(y_true_weighted)\n",
    "y_pred_weighted = np.array(y_pred_weighted)\n",
    "\n",
    "print(\"\\nClassification Report (Weighted):\")\n",
    "print(classification_report(y_true_weighted, y_pred_weighted))\n",
    "print(\"\\nConfusion Matrix (Weighted):\")\n",
    "cm_weighted = confusion_matrix(y_true_weighted, y_pred_weighted)\n",
    "sns.heatmap(cm_weighted, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Weighted)')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Weighted):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.73      0.83     68936\n",
      "         1.0       0.24      0.82      0.37      7168\n",
      "\n",
      "    accuracy                           0.74     76104\n",
      "   macro avg       0.61      0.77      0.60     76104\n",
      "weighted avg       0.90      0.74      0.79     76104\n",
      "\n",
      "\n",
      "Confusion Matrix (Weighted):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-h1IzazAihj"
   },
   "source": [
    "### train:test = 6:4"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjYaal-kAihj",
    "outputId": "d51f556a-ff0e-427a-93f7-ee3348980b1b",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:14:19.371686Z",
     "start_time": "2025-11-05T04:13:00.495083Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "std = StandardScaler()\n",
    "X_train_scaled = std.fit_transform(X_train)\n",
    "X_test_scaled = std.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=14)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "train_dataset = HeartDiseaseDataset(X_train_pca, y_train)\n",
    "test_dataset = HeartDiseaseDataset(X_test_pca, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "input_features = X_train_pca.shape[1]\n",
    "\n",
    "weighted_model = HeartDiseaseMLPClassifier(input_size=input_features, class_frequencies=class_frequencies).to(device)\n",
    "\n",
    "optimizer = optim.Adam(weighted_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "num_epochs = 20\n",
    "weighted_train_losses = []\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    weighted_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = weighted_model(data)\n",
    "\n",
    "        target = target.float()\n",
    "        output = output.float()\n",
    "        loss = weighted_model.get_weighted_loss(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    weighted_train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "print('Training finished!')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch: 1/20, Batch: 0/1190, Loss: 1.6350\n",
      "Epoch: 1/20, Batch: 50/1190, Loss: 0.9185\n",
      "Epoch: 1/20, Batch: 100/1190, Loss: 1.0741\n",
      "Epoch: 1/20, Batch: 150/1190, Loss: 1.2873\n",
      "Epoch: 1/20, Batch: 200/1190, Loss: 1.2562\n",
      "Epoch: 1/20, Batch: 250/1190, Loss: 1.0320\n",
      "Epoch: 1/20, Batch: 300/1190, Loss: 0.9067\n",
      "Epoch: 1/20, Batch: 350/1190, Loss: 1.5130\n",
      "Epoch: 1/20, Batch: 400/1190, Loss: 0.9520\n",
      "Epoch: 1/20, Batch: 450/1190, Loss: 0.7157\n",
      "Epoch: 1/20, Batch: 500/1190, Loss: 0.9976\n",
      "Epoch: 1/20, Batch: 550/1190, Loss: 1.1060\n",
      "Epoch: 1/20, Batch: 600/1190, Loss: 1.2259\n",
      "Epoch: 1/20, Batch: 650/1190, Loss: 0.9612\n",
      "Epoch: 1/20, Batch: 700/1190, Loss: 0.8347\n",
      "Epoch: 1/20, Batch: 750/1190, Loss: 1.1510\n",
      "Epoch: 1/20, Batch: 800/1190, Loss: 0.9170\n",
      "Epoch: 1/20, Batch: 850/1190, Loss: 1.5671\n",
      "Epoch: 1/20, Batch: 900/1190, Loss: 0.8651\n",
      "Epoch: 1/20, Batch: 950/1190, Loss: 0.8319\n",
      "Epoch: 1/20, Batch: 1000/1190, Loss: 1.2385\n",
      "Epoch: 1/20, Batch: 1050/1190, Loss: 0.9492\n",
      "Epoch: 1/20, Batch: 1100/1190, Loss: 0.8552\n",
      "Epoch: 1/20, Batch: 1150/1190, Loss: 1.4100\n",
      "Epoch: 1, Train Loss: 1.0194\n",
      "Epoch: 2/20, Batch: 0/1190, Loss: 1.1276\n",
      "Epoch: 2/20, Batch: 50/1190, Loss: 1.0179\n",
      "Epoch: 2/20, Batch: 100/1190, Loss: 1.0420\n",
      "Epoch: 2/20, Batch: 150/1190, Loss: 1.0871\n",
      "Epoch: 2/20, Batch: 200/1190, Loss: 0.7137\n",
      "Epoch: 2/20, Batch: 250/1190, Loss: 1.3610\n",
      "Epoch: 2/20, Batch: 300/1190, Loss: 0.8128\n",
      "Epoch: 2/20, Batch: 350/1190, Loss: 0.8996\n",
      "Epoch: 2/20, Batch: 400/1190, Loss: 0.8375\n",
      "Epoch: 2/20, Batch: 450/1190, Loss: 0.7139\n",
      "Epoch: 2/20, Batch: 500/1190, Loss: 1.0871\n",
      "Epoch: 2/20, Batch: 550/1190, Loss: 1.2464\n",
      "Epoch: 2/20, Batch: 600/1190, Loss: 1.1452\n",
      "Epoch: 2/20, Batch: 650/1190, Loss: 1.1026\n",
      "Epoch: 2/20, Batch: 700/1190, Loss: 1.0468\n",
      "Epoch: 2/20, Batch: 750/1190, Loss: 1.0409\n",
      "Epoch: 2/20, Batch: 800/1190, Loss: 0.9542\n",
      "Epoch: 2/20, Batch: 850/1190, Loss: 1.0629\n",
      "Epoch: 2/20, Batch: 900/1190, Loss: 1.2571\n",
      "Epoch: 2/20, Batch: 950/1190, Loss: 0.8305\n",
      "Epoch: 2/20, Batch: 1000/1190, Loss: 0.9213\n",
      "Epoch: 2/20, Batch: 1050/1190, Loss: 0.7730\n",
      "Epoch: 2/20, Batch: 1100/1190, Loss: 1.2742\n",
      "Epoch: 2/20, Batch: 1150/1190, Loss: 0.8685\n",
      "Epoch: 2, Train Loss: 0.9986\n",
      "Epoch: 3/20, Batch: 0/1190, Loss: 0.7977\n",
      "Epoch: 3/20, Batch: 50/1190, Loss: 0.9102\n",
      "Epoch: 3/20, Batch: 100/1190, Loss: 0.9816\n",
      "Epoch: 3/20, Batch: 150/1190, Loss: 1.0845\n",
      "Epoch: 3/20, Batch: 200/1190, Loss: 0.9527\n",
      "Epoch: 3/20, Batch: 250/1190, Loss: 0.8012\n",
      "Epoch: 3/20, Batch: 300/1190, Loss: 1.1337\n",
      "Epoch: 3/20, Batch: 350/1190, Loss: 0.8899\n",
      "Epoch: 3/20, Batch: 400/1190, Loss: 1.0208\n",
      "Epoch: 3/20, Batch: 450/1190, Loss: 0.9998\n",
      "Epoch: 3/20, Batch: 500/1190, Loss: 1.0869\n",
      "Epoch: 3/20, Batch: 550/1190, Loss: 0.9950\n",
      "Epoch: 3/20, Batch: 600/1190, Loss: 1.0993\n",
      "Epoch: 3/20, Batch: 650/1190, Loss: 1.4383\n",
      "Epoch: 3/20, Batch: 700/1190, Loss: 1.0033\n",
      "Epoch: 3/20, Batch: 750/1190, Loss: 0.9758\n",
      "Epoch: 3/20, Batch: 800/1190, Loss: 0.9239\n",
      "Epoch: 3/20, Batch: 850/1190, Loss: 1.3437\n",
      "Epoch: 3/20, Batch: 900/1190, Loss: 0.8878\n",
      "Epoch: 3/20, Batch: 950/1190, Loss: 1.2570\n",
      "Epoch: 3/20, Batch: 1000/1190, Loss: 0.8427\n",
      "Epoch: 3/20, Batch: 1050/1190, Loss: 0.7970\n",
      "Epoch: 3/20, Batch: 1100/1190, Loss: 0.7881\n",
      "Epoch: 3/20, Batch: 1150/1190, Loss: 1.0217\n",
      "Epoch: 3, Train Loss: 0.9957\n",
      "Epoch: 4/20, Batch: 0/1190, Loss: 1.2102\n",
      "Epoch: 4/20, Batch: 50/1190, Loss: 1.1228\n",
      "Epoch: 4/20, Batch: 100/1190, Loss: 1.0698\n",
      "Epoch: 4/20, Batch: 150/1190, Loss: 1.1259\n",
      "Epoch: 4/20, Batch: 200/1190, Loss: 0.8235\n",
      "Epoch: 4/20, Batch: 250/1190, Loss: 0.8942\n",
      "Epoch: 4/20, Batch: 300/1190, Loss: 0.8601\n",
      "Epoch: 4/20, Batch: 350/1190, Loss: 0.7277\n",
      "Epoch: 4/20, Batch: 400/1190, Loss: 1.2803\n",
      "Epoch: 4/20, Batch: 450/1190, Loss: 1.2803\n",
      "Epoch: 4/20, Batch: 500/1190, Loss: 0.7667\n",
      "Epoch: 4/20, Batch: 550/1190, Loss: 0.9369\n",
      "Epoch: 4/20, Batch: 600/1190, Loss: 1.2827\n",
      "Epoch: 4/20, Batch: 650/1190, Loss: 0.9631\n",
      "Epoch: 4/20, Batch: 700/1190, Loss: 1.5226\n",
      "Epoch: 4/20, Batch: 750/1190, Loss: 0.7306\n",
      "Epoch: 4/20, Batch: 800/1190, Loss: 0.6763\n",
      "Epoch: 4/20, Batch: 850/1190, Loss: 0.7450\n",
      "Epoch: 4/20, Batch: 900/1190, Loss: 0.7600\n",
      "Epoch: 4/20, Batch: 950/1190, Loss: 1.2281\n",
      "Epoch: 4/20, Batch: 1000/1190, Loss: 0.6671\n",
      "Epoch: 4/20, Batch: 1050/1190, Loss: 1.1114\n",
      "Epoch: 4/20, Batch: 1100/1190, Loss: 0.8229\n",
      "Epoch: 4/20, Batch: 1150/1190, Loss: 0.7972\n",
      "Epoch: 4, Train Loss: 0.9907\n",
      "Epoch: 5/20, Batch: 0/1190, Loss: 0.7234\n",
      "Epoch: 5/20, Batch: 50/1190, Loss: 1.3063\n",
      "Epoch: 5/20, Batch: 100/1190, Loss: 1.4250\n",
      "Epoch: 5/20, Batch: 150/1190, Loss: 0.8665\n",
      "Epoch: 5/20, Batch: 200/1190, Loss: 0.8970\n",
      "Epoch: 5/20, Batch: 250/1190, Loss: 0.9707\n",
      "Epoch: 5/20, Batch: 300/1190, Loss: 0.9895\n",
      "Epoch: 5/20, Batch: 350/1190, Loss: 0.9440\n",
      "Epoch: 5/20, Batch: 400/1190, Loss: 1.1096\n",
      "Epoch: 5/20, Batch: 450/1190, Loss: 0.6520\n",
      "Epoch: 5/20, Batch: 500/1190, Loss: 1.0306\n",
      "Epoch: 5/20, Batch: 550/1190, Loss: 1.3342\n",
      "Epoch: 5/20, Batch: 600/1190, Loss: 1.1457\n",
      "Epoch: 5/20, Batch: 650/1190, Loss: 1.2305\n",
      "Epoch: 5/20, Batch: 700/1190, Loss: 0.7789\n",
      "Epoch: 5/20, Batch: 750/1190, Loss: 0.9966\n",
      "Epoch: 5/20, Batch: 800/1190, Loss: 0.9621\n",
      "Epoch: 5/20, Batch: 850/1190, Loss: 0.7928\n",
      "Epoch: 5/20, Batch: 900/1190, Loss: 0.8624\n",
      "Epoch: 5/20, Batch: 950/1190, Loss: 1.1180\n",
      "Epoch: 5/20, Batch: 1000/1190, Loss: 0.9629\n",
      "Epoch: 5/20, Batch: 1050/1190, Loss: 0.9552\n",
      "Epoch: 5/20, Batch: 1100/1190, Loss: 0.8979\n",
      "Epoch: 5/20, Batch: 1150/1190, Loss: 1.2587\n",
      "Epoch: 5, Train Loss: 0.9914\n",
      "Epoch: 6/20, Batch: 0/1190, Loss: 0.7488\n",
      "Epoch: 6/20, Batch: 50/1190, Loss: 0.6753\n",
      "Epoch: 6/20, Batch: 100/1190, Loss: 0.7796\n",
      "Epoch: 6/20, Batch: 150/1190, Loss: 1.0044\n",
      "Epoch: 6/20, Batch: 200/1190, Loss: 1.0326\n",
      "Epoch: 6/20, Batch: 250/1190, Loss: 1.1862\n",
      "Epoch: 6/20, Batch: 300/1190, Loss: 1.2643\n",
      "Epoch: 6/20, Batch: 350/1190, Loss: 0.8645\n",
      "Epoch: 6/20, Batch: 400/1190, Loss: 0.9304\n",
      "Epoch: 6/20, Batch: 450/1190, Loss: 1.4812\n",
      "Epoch: 6/20, Batch: 500/1190, Loss: 0.7862\n",
      "Epoch: 6/20, Batch: 550/1190, Loss: 0.9329\n",
      "Epoch: 6/20, Batch: 600/1190, Loss: 0.9652\n",
      "Epoch: 6/20, Batch: 650/1190, Loss: 0.9884\n",
      "Epoch: 6/20, Batch: 700/1190, Loss: 1.2158\n",
      "Epoch: 6/20, Batch: 750/1190, Loss: 0.9442\n",
      "Epoch: 6/20, Batch: 800/1190, Loss: 1.1054\n",
      "Epoch: 6/20, Batch: 850/1190, Loss: 1.0475\n",
      "Epoch: 6/20, Batch: 900/1190, Loss: 0.8655\n",
      "Epoch: 6/20, Batch: 950/1190, Loss: 0.8890\n",
      "Epoch: 6/20, Batch: 1000/1190, Loss: 0.7485\n",
      "Epoch: 6/20, Batch: 1050/1190, Loss: 1.0702\n",
      "Epoch: 6/20, Batch: 1100/1190, Loss: 0.9859\n",
      "Epoch: 6/20, Batch: 1150/1190, Loss: 1.1568\n",
      "Epoch: 6, Train Loss: 0.9897\n",
      "Epoch: 7/20, Batch: 0/1190, Loss: 0.9142\n",
      "Epoch: 7/20, Batch: 50/1190, Loss: 0.9938\n",
      "Epoch: 7/20, Batch: 100/1190, Loss: 1.2086\n",
      "Epoch: 7/20, Batch: 150/1190, Loss: 0.7342\n",
      "Epoch: 7/20, Batch: 200/1190, Loss: 1.3233\n",
      "Epoch: 7/20, Batch: 250/1190, Loss: 0.8338\n",
      "Epoch: 7/20, Batch: 300/1190, Loss: 0.7817\n",
      "Epoch: 7/20, Batch: 350/1190, Loss: 1.0389\n",
      "Epoch: 7/20, Batch: 400/1190, Loss: 0.8988\n",
      "Epoch: 7/20, Batch: 450/1190, Loss: 0.7758\n",
      "Epoch: 7/20, Batch: 500/1190, Loss: 1.4210\n",
      "Epoch: 7/20, Batch: 550/1190, Loss: 0.8362\n",
      "Epoch: 7/20, Batch: 600/1190, Loss: 0.8713\n",
      "Epoch: 7/20, Batch: 650/1190, Loss: 1.0145\n",
      "Epoch: 7/20, Batch: 700/1190, Loss: 0.9644\n",
      "Epoch: 7/20, Batch: 750/1190, Loss: 1.1199\n",
      "Epoch: 7/20, Batch: 800/1190, Loss: 0.9294\n",
      "Epoch: 7/20, Batch: 850/1190, Loss: 0.7251\n",
      "Epoch: 7/20, Batch: 900/1190, Loss: 0.8088\n",
      "Epoch: 7/20, Batch: 950/1190, Loss: 1.0729\n",
      "Epoch: 7/20, Batch: 1000/1190, Loss: 1.0433\n",
      "Epoch: 7/20, Batch: 1050/1190, Loss: 0.7854\n",
      "Epoch: 7/20, Batch: 1100/1190, Loss: 0.7317\n",
      "Epoch: 7/20, Batch: 1150/1190, Loss: 0.9035\n",
      "Epoch: 7, Train Loss: 0.9879\n",
      "Epoch: 8/20, Batch: 0/1190, Loss: 1.2122\n",
      "Epoch: 8/20, Batch: 50/1190, Loss: 0.8625\n",
      "Epoch: 8/20, Batch: 100/1190, Loss: 0.7100\n",
      "Epoch: 8/20, Batch: 150/1190, Loss: 0.8298\n",
      "Epoch: 8/20, Batch: 200/1190, Loss: 1.1118\n",
      "Epoch: 8/20, Batch: 250/1190, Loss: 0.8295\n",
      "Epoch: 8/20, Batch: 300/1190, Loss: 1.0503\n",
      "Epoch: 8/20, Batch: 350/1190, Loss: 0.9049\n",
      "Epoch: 8/20, Batch: 400/1190, Loss: 0.8205\n",
      "Epoch: 8/20, Batch: 450/1190, Loss: 1.0203\n",
      "Epoch: 8/20, Batch: 500/1190, Loss: 1.0182\n",
      "Epoch: 8/20, Batch: 550/1190, Loss: 1.2363\n",
      "Epoch: 8/20, Batch: 600/1190, Loss: 1.1257\n",
      "Epoch: 8/20, Batch: 650/1190, Loss: 0.8474\n",
      "Epoch: 8/20, Batch: 700/1190, Loss: 1.0385\n",
      "Epoch: 8/20, Batch: 750/1190, Loss: 1.1501\n",
      "Epoch: 8/20, Batch: 800/1190, Loss: 0.8626\n",
      "Epoch: 8/20, Batch: 850/1190, Loss: 1.1986\n",
      "Epoch: 8/20, Batch: 900/1190, Loss: 0.9665\n",
      "Epoch: 8/20, Batch: 950/1190, Loss: 0.9191\n",
      "Epoch: 8/20, Batch: 1000/1190, Loss: 1.0780\n",
      "Epoch: 8/20, Batch: 1050/1190, Loss: 0.8593\n",
      "Epoch: 8/20, Batch: 1100/1190, Loss: 1.0322\n",
      "Epoch: 8/20, Batch: 1150/1190, Loss: 0.9282\n",
      "Epoch: 8, Train Loss: 0.9856\n",
      "Epoch: 9/20, Batch: 0/1190, Loss: 0.7981\n",
      "Epoch: 9/20, Batch: 50/1190, Loss: 0.7767\n",
      "Epoch: 9/20, Batch: 100/1190, Loss: 1.3827\n",
      "Epoch: 9/20, Batch: 150/1190, Loss: 1.0499\n",
      "Epoch: 9/20, Batch: 200/1190, Loss: 0.9876\n",
      "Epoch: 9/20, Batch: 250/1190, Loss: 1.0838\n",
      "Epoch: 9/20, Batch: 300/1190, Loss: 0.9460\n",
      "Epoch: 9/20, Batch: 350/1190, Loss: 1.3369\n",
      "Epoch: 9/20, Batch: 400/1190, Loss: 0.9690\n",
      "Epoch: 9/20, Batch: 450/1190, Loss: 0.8593\n",
      "Epoch: 9/20, Batch: 500/1190, Loss: 1.0213\n",
      "Epoch: 9/20, Batch: 550/1190, Loss: 0.9545\n",
      "Epoch: 9/20, Batch: 600/1190, Loss: 0.8672\n",
      "Epoch: 9/20, Batch: 650/1190, Loss: 1.1263\n",
      "Epoch: 9/20, Batch: 700/1190, Loss: 1.2910\n",
      "Epoch: 9/20, Batch: 750/1190, Loss: 1.0678\n",
      "Epoch: 9/20, Batch: 800/1190, Loss: 1.1194\n",
      "Epoch: 9/20, Batch: 850/1190, Loss: 0.8675\n",
      "Epoch: 9/20, Batch: 900/1190, Loss: 1.0568\n",
      "Epoch: 9/20, Batch: 950/1190, Loss: 0.9821\n",
      "Epoch: 9/20, Batch: 1000/1190, Loss: 1.6912\n",
      "Epoch: 9/20, Batch: 1050/1190, Loss: 0.8778\n",
      "Epoch: 9/20, Batch: 1100/1190, Loss: 0.6995\n",
      "Epoch: 9/20, Batch: 1150/1190, Loss: 1.4676\n",
      "Epoch: 9, Train Loss: 0.9873\n",
      "Epoch: 10/20, Batch: 0/1190, Loss: 1.2459\n",
      "Epoch: 10/20, Batch: 50/1190, Loss: 1.2459\n",
      "Epoch: 10/20, Batch: 100/1190, Loss: 0.6997\n",
      "Epoch: 10/20, Batch: 150/1190, Loss: 0.8886\n",
      "Epoch: 10/20, Batch: 200/1190, Loss: 1.1706\n",
      "Epoch: 10/20, Batch: 250/1190, Loss: 1.0985\n",
      "Epoch: 10/20, Batch: 300/1190, Loss: 0.9533\n",
      "Epoch: 10/20, Batch: 350/1190, Loss: 1.1775\n",
      "Epoch: 10/20, Batch: 400/1190, Loss: 0.7982\n",
      "Epoch: 10/20, Batch: 450/1190, Loss: 1.1456\n",
      "Epoch: 10/20, Batch: 500/1190, Loss: 1.3928\n",
      "Epoch: 10/20, Batch: 550/1190, Loss: 1.0790\n",
      "Epoch: 10/20, Batch: 600/1190, Loss: 0.9444\n",
      "Epoch: 10/20, Batch: 650/1190, Loss: 0.7441\n",
      "Epoch: 10/20, Batch: 700/1190, Loss: 1.0832\n",
      "Epoch: 10/20, Batch: 750/1190, Loss: 0.7582\n",
      "Epoch: 10/20, Batch: 800/1190, Loss: 0.9156\n",
      "Epoch: 10/20, Batch: 850/1190, Loss: 0.9777\n",
      "Epoch: 10/20, Batch: 900/1190, Loss: 0.9972\n",
      "Epoch: 10/20, Batch: 950/1190, Loss: 1.1168\n",
      "Epoch: 10/20, Batch: 1000/1190, Loss: 0.7743\n",
      "Epoch: 10/20, Batch: 1050/1190, Loss: 0.9001\n",
      "Epoch: 10/20, Batch: 1100/1190, Loss: 0.9962\n",
      "Epoch: 10/20, Batch: 1150/1190, Loss: 1.1432\n",
      "Epoch: 10, Train Loss: 0.9871\n",
      "Epoch: 11/20, Batch: 0/1190, Loss: 0.7125\n",
      "Epoch: 11/20, Batch: 50/1190, Loss: 0.8710\n",
      "Epoch: 11/20, Batch: 100/1190, Loss: 0.7657\n",
      "Epoch: 11/20, Batch: 150/1190, Loss: 1.1394\n",
      "Epoch: 11/20, Batch: 200/1190, Loss: 0.9076\n",
      "Epoch: 11/20, Batch: 250/1190, Loss: 0.9473\n",
      "Epoch: 11/20, Batch: 300/1190, Loss: 0.7723\n",
      "Epoch: 11/20, Batch: 350/1190, Loss: 0.8830\n",
      "Epoch: 11/20, Batch: 400/1190, Loss: 1.0092\n",
      "Epoch: 11/20, Batch: 450/1190, Loss: 0.8497\n",
      "Epoch: 11/20, Batch: 500/1190, Loss: 1.0713\n",
      "Epoch: 11/20, Batch: 550/1190, Loss: 0.7559\n",
      "Epoch: 11/20, Batch: 600/1190, Loss: 1.4295\n",
      "Epoch: 11/20, Batch: 650/1190, Loss: 0.8130\n",
      "Epoch: 11/20, Batch: 700/1190, Loss: 0.6846\n",
      "Epoch: 11/20, Batch: 750/1190, Loss: 0.9111\n",
      "Epoch: 11/20, Batch: 800/1190, Loss: 0.8259\n",
      "Epoch: 11/20, Batch: 850/1190, Loss: 1.1277\n",
      "Epoch: 11/20, Batch: 900/1190, Loss: 1.2020\n",
      "Epoch: 11/20, Batch: 950/1190, Loss: 0.8623\n",
      "Epoch: 11/20, Batch: 1000/1190, Loss: 0.6788\n",
      "Epoch: 11/20, Batch: 1050/1190, Loss: 0.8150\n",
      "Epoch: 11/20, Batch: 1100/1190, Loss: 1.0209\n",
      "Epoch: 11/20, Batch: 1150/1190, Loss: 0.9803\n",
      "Epoch: 11, Train Loss: 0.9853\n",
      "Epoch: 12/20, Batch: 0/1190, Loss: 0.9228\n",
      "Epoch: 12/20, Batch: 50/1190, Loss: 0.9719\n",
      "Epoch: 12/20, Batch: 100/1190, Loss: 1.0097\n",
      "Epoch: 12/20, Batch: 150/1190, Loss: 0.8896\n",
      "Epoch: 12/20, Batch: 200/1190, Loss: 0.8119\n",
      "Epoch: 12/20, Batch: 250/1190, Loss: 0.8118\n",
      "Epoch: 12/20, Batch: 300/1190, Loss: 0.9344\n",
      "Epoch: 12/20, Batch: 350/1190, Loss: 1.0348\n",
      "Epoch: 12/20, Batch: 400/1190, Loss: 0.7569\n",
      "Epoch: 12/20, Batch: 450/1190, Loss: 0.7148\n",
      "Epoch: 12/20, Batch: 500/1190, Loss: 0.9649\n",
      "Epoch: 12/20, Batch: 550/1190, Loss: 0.9008\n",
      "Epoch: 12/20, Batch: 600/1190, Loss: 1.3557\n",
      "Epoch: 12/20, Batch: 650/1190, Loss: 1.1477\n",
      "Epoch: 12/20, Batch: 700/1190, Loss: 0.8438\n",
      "Epoch: 12/20, Batch: 750/1190, Loss: 0.8722\n",
      "Epoch: 12/20, Batch: 800/1190, Loss: 0.9978\n",
      "Epoch: 12/20, Batch: 850/1190, Loss: 1.0017\n",
      "Epoch: 12/20, Batch: 900/1190, Loss: 0.6674\n",
      "Epoch: 12/20, Batch: 950/1190, Loss: 0.9872\n",
      "Epoch: 12/20, Batch: 1000/1190, Loss: 1.0552\n",
      "Epoch: 12/20, Batch: 1050/1190, Loss: 1.1826\n",
      "Epoch: 12/20, Batch: 1100/1190, Loss: 0.8260\n",
      "Epoch: 12/20, Batch: 1150/1190, Loss: 0.8209\n",
      "Epoch: 12, Train Loss: 0.9847\n",
      "Epoch: 13/20, Batch: 0/1190, Loss: 1.3541\n",
      "Epoch: 13/20, Batch: 50/1190, Loss: 0.7359\n",
      "Epoch: 13/20, Batch: 100/1190, Loss: 0.8308\n",
      "Epoch: 13/20, Batch: 150/1190, Loss: 0.8024\n",
      "Epoch: 13/20, Batch: 200/1190, Loss: 1.1470\n",
      "Epoch: 13/20, Batch: 250/1190, Loss: 1.0464\n",
      "Epoch: 13/20, Batch: 300/1190, Loss: 0.8889\n",
      "Epoch: 13/20, Batch: 350/1190, Loss: 0.7462\n",
      "Epoch: 13/20, Batch: 400/1190, Loss: 0.9233\n",
      "Epoch: 13/20, Batch: 450/1190, Loss: 1.4564\n",
      "Epoch: 13/20, Batch: 500/1190, Loss: 1.2051\n",
      "Epoch: 13/20, Batch: 550/1190, Loss: 1.0473\n",
      "Epoch: 13/20, Batch: 600/1190, Loss: 1.2869\n",
      "Epoch: 13/20, Batch: 650/1190, Loss: 0.8229\n",
      "Epoch: 13/20, Batch: 700/1190, Loss: 0.7215\n",
      "Epoch: 13/20, Batch: 750/1190, Loss: 0.7616\n",
      "Epoch: 13/20, Batch: 800/1190, Loss: 1.2213\n",
      "Epoch: 13/20, Batch: 850/1190, Loss: 0.8519\n",
      "Epoch: 13/20, Batch: 900/1190, Loss: 0.7535\n",
      "Epoch: 13/20, Batch: 950/1190, Loss: 0.8817\n",
      "Epoch: 13/20, Batch: 1000/1190, Loss: 1.2898\n",
      "Epoch: 13/20, Batch: 1050/1190, Loss: 0.8239\n",
      "Epoch: 13/20, Batch: 1100/1190, Loss: 0.8373\n",
      "Epoch: 13/20, Batch: 1150/1190, Loss: 1.1132\n",
      "Epoch: 13, Train Loss: 0.9819\n",
      "Epoch: 14/20, Batch: 0/1190, Loss: 1.1166\n",
      "Epoch: 14/20, Batch: 50/1190, Loss: 0.9243\n",
      "Epoch: 14/20, Batch: 100/1190, Loss: 0.9500\n",
      "Epoch: 14/20, Batch: 150/1190, Loss: 0.9147\n",
      "Epoch: 14/20, Batch: 200/1190, Loss: 0.9014\n",
      "Epoch: 14/20, Batch: 250/1190, Loss: 0.7786\n",
      "Epoch: 14/20, Batch: 300/1190, Loss: 0.7916\n",
      "Epoch: 14/20, Batch: 350/1190, Loss: 1.2184\n",
      "Epoch: 14/20, Batch: 400/1190, Loss: 1.1869\n",
      "Epoch: 14/20, Batch: 450/1190, Loss: 0.9640\n",
      "Epoch: 14/20, Batch: 500/1190, Loss: 0.9511\n",
      "Epoch: 14/20, Batch: 550/1190, Loss: 0.8657\n",
      "Epoch: 14/20, Batch: 600/1190, Loss: 1.0758\n",
      "Epoch: 14/20, Batch: 650/1190, Loss: 0.9202\n",
      "Epoch: 14/20, Batch: 700/1190, Loss: 0.8457\n",
      "Epoch: 14/20, Batch: 750/1190, Loss: 1.0104\n",
      "Epoch: 14/20, Batch: 800/1190, Loss: 1.2528\n",
      "Epoch: 14/20, Batch: 850/1190, Loss: 1.1651\n",
      "Epoch: 14/20, Batch: 900/1190, Loss: 1.0264\n",
      "Epoch: 14/20, Batch: 950/1190, Loss: 0.8670\n",
      "Epoch: 14/20, Batch: 1000/1190, Loss: 1.2178\n",
      "Epoch: 14/20, Batch: 1050/1190, Loss: 1.2183\n",
      "Epoch: 14/20, Batch: 1100/1190, Loss: 1.0793\n",
      "Epoch: 14/20, Batch: 1150/1190, Loss: 1.0040\n",
      "Epoch: 14, Train Loss: 0.9834\n",
      "Epoch: 15/20, Batch: 0/1190, Loss: 1.0137\n",
      "Epoch: 15/20, Batch: 50/1190, Loss: 1.3444\n",
      "Epoch: 15/20, Batch: 100/1190, Loss: 0.9679\n",
      "Epoch: 15/20, Batch: 150/1190, Loss: 1.1783\n",
      "Epoch: 15/20, Batch: 200/1190, Loss: 1.4169\n",
      "Epoch: 15/20, Batch: 250/1190, Loss: 0.7796\n",
      "Epoch: 15/20, Batch: 300/1190, Loss: 1.2742\n",
      "Epoch: 15/20, Batch: 350/1190, Loss: 0.7970\n",
      "Epoch: 15/20, Batch: 400/1190, Loss: 0.9282\n",
      "Epoch: 15/20, Batch: 450/1190, Loss: 0.7158\n",
      "Epoch: 15/20, Batch: 500/1190, Loss: 0.8977\n",
      "Epoch: 15/20, Batch: 550/1190, Loss: 1.4874\n",
      "Epoch: 15/20, Batch: 600/1190, Loss: 1.0373\n",
      "Epoch: 15/20, Batch: 650/1190, Loss: 0.8835\n",
      "Epoch: 15/20, Batch: 700/1190, Loss: 0.9523\n",
      "Epoch: 15/20, Batch: 750/1190, Loss: 0.8643\n",
      "Epoch: 15/20, Batch: 800/1190, Loss: 0.8508\n",
      "Epoch: 15/20, Batch: 850/1190, Loss: 0.9794\n",
      "Epoch: 15/20, Batch: 900/1190, Loss: 0.9160\n",
      "Epoch: 15/20, Batch: 950/1190, Loss: 0.7297\n",
      "Epoch: 15/20, Batch: 1000/1190, Loss: 1.1267\n",
      "Epoch: 15/20, Batch: 1050/1190, Loss: 1.4070\n",
      "Epoch: 15/20, Batch: 1100/1190, Loss: 1.0762\n",
      "Epoch: 15/20, Batch: 1150/1190, Loss: 1.2072\n",
      "Epoch: 15, Train Loss: 0.9818\n",
      "Epoch: 16/20, Batch: 0/1190, Loss: 1.0073\n",
      "Epoch: 16/20, Batch: 50/1190, Loss: 1.1800\n",
      "Epoch: 16/20, Batch: 100/1190, Loss: 1.4420\n",
      "Epoch: 16/20, Batch: 150/1190, Loss: 0.7329\n",
      "Epoch: 16/20, Batch: 200/1190, Loss: 1.1591\n",
      "Epoch: 16/20, Batch: 250/1190, Loss: 0.7260\n",
      "Epoch: 16/20, Batch: 300/1190, Loss: 0.8920\n",
      "Epoch: 16/20, Batch: 350/1190, Loss: 0.8271\n",
      "Epoch: 16/20, Batch: 400/1190, Loss: 0.8770\n",
      "Epoch: 16/20, Batch: 450/1190, Loss: 0.8666\n",
      "Epoch: 16/20, Batch: 500/1190, Loss: 1.1780\n",
      "Epoch: 16/20, Batch: 550/1190, Loss: 0.8117\n",
      "Epoch: 16/20, Batch: 600/1190, Loss: 1.0229\n",
      "Epoch: 16/20, Batch: 650/1190, Loss: 0.8609\n",
      "Epoch: 16/20, Batch: 700/1190, Loss: 0.7952\n",
      "Epoch: 16/20, Batch: 750/1190, Loss: 1.0972\n",
      "Epoch: 16/20, Batch: 800/1190, Loss: 0.9558\n",
      "Epoch: 16/20, Batch: 850/1190, Loss: 1.0449\n",
      "Epoch: 16/20, Batch: 900/1190, Loss: 1.0949\n",
      "Epoch: 16/20, Batch: 950/1190, Loss: 0.8144\n",
      "Epoch: 16/20, Batch: 1000/1190, Loss: 1.2163\n",
      "Epoch: 16/20, Batch: 1050/1190, Loss: 1.1493\n",
      "Epoch: 16/20, Batch: 1100/1190, Loss: 0.7616\n",
      "Epoch: 16/20, Batch: 1150/1190, Loss: 1.0261\n",
      "Epoch: 16, Train Loss: 0.9824\n",
      "Epoch: 17/20, Batch: 0/1190, Loss: 0.7713\n",
      "Epoch: 17/20, Batch: 50/1190, Loss: 1.0145\n",
      "Epoch: 17/20, Batch: 100/1190, Loss: 1.3786\n",
      "Epoch: 17/20, Batch: 150/1190, Loss: 0.7982\n",
      "Epoch: 17/20, Batch: 200/1190, Loss: 1.3996\n",
      "Epoch: 17/20, Batch: 250/1190, Loss: 0.8206\n",
      "Epoch: 17/20, Batch: 300/1190, Loss: 0.6770\n",
      "Epoch: 17/20, Batch: 350/1190, Loss: 0.9795\n",
      "Epoch: 17/20, Batch: 400/1190, Loss: 0.8192\n",
      "Epoch: 17/20, Batch: 450/1190, Loss: 0.8351\n",
      "Epoch: 17/20, Batch: 500/1190, Loss: 0.9607\n",
      "Epoch: 17/20, Batch: 550/1190, Loss: 1.2589\n",
      "Epoch: 17/20, Batch: 600/1190, Loss: 1.1672\n",
      "Epoch: 17/20, Batch: 650/1190, Loss: 1.0917\n",
      "Epoch: 17/20, Batch: 700/1190, Loss: 1.1253\n",
      "Epoch: 17/20, Batch: 750/1190, Loss: 0.9470\n",
      "Epoch: 17/20, Batch: 800/1190, Loss: 1.1105\n",
      "Epoch: 17/20, Batch: 850/1190, Loss: 1.0406\n",
      "Epoch: 17/20, Batch: 900/1190, Loss: 0.8130\n",
      "Epoch: 17/20, Batch: 950/1190, Loss: 0.8706\n",
      "Epoch: 17/20, Batch: 1000/1190, Loss: 1.0701\n",
      "Epoch: 17/20, Batch: 1050/1190, Loss: 0.9759\n",
      "Epoch: 17/20, Batch: 1100/1190, Loss: 0.7448\n",
      "Epoch: 17/20, Batch: 1150/1190, Loss: 1.2671\n",
      "Epoch: 17, Train Loss: 0.9819\n",
      "Epoch: 18/20, Batch: 0/1190, Loss: 1.0946\n",
      "Epoch: 18/20, Batch: 50/1190, Loss: 1.0164\n",
      "Epoch: 18/20, Batch: 100/1190, Loss: 0.8396\n",
      "Epoch: 18/20, Batch: 150/1190, Loss: 1.1273\n",
      "Epoch: 18/20, Batch: 200/1190, Loss: 0.9362\n",
      "Epoch: 18/20, Batch: 250/1190, Loss: 1.1998\n",
      "Epoch: 18/20, Batch: 300/1190, Loss: 0.9124\n",
      "Epoch: 18/20, Batch: 350/1190, Loss: 0.9022\n",
      "Epoch: 18/20, Batch: 400/1190, Loss: 1.1862\n",
      "Epoch: 18/20, Batch: 450/1190, Loss: 1.2979\n",
      "Epoch: 18/20, Batch: 500/1190, Loss: 0.8730\n",
      "Epoch: 18/20, Batch: 550/1190, Loss: 1.3592\n",
      "Epoch: 18/20, Batch: 600/1190, Loss: 0.7903\n",
      "Epoch: 18/20, Batch: 650/1190, Loss: 0.7478\n",
      "Epoch: 18/20, Batch: 700/1190, Loss: 1.0076\n",
      "Epoch: 18/20, Batch: 750/1190, Loss: 0.7311\n",
      "Epoch: 18/20, Batch: 800/1190, Loss: 1.1294\n",
      "Epoch: 18/20, Batch: 850/1190, Loss: 1.1314\n",
      "Epoch: 18/20, Batch: 900/1190, Loss: 1.0795\n",
      "Epoch: 18/20, Batch: 950/1190, Loss: 0.8545\n",
      "Epoch: 18/20, Batch: 1000/1190, Loss: 0.9995\n",
      "Epoch: 18/20, Batch: 1050/1190, Loss: 0.8306\n",
      "Epoch: 18/20, Batch: 1100/1190, Loss: 1.3165\n",
      "Epoch: 18/20, Batch: 1150/1190, Loss: 1.2382\n",
      "Epoch: 18, Train Loss: 0.9793\n",
      "Epoch: 19/20, Batch: 0/1190, Loss: 0.9123\n",
      "Epoch: 19/20, Batch: 50/1190, Loss: 0.8427\n",
      "Epoch: 19/20, Batch: 100/1190, Loss: 0.9069\n",
      "Epoch: 19/20, Batch: 150/1190, Loss: 0.7319\n",
      "Epoch: 19/20, Batch: 200/1190, Loss: 1.0813\n",
      "Epoch: 19/20, Batch: 250/1190, Loss: 1.2285\n",
      "Epoch: 19/20, Batch: 300/1190, Loss: 1.4435\n",
      "Epoch: 19/20, Batch: 350/1190, Loss: 0.8324\n",
      "Epoch: 19/20, Batch: 400/1190, Loss: 0.9112\n",
      "Epoch: 19/20, Batch: 450/1190, Loss: 0.8152\n",
      "Epoch: 19/20, Batch: 500/1190, Loss: 0.7814\n",
      "Epoch: 19/20, Batch: 550/1190, Loss: 0.8802\n",
      "Epoch: 19/20, Batch: 600/1190, Loss: 1.7738\n",
      "Epoch: 19/20, Batch: 650/1190, Loss: 0.8478\n",
      "Epoch: 19/20, Batch: 700/1190, Loss: 0.8295\n",
      "Epoch: 19/20, Batch: 750/1190, Loss: 1.0127\n",
      "Epoch: 19/20, Batch: 800/1190, Loss: 0.9900\n",
      "Epoch: 19/20, Batch: 850/1190, Loss: 1.2408\n",
      "Epoch: 19/20, Batch: 900/1190, Loss: 1.0581\n",
      "Epoch: 19/20, Batch: 950/1190, Loss: 0.8194\n",
      "Epoch: 19/20, Batch: 1000/1190, Loss: 1.0035\n",
      "Epoch: 19/20, Batch: 1050/1190, Loss: 0.9271\n",
      "Epoch: 19/20, Batch: 1100/1190, Loss: 0.7921\n",
      "Epoch: 19/20, Batch: 1150/1190, Loss: 1.2159\n",
      "Epoch: 19, Train Loss: 0.9835\n",
      "Epoch: 20/20, Batch: 0/1190, Loss: 0.8635\n",
      "Epoch: 20/20, Batch: 50/1190, Loss: 0.8265\n",
      "Epoch: 20/20, Batch: 100/1190, Loss: 0.9676\n",
      "Epoch: 20/20, Batch: 150/1190, Loss: 0.9192\n",
      "Epoch: 20/20, Batch: 200/1190, Loss: 0.7661\n",
      "Epoch: 20/20, Batch: 250/1190, Loss: 0.7622\n",
      "Epoch: 20/20, Batch: 300/1190, Loss: 1.0640\n",
      "Epoch: 20/20, Batch: 350/1190, Loss: 1.0460\n",
      "Epoch: 20/20, Batch: 400/1190, Loss: 0.8222\n",
      "Epoch: 20/20, Batch: 450/1190, Loss: 0.7682\n",
      "Epoch: 20/20, Batch: 500/1190, Loss: 1.0292\n",
      "Epoch: 20/20, Batch: 550/1190, Loss: 0.8467\n",
      "Epoch: 20/20, Batch: 600/1190, Loss: 0.9471\n",
      "Epoch: 20/20, Batch: 650/1190, Loss: 0.7585\n",
      "Epoch: 20/20, Batch: 700/1190, Loss: 0.9755\n",
      "Epoch: 20/20, Batch: 750/1190, Loss: 0.7025\n",
      "Epoch: 20/20, Batch: 800/1190, Loss: 1.0795\n",
      "Epoch: 20/20, Batch: 850/1190, Loss: 0.8458\n",
      "Epoch: 20/20, Batch: 900/1190, Loss: 1.3027\n",
      "Epoch: 20/20, Batch: 950/1190, Loss: 1.0097\n",
      "Epoch: 20/20, Batch: 1000/1190, Loss: 0.9547\n",
      "Epoch: 20/20, Batch: 1050/1190, Loss: 0.9515\n",
      "Epoch: 20/20, Batch: 1100/1190, Loss: 0.9585\n",
      "Epoch: 20/20, Batch: 1150/1190, Loss: 0.7962\n",
      "Epoch: 20, Train Loss: 0.9811\n",
      "Training finished!\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "id": "JzBirwrUAihk",
    "outputId": "b2f2436f-b845-4255-dd21-c28565a89899",
    "ExecuteTime": {
     "end_time": "2025-11-05T04:14:20.390832Z",
     "start_time": "2025-11-05T04:14:19.450213Z"
    }
   },
   "source": [
    "weighted_model.eval()\n",
    "y_true_weighted = []\n",
    "y_pred_weighted = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = weighted_model(data)\n",
    "\n",
    "        y_true_weighted.extend(target.cpu().numpy())\n",
    "        y_pred_weighted.extend((output > 0.5).cpu().numpy())\n",
    "\n",
    "y_true_weighted = np.array(y_true_weighted)\n",
    "y_pred_weighted = np.array(y_pred_weighted)\n",
    "\n",
    "print(\"\\nClassification Report (Weighted):\")\n",
    "print(classification_report(y_true_weighted, y_pred_weighted))\n",
    "print(\"\\nConfusion Matrix (Weighted):\")\n",
    "cm_weighted = confusion_matrix(y_true_weighted, y_pred_weighted)\n",
    "sns.heatmap(cm_weighted, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Weighted)')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Weighted):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.68      0.80     91915\n",
      "         1.0       0.22      0.85      0.34      9557\n",
      "\n",
      "    accuracy                           0.69    101472\n",
      "   macro avg       0.60      0.77      0.57    101472\n",
      "weighted avg       0.91      0.69      0.76    101472\n",
      "\n",
      "\n",
      "Confusion Matrix (Weighted):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
